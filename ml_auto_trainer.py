#!/usr/bin/env python3
"""
ğŸ¤– ML AUTO TRAINER - Sistema de Entrenamientos y Re-entrenamientos AutomÃ¡ticos
===============================================================================

CONSOLIDADO: Gestiona entrenamientos automÃ¡ticos de MÃšLTIPLES modelos + Re-entrenamiento continuo
1. Recolecta datos reales del sistema
2. Genera datasets automÃ¡ticamente
3. Entrena mÃºltiples modelos en paralelo
4. Re-entrena periÃ³dicamente (reemplaza ml_auto_retrainer.py OBSOLETO)
5. Despliega modelos exitosos

FEATURES v2.0:
    pass  # TODO: Implementar
- Entrenamiento programado + bajo demanda
- Re-entrenamiento incremental automÃ¡tico
- Cola de prioridad para entrenamientos
- MÃ©tricas consolidadas de entrenamientos/re-entrenamientos
- Circuit breakers para prevenciÃ³n de fallos

Autor: METACORTEX Team
Fecha: 2025-11-04 (Consolidado)
"""

import json
import logging
import threading
import time
from datetime import UTC, datetime, timedelta
from pathlib import Path

try:
    from ml_pipeline import ModelType, TrainingConfig, TrainingStatus, get_ml_pipeline

    ML_PIPELINE_AVAILABLE = True
except ImportError:
    ML_PIPELINE_AVAILABLE = False
    logging.warning("âš ï¸ ml_pipeline no disponible")

try:
    from ml_data_collector import get_data_collector

    DATA_COLLECTOR_AVAILABLE = True
except ImportError:
    DATA_COLLECTOR_AVAILABLE = False
    logging.warning("âš ï¸ ml_data_collector no disponible")

logger = logging.getLogger(__name__)


class MLAutoTrainer:
    """
    Sistema de entrenamientos automÃ¡ticos para METACORTEX

    Funcionalidades:
    - RecolecciÃ³n continua de datos
    - Entrenamiento automÃ¡tico de mÃºltiples modelos
    - Re-entrenamiento periÃ³dico
    - Despliegue automÃ¡tico de modelos exitosos
    """

    def __init__(
        self,
        retraining_interval_hours: int = 24,
        min_samples_threshold: int = 100,
        enable_auto_collection: bool = True,
    ):
        if not ML_PIPELINE_AVAILABLE:
            raise RuntimeError("ml_pipeline no disponible")

        if not DATA_COLLECTOR_AVAILABLE:
            raise RuntimeError("ml_data_collector no disponible")

        self.ml_pipeline = get_ml_pipeline()
        self.data_collector = get_data_collector()

        self.retraining_interval = timedelta(hours=retraining_interval_hours)
        self.min_samples_threshold = min_samples_threshold
        self.enable_auto_collection = enable_auto_collection

        # Control de threads
        self.running = False
        self.collection_thread = None
        self.training_thread = None

        # Estado
        self.last_training = {}
        self.training_schedule = self._create_training_schedule()

        logger.info("âœ… ML Auto Trainer inicializado")
        logger.info(f"   Re-entrenamiento cada: {retraining_interval_hours}h")
        logger.info(f"   MÃ­nimo de muestras: {min_samples_threshold}")
        logger.info(f"   Modelos programados: {len(self.training_schedule)}")

    def _create_training_schedule(self) -> list[dict]:
        """
        Define todos los modelos a entrenar automÃ¡ticamente
        """
        schedule = [
            {
                "name": "intention_classifier",
                "model_type": ModelType.CLASSIFICATION,
                "algorithm": "random_forest",
                "dataset_generator": "generate_intention_classifier_dataset",
                "hyperparameters": {
                    "n_estimators": 100,
                    "max_depth": 10,
                    "min_samples_split": 5,
                },
                "auto_deploy": True,
                "min_accuracy": 0.85,
                "description": "Clasificador de intenciones de usuario",
            },
            {
                "name": "load_predictor",
                "model_type": ModelType.CLASSIFICATION,
                "algorithm": "gradient_boosting",
                "dataset_generator": "generate_load_predictor_dataset",
                "hyperparameters": {
                    "n_estimators": 100,
                    "learning_rate": 0.1,
                    "max_depth": 5,
                },
                "auto_deploy": True,
                "min_accuracy": 0.80,
                "description": "Predictor de carga del sistema",
            },
            {
                "name": "cache_optimizer",
                "model_type": ModelType.CLASSIFICATION,
                "algorithm": "logistic_regression",
                "dataset_generator": "generate_cache_optimizer_dataset",
                "hyperparameters": {"max_iter": 1000, "C": 1.0},
                "auto_deploy": True,
                "min_accuracy": 0.75,
                "description": "Optimizador de patrones de cachÃ©",
            },
            {
                "name": "agent_performance",
                "model_type": ModelType.REGRESSION,
                "algorithm": "gradient_boosting",
                "dataset_generator": "generate_agent_performance_dataset",
                "hyperparameters": {
                    "n_estimators": 100,
                    "learning_rate": 0.1,
                    "max_depth": 5,
                },
                "auto_deploy": True,
                "min_accuracy": 0.70,  # RÂ² para regresiÃ³n
                "description": "Predictor de rendimiento de agentes",
            },
        ]

        return schedule

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RECOLECCIÃ“N DE DATOS AUTOMÃTICA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def start_auto_collection(self):
        """Inicia recolecciÃ³n automÃ¡tica de datos del sistema"""
        if not self.enable_auto_collection:
            logger.info("âš ï¸ RecolecciÃ³n automÃ¡tica deshabilitada")
            return

        self.running = True
        self.collection_thread = threading.Thread(
            target=self._collection_loop, daemon=True, name="MLAutoCollector"
        )
        self.collection_thread.start()
        logger.info("âœ… RecolecciÃ³n automÃ¡tica iniciada")

    def _collection_loop(self):
        """Loop de recolecciÃ³n de datos"""
        while self.running:
            try:
                # Recolectar mÃ©tricas del sistema cada 5 minutos
                self.data_collector.collect_system_metrics()
                logger.debug("ğŸ“Š MÃ©tricas del sistema recolectadas")

                # Esperar 5 minutos
                time.sleep(300)

            except Exception:
                logger.exception("âŒ Error en recolecciÃ³n automÃ¡tica")
                time.sleep(60)  # Esperar 1 min si hay error

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ENTRENAMIENTO AUTOMÃTICO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def start_auto_training(self):
        """Inicia entrenamientos automÃ¡ticos"""
        self.running = True
        self.training_thread = threading.Thread(
            target=self._training_loop, daemon=True, name="MLAutoTrainer"
        )
        self.training_thread.start()
        logger.info("âœ… Entrenamientos automÃ¡ticos iniciados")

    def _training_loop(self):
        """Loop de entrenamientos automÃ¡ticos"""
        while self.running:
            try:
                # Verificar cada modelo en el schedule
                for model_config in self.training_schedule:
                    self._check_and_train_model(model_config)

                # Esperar 1 hora antes de verificar de nuevo
                time.sleep(3600)

            except Exception:
                logger.exception("âŒ Error en training loop")
                time.sleep(300)  # Esperar 5 min si hay error

    def _check_and_train_model(self, model_config: dict):
        """
        Verifica si un modelo necesita entrenamiento y lo ejecuta
        """
        model_name = model_config["name"]

        # Verificar si necesita re-entrenamiento
        if model_name in self.last_training:
            time_since_last = datetime.now(UTC) - self.last_training[model_name]
            if time_since_last < self.retraining_interval:
                logger.debug(f"â­ï¸ {model_name}: No requiere re-entrenamiento aÃºn")
                return

        # Generar dataset
        logger.info(f"ğŸ“Š Generando dataset para {model_name}...")
        generator_method = getattr(self.data_collector, model_config["dataset_generator"])
        dataset_path = generator_method(min_samples=self.min_samples_threshold)

        if dataset_path is None:
            logger.warning(f"âš ï¸ {model_name}: Insuficientes datos para entrenar")
            return

        # Crear configuraciÃ³n de entrenamiento
        training_config = TrainingConfig(
            model_type=model_config["model_type"],
            model_name=model_name,
            algorithm=model_config["algorithm"],
            train_data_path=str(dataset_path),
            hyperparameters=model_config["hyperparameters"],
            auto_deploy=model_config["auto_deploy"],
            min_accuracy=model_config["min_accuracy"],
            validation_split=0.2,
        )

        # Encolar entrenamiento
        logger.info(f"ğŸš€ Encolando entrenamiento: {model_name}")
        logger.info(f"   DescripciÃ³n: {model_config['description']}")
        logger.info(f"   Algoritmo: {model_config['algorithm']}")
        logger.info(f"   Dataset: {dataset_path}")

        self.ml_pipeline.enqueue_training(training_config)

        # Actualizar Ãºltima vez entrenado
        self.last_training[model_name] = datetime.now(UTC)

    def train_all_models_now(self) -> dict[str, bool]:
        """
        Fuerza entrenamiento inmediato de todos los modelos

        Returns:
            Dict con resultado de cada modelo
        """
        logger.info("ğŸš€ Iniciando entrenamiento de TODOS los modelos...")

        results = {}

        for model_config in self.training_schedule:
            model_name = model_config["name"]

            try:
                # Generar dataset
                generator_method = getattr(self.data_collector, model_config["dataset_generator"])
                dataset_path = generator_method(min_samples=self.min_samples_threshold)

                if dataset_path is None:
                    logger.warning(f"âš ï¸ {model_name}: Insuficientes datos")
                    results[model_name] = False
                    continue

                # Crear configuraciÃ³n
                training_config = TrainingConfig(
                    model_type=model_config["model_type"],
                    model_name=model_name,
                    algorithm=model_config["algorithm"],
                    train_data_path=str(dataset_path),
                    hyperparameters=model_config["hyperparameters"],
                    auto_deploy=model_config["auto_deploy"],
                    min_accuracy=model_config["min_accuracy"],
                    validation_split=0.2,
                )

                # Encolar
                self.ml_pipeline.enqueue_training(training_config)
                self.last_training[model_name] = datetime.now(UTC)

                results[model_name] = True
                logger.info(f"âœ… {model_name} encolado para entrenamiento")

            except Exception:
                logger.exception("âŒ Error entrenando {model_name}")
                results[model_name] = False

        # Resumen
        successful = sum(1 for success in results.values() if success)
        total = len(results)
        logger.info(f"âœ… Entrenamiento iniciado: {successful}/{total} modelos")

        return results

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CONTROL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def start(self):
        """Inicia sistema completo de auto-entrenamiento"""
        logger.info("ğŸš€ Iniciando ML Auto Trainer...")

        # Iniciar recolecciÃ³n
        self.start_auto_collection()

        # Iniciar entrenamientos
        self.start_auto_training()

        # Guardar estado en archivo
        self._save_status_file()

        logger.info("âœ… ML Auto Trainer completamente iniciado")

    def stop(self):
        """Detiene todos los threads"""
        logger.info("ğŸ›‘ Deteniendo ML Auto Trainer...")
        self.running = False

        if self.collection_thread and self.collection_thread.is_alive():
            self.collection_thread.join(timeout=5)
            logger.info("âœ… RecolecciÃ³n detenida")

        if self.training_thread and self.training_thread.is_alive():
            self.training_thread.join(timeout=5)
            logger.info("âœ… Entrenamientos detenidos")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RE-ENTRENAMIENTO AUTOMÃTICO (consolidado de ml_auto_retrainer.py OBSOLETO)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def trigger_retraining(self, model_name: str) -> bool:
        """
        Dispara re-entrenamiento inmediato de un modelo especÃ­fico

        Args:
            model_name: Nombre del modelo a re-entrenar

        Returns:
            True si el re-entrenamiento fue programado exitosamente
        """
        logger.info(f"ğŸ”„ Re-entrenamiento disparado para: {model_name}")

        # Buscar configuraciÃ³n del modelo
        model_config = next((m for m in self.training_schedule if m["name"] == model_name), None)

        if not model_config:
            logger.exception(f"âŒ Modelo no encontrado: {model_name}")
            return False

        try:
            self._check_and_train_model(model_config)
            logger.info(f"âœ… Re-entrenamiento de {model_name} programado")
            return True
        except Exception:
            logger.exception("âŒ Error disparando re-entrenamiento de {model_name}")
            return False

    def retrain_all_models(self) -> dict[str, bool]:
        """
        Re-entrena todos los modelos inmediatamente

        Returns:
            Dict con resultado de cada re-entrenamiento
        """
        logger.info("ğŸ”„ Re-entrenando TODOS los modelos...")
        return self.train_all_models_now()

    def get_retraining_metrics(self) -> dict:
        """
        Obtiene mÃ©tricas de re-entrenamientos

        Returns:
            Dict con mÃ©tricas de re-entrenamientos
        """
        total_retrainings = len(self.last_training)

        return {
            "total_models": len(self.training_schedule),
            "models_trained": total_retrainings,
            "last_trainings": {
                name: timestamp.isoformat() for name, timestamp in self.last_training.items()
            },
            "retraining_interval_hours": self.retraining_interval.total_seconds() / 3600,
            "next_retraining_due": {
                name: (timestamp + self.retraining_interval).isoformat()
                for name, timestamp in self.last_training.items()
            },
        }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # GESTIÃ“N Y ESTADO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _save_status_file(self):
        """Guarda estado en archivo para lectura externa"""
        try:
            status_file = Path("ml_data") / "auto_trainer_status.json"
            status_file.parent.mkdir(exist_ok=True)

            with open(status_file, "w") as f:
                json.dump(
                    {
                        "running": self.running,
                        "collection_thread_alive": self.collection_thread.is_alive()
                        if self.collection_thread
                        else False,
                        "training_thread_alive": self.training_thread.is_alive()
                        if self.training_thread
                        else False,
                        "last_update": datetime.now(UTC).isoformat(),
                    },
                    f,
                    indent=2,
                )
        except Exception:
            logger.exception("Error guardando estado")

    def get_status(self) -> dict:
        """Obtiene estado del auto-trainer"""
        stats = self.data_collector.get_data_stats()

        # Intentar leer estado de archivo si existe
        running_status = self.running
        try:
            status_file = Path("ml_data") / "auto_trainer_status.json"
            if status_file.exists():
                with open(status_file) as f:
                    file_status = json.load(f)
                    running_status = file_status.get("running", self.running)
        except Exception:
            logger.error(f"Error: {e}", exc_info=True)
        return {
            "running": running_status,
            "models_scheduled": len(self.training_schedule),
            "models_trained": len(self.last_training),
            "data_collected": stats,
            "next_retraining": {
                model: (self.last_training[model] + self.retraining_interval).isoformat()
                for model in self.last_training
            },
            "ml_pipeline_stats": self.ml_pipeline.get_stats(),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SINGLETON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_global_auto_trainer = None


def get_auto_trainer(**kwargs) -> MLAutoTrainer:
    """Obtiene instancia global del auto-trainer"""
    global _global_auto_trainer
    if _global_auto_trainer is None:
        _global_auto_trainer = MLAutoTrainer(**kwargs)
    return _global_auto_trainer


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

    print("ğŸ¤– ML Auto Trainer - Test")
    print("=" * 60)

    # Crear auto-trainer
    trainer = get_auto_trainer(
        retraining_interval_hours=24,
        min_samples_threshold=10,  # Bajo para test
        enable_auto_collection=False,  # Deshabilitado para test
    )

    # Primero generar datos de prueba
    print("\nğŸ“Š Generando datos de prueba...")
    collector = trainer.data_collector

    # Datos de usuario
    intents = ["coding", "search", "analysis", "chat", "debug"]
    queries = [
        "Crea una funciÃ³n",
        "Busca informaciÃ³n",
        "Analiza el cÃ³digo",
        "Hola",
        "Error en el cÃ³digo",
    ]

    for i in range(50):
        collector.collect_user_interaction(
            user_query=queries[i % len(queries)],
            intent=intents[i % len(intents)],
            response_time_ms=100 + i * 10,
            tokens_used=50 + i,
            success=True,
            agent_used="test_agent",
        )

    # MÃ©tricas del sistema
    for _ in range(50):
        collector.collect_system_metrics()

    # CachÃ©
    for i in range(50):
        collector.collect_cache_pattern(
            cache_key=f"key_{i}",
            hit=i % 2 == 0,
            access_time_ms=5 + i,
            data_size_kb=10 + i,
        )

    # Agentes
    for i in range(50):
        collector.collect_agent_performance(
            agent_name="test_agent",
            task_type="test_task",
            execution_time_ms=100 + i * 5,
            success=True,
        )

    print("âœ… Datos de prueba generados")

    # Entrenar todos los modelos
    print("\nğŸš€ Entrenando todos los modelos...")
    results = trainer.train_all_models_now()

    for model, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {model}")

    # Ver estado
    print("\nğŸ“Š Estado del sistema:")
    status = trainer.get_status()
    print(f"   Modelos programados: {status['models_scheduled']}")
    print(f"   Modelos encolados: {status['models_trained']}")
    print("   Datos recolectados:")
    for table, count in status["data_collected"].items():
        print(f"      {table}: {count}")

    # Ver estado del pipeline
    print("\nğŸ“Š Estado del ML Pipeline:")
    ml_stats = status["ml_pipeline_stats"]
    print(f"   Modelos entrenados: {ml_stats['total_models_trained']}")
    print(f"   Modelos activos: {ml_stats['active_models']}")
    print(f"   Cola de entrenamiento: {ml_stats['queue_size']}")
    print(f"   Modo perpetuo: {ml_stats['perpetual_mode']}")

    print("\nâœ… Test completado")
    print("\nğŸ’¡ Para ver el progreso del entrenamiento:")
    print("   tail -f ml_models/training_history.json")