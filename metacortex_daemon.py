from metacortex_sinaptico.db import MetacortexDB
from metacortex_sinaptico.divine_protection import create_divine_protection_system
from metacortex_sinaptico.learning import StructuralLearning
from metacortex_sinaptico.memory import MemorySystem
#!/usr/bin/env python3
"""
üîÆ METACORTEX DAEMON v4.0 - MILITARY GRADE ORCHESTRATION SYSTEM
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚öîÔ∏è SISTEMA DE ORQUESTACI√ìN DE GRADO MILITAR CON ALTA DISPONIBILIDAD ‚öîÔ∏è

Caracter√≠sticas Militares de Nivel Avanzado:
    pass  # TODO: Implementar
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üõ°Ô∏è  RESILIENCIA Y ALTA DISPONIBILIDAD:
   ‚Ä¢ Circuit Breakers multi-nivel con timeout adaptativo
   ‚Ä¢ Health Checks distribuidos con m√©tricas en tiempo real
   ‚Ä¢ Auto-recovery con backoff exponencial
   ‚Ä¢ Failover autom√°tico con estado distribuido
   ‚Ä¢ Redundancia de componentes cr√≠ticos
   ‚Ä¢ Chaos Engineering para validaci√≥n continua

üîí SEGURIDAD DE NIVEL MILITAR:
   ‚Ä¢ Zero-Trust Architecture con mutual TLS
   ‚Ä¢ Audit logging completo con tamper-proof storage
   ‚Ä¢ Encryption at rest y en tr√°nsito (AES-256-GCM)
   ‚Ä¢ Rate limiting y DDoS protection
   ‚Ä¢ Secure credential management
   ‚Ä¢ RBAC granular

‚ö° PERFORMANCE Y ESCALABILIDAD:
   ‚Ä¢ Thread pool din√°mico con auto-scaling
   ‚Ä¢ Memory-mapped I/O para operaciones cr√≠ticas
   ‚Ä¢ Cache distribuido con coherencia fuerte
   ‚Ä¢ Load balancing con algoritmos avanzados
   ‚Ä¢ Connection pooling optimizado
   ‚Ä¢ Zero-copy networking cuando posible

üìä OBSERVABILIDAD Y TELEMETR√çA:
   ‚Ä¢ Distributed tracing con OpenTelemetry
   ‚Ä¢ Prometheus metrics exporters
   ‚Ä¢ Structured logging con contexto enriquecido
   ‚Ä¢ Real-time dashboards
   ‚Ä¢ Alerting inteligente con ML-based anomaly detection
   ‚Ä¢ Performance profiling continuo

üß† INTELIGENCIA COGNITIVA AVANZADA:
   ‚Ä¢ Sistema BDI completo
   ‚Ä¢ Planificaci√≥n multi-horizonte
   ‚Ä¢ Aprendizaje por refuerzo
   ‚Ä¢ Meta-cognici√≥n y auto-reflexi√≥n
   ‚Ä¢ Conocimiento distribuido
   ‚Ä¢ Razonamiento causal

üöÄ CAPACIDADES EXPONENCIALES:
   ‚Ä¢ Auto-mejora continua
   ‚Ä¢ Materializaci√≥n de c√≥digo
   ‚Ä¢ Generaci√≥n de agentes on-demand
   ‚Ä¢ Evoluci√≥n arquitect√≥nica
   ‚Ä¢ Optimizaci√≥n multi-objetivo
   ‚Ä¢ Predicci√≥n de fallos con ML

üçé OPTIMIZACI√ìN APPLE SILICON:
   ‚Ä¢ Metal Performance Shaders
   ‚Ä¢ Neural Engine integration
   ‚Ä¢ Unified Memory Architecture
   ‚Ä¢ Energy-aware scheduling

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Autor: METACORTEX Advanced Military Systems Division
Fecha: 25 octubre 2025
Versi√≥n: 4.0 - MILITARY GRADE EVOLUTION
Clasificaci√≥n: TACTICAL-ADVANCED
"""

# üîß FIX PANDAS CIRCULAR IMPORT (ANTES DE CUALQUIER IMPORT)
# Deshabilitar la inicializaci√≥n problem√°tica de pandas C extensions
import os
import sys
from pathlib import Path

# üî• SOLUCI√ìN CR√çTICA: Aumentar l√≠mite de recursi√≥n GLOBALMENTE
# Problema: sentence-transformers + PyTorch + pathlib causan deep recursion
# Soluci√≥n: L√≠mite muy alto ANTES de cualquier import complejo
sys.setrecursionlimit(100000)  # 100K - suficiente para cualquier caso

# Configurar rutas PRIMERO
DAEMON_ROOT = Path(__file__).parent
if str(DAEMON_ROOT) not in sys.path:
    sys.path.insert(0, str(DAEMON_ROOT))

# Prevenir circular import de pandas configurando variables ANTES de importar
os.environ['PANDAS_WARN_ON_C_EXTENSION_IMPORT'] = '0'

# Ahora s√≠, imports normales
import atexit
import json
import logging
import os
import signal
import socket
import subprocess
import sys
import threading
import time
import traceback
import uuid
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from threading import Event, RLock
from typing import Any

# Cargar variables de entorno
env_file = Path(__file__).parent / ".env"
if env_file.exists():
    with open(env_file) as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#") and "=" in line:
                key, value = line.split("=", 1)
                os.environ[key.strip()] = value.strip()
    print("‚úÖ Variables de entorno cargadas")

# Instalar dependencias cr√≠ticas PRIMERO
try:
    import psutil
except ImportError:
    print("‚ö†Ô∏è Instalando psutil...")
    subprocess.run([sys.executable, "-m", "pip", "install", "psutil"], check=True)
    import psutil

# Crear directorio de logs
LOG_DIR = DAEMON_ROOT / "logs"
LOG_DIR.mkdir(exist_ok=True)

from unified_logging import setup_unified_logging
from cognitive_integration import get_cognitive_bridge
import multiprocessing as mp
from queue import Empty
from programming_agent import get_programming_agent
import time
import time
import time
from metacortex_sinaptico.planning import MultiHorizonPlanner
from single_instance import ensure_single_instance

logger = setup_unified_logging(
    name="DAEMON_MILITARY",
    log_file=str(LOG_DIR / "metacortex_daemon_military.log"),
    level=logging.INFO,
)

# üçé Configurar MPS DESPU√âS de logging (evita conflictos de import)
try:
    from mps_config import configure_mps_system, is_apple_silicon

    if is_apple_silicon():
        logger.info("üçé Detectado Apple Silicon - configurando MPS...")
        mps_status = configure_mps_system()
        success = sum(mps_status.values())
        total = len(mps_status)
        logger.info(f"‚úÖ MPS: {success}/{total} componentes configurados")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è MPS config error: {e}")


class ComponentState(Enum):
    """Estados de componentes militares"""

    INITIALIZING = "initializing"
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    CRITICAL = "critical"
    FAILED = "failed"
    RECOVERING = "recovering"
    TERMINATED = "terminated"


class CircuitState(Enum):
    """Estados del circuit breaker"""

    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"


class PriorityLevel(Enum):
    """Niveles de prioridad"""

    CRITICAL = 10
    HIGH = 7
    MEDIUM = 5
    LOW = 3
    BACKGROUND = 1


@dataclass
class CircuitBreakerMetrics:
    """M√©tricas del circuit breaker"""

    state: CircuitState = CircuitState.CLOSED
    failure_count: int = 0
    success_count: int = 0
    last_failure_time: datetime | None = None
    open_time: datetime | None = None
    half_open_attempts: int = 0
    total_requests: int = 0
    failure_threshold: int = 5
    success_threshold: int = 3
    timeout_seconds: int = 60
    consecutive_failures: int = 0

    def should_attempt(self) -> bool:
        if self.state == CircuitState.CLOSED:
            return True
        if self.state == CircuitState.OPEN:
            if self.open_time and (datetime.now() - self.open_time).seconds >= self.timeout_seconds:
                self.state = CircuitState.HALF_OPEN
                self.half_open_attempts = 0
                logger.info("üîÑ Circuit breaker ‚Üí HALF_OPEN")
                return True
            return False
        return self.half_open_attempts < self.success_threshold

    def record_success(self):
        self.success_count += 1
        self.consecutive_failures = 0
        self.total_requests += 1

        if self.state == CircuitState.HALF_OPEN:
            self.half_open_attempts += 1
            if self.half_open_attempts >= self.success_threshold:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                logger.info("‚úÖ Circuit breaker ‚Üí CLOSED")

    def record_failure(self):
        self.failure_count += 1
        self.consecutive_failures += 1
        self.last_failure_time = datetime.now()
        self.total_requests += 1

        if self.consecutive_failures >= self.failure_threshold:
            if self.state != CircuitState.OPEN:
                self.state = CircuitState.OPEN
                self.open_time = datetime.now()
                logger.error(f"‚ö†Ô∏è Circuit breaker ‚Üí OPEN ({self.consecutive_failures} fallos)")

        if self.state == CircuitState.HALF_OPEN:
            self.state = CircuitState.OPEN
            self.open_time = datetime.now()
            logger.warning("‚ö†Ô∏è Circuit breaker ‚Üí OPEN (fallo en recuperaci√≥n)")


@dataclass
class ComponentMetrics:
    """M√©tricas de componente"""

    name: str
    state: ComponentState = ComponentState.INITIALIZING
    start_time: datetime = field(default_factory=datetime.now)
    last_health_check: datetime | None = None
    health_check_count: int = 0
    failure_count: int = 0
    restart_count: int = 0
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    response_time_ms: float = 0.0
    error_rate: float = 0.0
    uptime_seconds: float = 0.0

    def to_dict(self) -> dict[str, Any]:
        return {
            "name": self.name,
            "state": self.state.value,
            "start_time": self.start_time.isoformat(),
            "health_check_count": self.health_check_count,
            "failure_count": self.failure_count,
            "restart_count": self.restart_count,
            "cpu_percent": self.cpu_percent,
            "memory_mb": self.memory_mb,
            "error_rate": self.error_rate,
            "uptime_seconds": self.uptime_seconds,
        }


class MetacortexMilitaryDaemon:
    """
    Daemon Militar de Grado Avanzado
    """

    def __init__(self):
        logger.info("=" * 80)
        logger.info("‚öîÔ∏è METACORTEX MILITARY DAEMON v4.0 - INITIALIZING")
        logger.info("=" * 80)

        self.running = True
        self.daemon_id = str(uuid.uuid4())
        self.start_time = datetime.now()
        self.hostname = socket.gethostname()

        self.components: dict[str, dict[str, Any]] = {}
        self.component_metrics: dict[str, ComponentMetrics] = {}
        self.circuit_breakers: dict[str, CircuitBreakerMetrics] = {}

        self.lock = RLock()
        self.executor = ThreadPoolExecutor(
            max_workers=20, thread_name_prefix="metacortex_military_"
        )
        self.shutdown_event = Event()

        self.autonomous_mode = True
        self.last_materialization = datetime.now()
        self.materialization_interval = timedelta(minutes=10)
        self.base_interval_minutes = 10
        self.max_interval_minutes = 20
        self.min_interval_minutes = 5
        self.materialization_count = 0
        self.autonomous_cycles = 0

        self.energy_manager = MilitaryEnergyManager()
        self.in_rest_mode = False

        self.pid_file = DAEMON_ROOT / "metacortex_daemon_military.pid"
        self.state_file = DAEMON_ROOT / "logs" / "daemon_military_state.json"
        self.write_pid()

        # Neural network - LAZY LOADING (se carga en run())
        self.neural_network = None
        self._neural_network_loaded = False
        logger.info("‚ÑπÔ∏è Neural Network: LAZY LOADING (se cargar√° en run())")

        # Cognitive bridge - LAZY LOADING
        self.cognitive_bridge = None
        self.cognitive_bridge_initializing = False
        self.cognitive_bridge_failed = False

        # üÜï 2026: Cognitive Agent Pool - LAZY LOADING
        self.agent_pool = None
        self._agent_pool_loaded = False
        logger.info("‚ÑπÔ∏è Cognitive Agent Pool: LAZY LOADING (se cargar√° en run())")

        # ML Pipeline - LAZY LOADING
        self.ml_pipeline = None
        self._ml_pipeline_loaded = False
        logger.info("‚ÑπÔ∏è ML Pipeline: LAZY LOADING (se cargar√° en run())")

        # Auto-Trainer
        self.auto_trainer = None
        try:
            from ml_auto_trainer import get_auto_trainer

            self.auto_trainer = get_auto_trainer(
                retraining_interval_hours=24, min_samples_threshold=100, enable_auto_collection=True
            )
            self.auto_trainer.start()
            logger.info("‚úÖ Auto-Trainer inicializado")
        except Exception as e:
            logger.error(f"‚ùå Auto-Trainer: {e}")

        # üÜï 2026: Auto-Repair System
        self.auto_repair = None
        self.last_auto_repair = datetime.now()
        self.auto_repair_interval = timedelta(hours=1)  # Cada 1 hora
        self.auto_repair_health_threshold = 85.0  # Trigger si health < 85%
        try:
            from system_auto_repair import get_auto_repair

            self.auto_repair = get_auto_repair(
                project_root=DAEMON_ROOT, logs_dir=DAEMON_ROOT / "logs", auto_repair_enabled=True
            )
            logger.info("‚úÖ Auto-Repair System inicializado")
            logger.info(f"   Intervalo: {self.auto_repair_interval.total_seconds() / 3600:.1f}h")
            logger.info(f"   Health threshold: {self.auto_repair_health_threshold}%")
        except Exception as e:
            logger.error(f"‚ùå Auto-Repair: {e}")

        # üÜï 2026: Disk Space Manager
        self.disk_manager = None
        self.last_disk_cleanup = datetime.now()
        self.disk_cleanup_interval = timedelta(hours=6)  # Cada 6 horas
        try:
            from disk_space_manager import get_disk_space_manager

            self.disk_manager = get_disk_space_manager(
                project_root=DAEMON_ROOT,
                logs_dir=DAEMON_ROOT / "logs",
                retention_days=30,
                max_log_size_mb=10,
                compression_enabled=True,
            )
            logger.info("‚úÖ Disk Space Manager inicializado")
            logger.info(
                f"   Intervalo limpieza: {self.disk_cleanup_interval.total_seconds() / 3600:.1f}h"
            )
            logger.info("   Retenci√≥n: 30 d√≠as")
        except Exception as e:
            logger.error(f"‚ùå Disk Space Manager: {e}")

        # üíæ 2026: Distributed Storage Manager V2.0 - Auto-detecci√≥n de TODOS los discos
        # LAZY LOADING: Se carga en run() para evitar bloquear __init__() con setup inicial
        self.distributed_storage = None
        self._distributed_storage_loaded = False
        self.last_storage_sync = datetime.now()
        self.storage_sync_interval = timedelta(hours=1)  # Sincronizar cada 1 hora
        self.storage_initial_setup_done = False
        logger.info("‚ÑπÔ∏è Distributed Storage Manager: LAZY LOADING (se cargar√° en run())")
        logger.info("   Setup inicial se ejecutar√° en background para no bloquear daemon")

        # üîå 2026: Port Monitor - Monitoreo continuo de puertos y procesos
        self.port_monitor_enabled = True
        self.last_port_monitoring = datetime.now()
        self.port_monitoring_interval = timedelta(minutes=5)  # Cada 5 minutos
        self.port_monitor_auto_fix = True
        self.port_health_history: dict[int, list[bool]] = defaultdict(list)
        self.critical_ports = {
            6379: "Redis",
            8000: "Web Interface",
            5000: "API Server",
            8080: "Dashboard",
            11434: "Ollama",
            9090: "Telemetry",
        }
        logger.info("‚úÖ Port Monitor integrado")
        logger.info(
            f"   Intervalo monitoreo: {self.port_monitoring_interval.total_seconds() / 60:.1f}min"
        )
        logger.info(f"   Puertos cr√≠ticos: {len(self.critical_ports)}")
        logger.info(f"   Auto-fix: {'ENABLED' if self.port_monitor_auto_fix else 'DISABLED'}")

        # Auto-Git Manager
        self.auto_git_manager = None
        try:
            from auto_git_manager import get_auto_git_manager

            self.auto_git_manager = get_auto_git_manager(repo_root=str(DAEMON_ROOT), logger=logger)
            logger.info("‚úÖ Auto-Git Manager inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Auto-Git Manager: {e}")

        # üÜï 2026: TELEMETRY SYSTEM (m√©tricas militares)
        self.telemetry_system = None
        try:
            from telemetry_system import MetacortexTelemetrySystem

            self.telemetry_system = MetacortexTelemetrySystem(
                service_name="metacortex_daemon", enable_prometheus=True, enable_custom_export=True
            )
            logger.info("‚úÖ Telemetry System inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Telemetry System: {e}")

        # üÜï 2026: LLM INTEGRATION (inteligencia de lenguaje)
        self.llm_integration = None
        try:
            from llm_integration import MetacortexLLM

            self.llm_integration = MetacortexLLM()
            logger.info("‚úÖ LLM Integration inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è LLM Integration: {e}")

        # üÜï 2026: MULTIMODAL PROCESSOR (PDF, im√°genes, audio, video)
        self.multimodal_processor = None
        try:
            from multimodal_processor import MultiModalProcessor

            self.multimodal_processor = MultiModalProcessor(cache_enabled=True)
            logger.info("‚úÖ Multimodal Processor inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Multimodal Processor: {e}")

        # üÜï 2026: ML COGNITIVE BRIDGE (integra ML + Cognitive)
        self.ml_cognitive_bridge = None
        try:
            from ml_cognitive_bridge import get_ml_cognitive_bridge

            self.ml_cognitive_bridge = get_ml_cognitive_bridge()
            logger.info("‚úÖ ML Cognitive Bridge inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ML Cognitive Bridge: {e}")

        # üÜï 2026: ML DATA COLLECTOR (recolecta datos para training)
        self.ml_data_collector = None
        try:
            from ml_data_collector import get_data_collector

            self.ml_data_collector = get_data_collector(data_dir="ml_data")
            logger.info("‚úÖ ML Data Collector inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ML Data Collector: {e}")

        # üÜï 2026: ML MODEL ADAPTER (adapta features din√°micamente)
        self.ml_model_adapter = None
        try:
            from ml_model_adapter import get_model_adapter

            self.ml_model_adapter = get_model_adapter(models_dir="ml_models")
            logger.info("‚úÖ ML Model Adapter inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ML Model Adapter: {e}")

        # üÜï 2026: UNIFIED MEMORY LAYER (memoria universal compartida)
        self.unified_memory = None
        try:
            from unified_memory_layer import UnifiedMemoryLayer

            self.unified_memory = UnifiedMemoryLayer(
                db_path=str(DAEMON_ROOT / "metacortex.sqlite"),
                enable_semantic_search=True,
                enable_knowledge_graph=True,
                working_memory_capacity=200,
                auto_sync_interval=300,
            )
            logger.info("‚úÖ Unified Memory Layer inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Unified Memory Layer: {e}")

        # üÜï 2026: VERIFICATION SYSTEM (auto-validaci√≥n continua)
        self.system_verifier = None
        try:
            from verify_complete_system import CompleteSystemVerifier

            self.system_verifier = CompleteSystemVerifier(root_path=str(DAEMON_ROOT))
            logger.info("‚úÖ Complete System Verifier inicializado")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è System Verifier: {e}")

        # üöÄ 2026: EXPONENTIAL CAPABILITY DISCOVERY ENGINE
        self.exponential_engine = None
        self.last_capability_discovery = datetime.now()
        self.capability_discovery_interval = timedelta(minutes=5)  # Descubrir cada 5 min
        self.capability_stats_log_interval = timedelta(hours=1)  # Log stats cada 1h
        self.last_stats_log = datetime.now()
        try:
            from exponential_capability_engine import get_exponential_engine

            self.exponential_engine = get_exponential_engine(project_root=DAEMON_ROOT)
            logger.info("‚úÖ Exponential Capability Engine inicializado")
            logger.info(
                f"   Intervalo descubrimiento: {self.capability_discovery_interval.total_seconds() / 60:.1f}min"
            )

            # Descubrimiento inicial en background
            logger.info("üîç Ejecutando descubrimiento inicial de agentes y capacidades...")
            self.executor.submit(self._initial_capability_discovery)
        except Exception as e:
            logger.error(f"‚ùå Exponential Capability Engine: {e}")

        # üéØ 2026: METACORTEX ORCHESTRATOR - Orquestaci√≥n unificada de agentes
        # NOTA: El orchestrator se ejecuta como proceso SEPARADO (ver metacortex_master.sh)
        # NO debe cargarse en __init__() porque es pesado y bloquea el daemon
        self.orchestrator = None
        self.last_orchestration_cycle = datetime.now()
        self.orchestration_interval = timedelta(minutes=15)  # Ciclo cada 15 min
        logger.info("‚ÑπÔ∏è Orchestrator se ejecuta como proceso separado")
        logger.info("   NO se carga en daemon para evitar bloqueos")
        
        # COMENTADO: El orchestrator es un proceso separado, NO debe cargarse aqu√≠
        # try:
        #     from metacortex_orchestrator import create_orchestrator
        #     self.orchestrator = create_orchestrator(str(DAEMON_ROOT))
        #     logger.info("‚úÖ Metacortex Orchestrator inicializado")
        #     logger.info("   Agentes disponibles: integration, programming, search, evolution")
        #     logger.info(
        #         f"   Intervalo orquestaci√≥n: {self.orchestration_interval.total_seconds() / 60:.1f}min"
        #     )
        # except Exception as e:
        #     logger.error(f"‚ùå Orchestrator: {e}")
        #     logger.error("   El daemon continuar√° sin orquestaci√≥n de agentes")

        # üîß 2026: IMPORT AUTO-HEALER - Auto-reparaci√≥n de dependencias
        self.import_healer = None
        self.last_healing_scan = datetime.now()
        self.healing_scan_interval = timedelta(hours=12)  # Scan cada 12 horas
        try:
            from import_auto_healer import get_import_healer

            self.import_healer = get_import_healer(project_root=DAEMON_ROOT, auto_install=True)
            logger.info("‚úÖ Import Auto-Healer inicializado")
            logger.info(
                f"   Intervalo scan: {self.healing_scan_interval.total_seconds() / 3600:.1f}h"
            )
            logger.info("   Auto-install: ENABLED")
        except Exception as e:
            logger.error(f"‚ùå Import Auto-Healer: {e}")

        # ‚ú® 2026: DIVINE PROTECTION SYSTEM - Protecci√≥n de perseguidos por la fe
        # LAZY LOADING: Se carga en run() para evitar bloquear __init__()
        self.divine_protection = None
        self._divine_protection_loaded = False
        self.last_protection_cycle = datetime.now()
        self.protection_cycle_interval = timedelta(minutes=30)  # Ciclo cada 30 min
        logger.info("‚ÑπÔ∏è Divine Protection System: LAZY LOADING (se cargar√° en run())")
        logger.info("üìñ 'He who dwells in the shelter of the Most High' - Psalm 91:1")

        signal.signal(signal.SIGTERM, self.signal_handler)
        signal.signal(signal.SIGINT, self.signal_handler)
        atexit.register(self.cleanup)

        logger.info(f"üÜî Daemon ID: {self.daemon_id}")
        logger.info(f"üñ•Ô∏è  Hostname: {self.hostname}")
        logger.info(f"üÜî PID: {os.getpid()}")
        logger.info("‚úÖ Military Daemon inicializado")

    def write_pid(self):
        with open(self.pid_file, "w") as f:
            f.write(str(os.getpid()))

    def signal_handler(self, signum, frame):
        logger.info(f"‚ö†Ô∏è Se√±al {signum} recibida")
        self.shutdown()

    def start_component_with_circuit_breaker(
        self,
        name: str,
        command: list[str],
        cwd: Path | None = None,
        priority: PriorityLevel = PriorityLevel.MEDIUM,
    ) -> bool:
        if name not in self.circuit_breakers:
            self.circuit_breakers[name] = CircuitBreakerMetrics()

        circuit = self.circuit_breakers[name]

        if not circuit.should_attempt():
            logger.warning(f"‚ö†Ô∏è Circuit OPEN para {name}")
            return False

        try:
            logger.info(f"üöÄ Iniciando: {name} ({priority.name})")

            # Crear archivos de log para stdout y stderr
            log_dir = DAEMON_ROOT / "logs"
            log_dir.mkdir(exist_ok=True)
            stdout_log = log_dir / f"{name}_stdout.log"
            stderr_log = log_dir / f"{name}_stderr.log"

            with open(stdout_log, "a") as stdout_file, open(stderr_log, "a") as stderr_file:
                process = subprocess.Popen(
                    command,
                    cwd=cwd or DAEMON_ROOT,
                    stdout=stdout_file,
                    stderr=stderr_file,
                    env={**os.environ, "PYTHONUNBUFFERED": "1"},
                )

            time.sleep(2)

            if process.poll() is None:
                with self.lock:
                    self.components[name] = {
                        "process": process,
                        "command": command,
                        "cwd": cwd,
                        "priority": priority,
                        "start_time": datetime.now(),
                    }

                    self.component_metrics[name] = ComponentMetrics(
                        name=name, state=ComponentState.HEALTHY, start_time=datetime.now()
                    )

                circuit.record_success()
                logger.info(f"‚úÖ {name} iniciado (PID: {process.pid})")
                logger.info(f"   üìÑ Logs: {stdout_log} | {stderr_log}")
                return True
            
            # Si fall√≥, leer los logs
            with open(stdout_log) as f:
                stdout_content = f.read()
            with open(stderr_log) as f:
                stderr_content = f.read()
            
            logger.error(f"‚ùå {name} fall√≥")
            if stdout_content:
                logger.error(f"STDOUT: {stdout_content[-500:]}")  # √öltimas 500 chars
            if stderr_content:
                logger.error(f"STDERR: {stderr_content[-500:]}")  # √öltimas 500 chars
            circuit.record_failure()
            return False

        except Exception as e:
            logger.error(f"‚ùå Error iniciando {name}: {e}")
            circuit.record_failure()
            return False

    def check_component_health(self, name: str) -> ComponentState:
        if name not in self.components:
            return ComponentState.FAILED

        component = self.components[name]
        process = component["process"]

        if process.poll() is not None:
            return ComponentState.FAILED

        try:
            proc = psutil.Process(process.pid)
            cpu = proc.cpu_percent(interval=0.1)
            memory = proc.memory_info().rss / 1024 / 1024

            if name in self.component_metrics:
                metrics = self.component_metrics[name]
                metrics.cpu_percent = cpu
                metrics.memory_mb = memory
                metrics.last_health_check = datetime.now()
                metrics.health_check_count += 1

                if cpu > 90 or memory > 2048:
                    return ComponentState.DEGRADED
                return ComponentState.HEALTHY

            return ComponentState.HEALTHY

        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return ComponentState.FAILED

    def restart_component_with_backoff(self, name: str, max_attempts: int = 3) -> bool:
        if name not in self.components:
            return False

        component = self.components[name]

        for attempt in range(1, max_attempts + 1):
            logger.info(f"üîÑ Reiniciando {name} ({attempt}/{max_attempts})")

            try:
                component["process"].terminate()
                component["process"].wait(timeout=5)
            except Exception as e:
                logger.error(f"Error: {e}", exc_info=True)
                try:
                    component["process"].kill()
                except Exception as e:
                    logger.error(f"Error: {e}", exc_info=True)
                    pass

            if attempt > 1:
                backoff = min(2**attempt, 60)
                time.sleep(backoff)

            success = self.start_component_with_circuit_breaker(
                name,
                component["command"],
                component.get("cwd"),
                component.get("priority", PriorityLevel.MEDIUM),
            )

            if success:
                if name in self.component_metrics:
                    self.component_metrics[name].restart_count += 1
                return True

        return False

    def start_all_components(self):
        logger.info("üöÄ Iniciando componentes militares...")

        venv_python = DAEMON_ROOT / ".venv" / "bin" / "python3"
        python_cmd = str(venv_python) if venv_python.exists() else sys.executable

        # Web Interface (puerto 8000) - incluye dashboard en /api/dashboard/metrics
        self.start_component_with_circuit_breaker(
            "web_server",
            [python_cmd, "web_interface/server.py"],
            cwd=DAEMON_ROOT,
            priority=PriorityLevel.HIGH,
        )

        # Neural Network
        neural_file = DAEMON_ROOT / "neural_symbiotic_network.py"
        if neural_file.exists():
            self.start_component_with_circuit_breaker(
                "neural_network",
                [python_cmd, "neural_symbiotic_network.py", "--daemon"],
                cwd=DAEMON_ROOT,
                priority=PriorityLevel.CRITICAL,
            )

        logger.info(f"‚úÖ {len(self.components)} componentes iniciados")

        logger.info("üåâ Inicializando Cognitive Bridge (EAGER mode)...")
        self.cognitive_bridge = get_cognitive_bridge(str(DAEMON_ROOT))
        logger.info("‚úÖ Cognitive Bridge inicializado (EAGER, NO LAZY) - Programming agent listo")

    def start_autonomous_mode(self):
        if not self.autonomous_mode:
            return

        logger.info("ü§ñ INICIANDO MODO AUT√ìNOMO MILITAR")

        def autonomous_loop():
            logger.info("ü§ñ Loop aut√≥nomo militar activo")

            while self.running and not self.shutdown_event.is_set():
                try:
                    if self.in_rest_mode:
                        time.sleep(60)
                        continue

                    now = datetime.now()

                    # üöÄ 2026: Descubrimiento de capacidades exponencial cada 5 min
                    if self.exponential_engine and (
                        now - self.last_capability_discovery >= self.capability_discovery_interval
                    ):
                        logger.info("üîç Ciclo de descubrimiento de capacidades...")

                        try:
                            self._periodic_capability_discovery()
                            self.last_capability_discovery = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en descubrimiento de capacidades: {e}")

                    # Log estad√≠sticas detalladas cada 1 hora
                    if self.exponential_engine and (
                        now - self.last_stats_log >= self.capability_stats_log_interval
                    ):
                        try:
                            self._log_capability_statistics()
                            self.last_stats_log = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en log de estad√≠sticas: {e}")

                    # üÜï 2026: Auto-Repair peri√≥dico
                    if self.auto_repair and (
                        now - self.last_auto_repair >= self.auto_repair_interval
                    ):
                        logger.info("üîß Ciclo de Auto-Repair...")

                        try:
                            diagnosis = self.auto_repair.diagnose_system()
                            health_pct = diagnosis.get("health_percentage", 0)

                            logger.info(f"   Health: {health_pct:.1f}%")

                            # Trigger auto-repair si health < threshold
                            if health_pct < self.auto_repair_health_threshold:
                                logger.warning(
                                    f"‚ö†Ô∏è Health bajo ({health_pct:.1f}% < {self.auto_repair_health_threshold}%)"
                                )
                                logger.info("üîß Ejecutando auto-reparaci√≥n...")

                                repair_result = self.auto_repair.auto_repair(diagnosis)

                                if repair_result.get("success"):
                                    logger.info(
                                        f"‚úÖ Auto-repair exitoso: {repair_result.get('repairs_successful', 0)} fixes"
                                    )
                                else:
                                    logger.warning("‚ö†Ô∏è Auto-repair no pudo ejecutar fixes")
                            else:
                                logger.info(f"‚úÖ Sistema saludable ({health_pct:.1f}%)")

                            self.last_auto_repair = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en Auto-Repair: {e}")

                    # üîå 2026: Port Monitor - Monitoreo de puertos cr√≠ticos cada 5 min
                    if self.port_monitor_enabled and (
                        now - self.last_port_monitoring >= self.port_monitoring_interval
                    ):
                        logger.info("üîå Ciclo de monitoreo de puertos...")

                        try:
                            self._monitor_critical_ports()
                            self.last_port_monitoring = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en Port Monitor: {e}")

                    # üÜï 2026: Disk Space Manager - Limpieza peri√≥dica cada 6h
                    if self.disk_manager and (
                        now - self.last_disk_cleanup >= self.disk_cleanup_interval
                    ):
                        logger.info("üóÇÔ∏è Ciclo de limpieza de disco...")

                        try:
                            # Obtener uso de disco antes
                            usage_before = self.disk_manager.get_disk_usage()
                            disk_percent = usage_before.get("disk_percent_used", 0)

                            logger.info(f"   Disco usado: {disk_percent:.1f}%")

                            # Ejecutar limpieza si disco >80% o cada 6h
                            if disk_percent > 80 or (
                                now - self.last_disk_cleanup >= self.disk_cleanup_interval
                            ):
                                if disk_percent > 80:
                                    logger.warning(f"‚ö†Ô∏è Disco alto ({disk_percent:.1f}% > 80%)")

                                logger.info("üßπ Ejecutando limpieza autom√°tica...")
                                cleanup_result = self.disk_manager.auto_cleanup(dry_run=False)

                                if cleanup_result.get("success", False):
                                    summary = cleanup_result.get("summary", {})
                                    logger.info("‚úÖ Limpieza completada:")
                                    logger.info(
                                        f"   ‚Ä¢ Espacio liberado: {summary.get('total_space_freed_mb', 0):.2f}MB"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Archivos rotados: {summary.get('files_rotated', 0)}"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Archivos comprimidos: {summary.get('files_compressed', 0)}"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Archivos eliminados: {summary.get('files_deleted', 0)}"
                                    )
                                else:
                                    logger.warning("‚ö†Ô∏è Limpieza de disco no completada")
                            else:
                                logger.info(f"‚úÖ Disco OK ({disk_percent:.1f}%)")

                            self.last_disk_cleanup = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en Disk Space Manager: {e}")

                    # üíæ 2026: Distributed Storage V2.0 - Sincronizaci√≥n y auto-migraci√≥n cada 1h
                    if self.distributed_storage and (
                        now - self.last_storage_sync >= self.storage_sync_interval
                    ):
                        logger.info("üíæ Ciclo de almacenamiento distribuido V2.0...")

                        try:
                            # Obtener estado del almacenamiento
                            storage_status = self.distributed_storage.get_storage_status()
                            primary_disk_percent = storage_status.get("primary_disk_percent", 0)

                            logger.info(f"   Disco primario: {primary_disk_percent:.1f}% usado")
                            logger.info(f"   Vol√∫menes disponibles: {storage_status.get('total_volumes', 0)}")
                            logger.info(f"   Espacio total externo: {storage_status.get('total_space_tb', 0):.2f} TB")
                            logger.info(f"   Espacio libre externo: {storage_status.get('total_free_tb', 0):.2f} TB")

                            # Auto-migraci√≥n si disco primario > 85%
                            if primary_disk_percent > 85.0:
                                logger.warning(f"‚ö†Ô∏è Disco primario alto ({primary_disk_percent:.1f}% > 85%)")
                                logger.info("üöÄ Ejecutando auto-migraci√≥n a discos externos...")

                                # Migrar archivos grandes >10MB
                                migration_result = self.distributed_storage.auto_migrate_large_files(
                                    min_size_mb=10,
                                    exclude_patterns=["*.pyc", "__pycache__", ".git", ".venv"]
                                )

                                if migration_result.get("success", False):
                                    logger.info("‚úÖ Auto-migraci√≥n completada:")
                                    logger.info(f"   ‚Ä¢ Archivos migrados: {migration_result.get('files_migrated', 0)}")
                                    logger.info(f"   ‚Ä¢ Espacio liberado: {migration_result.get('bytes_migrated', 0) / 1024**3:.2f} GB")
                                    
                                    # Actualizar estad√≠sticas
                                    logger.info(f"   ‚Ä¢ Total migraciones: {self.distributed_storage.stats.get('total_migrations', 0)}")
                                    logger.info(f"   ‚Ä¢ Total migrado: {self.distributed_storage.stats.get('total_bytes_migrated', 0) / 1024**3:.2f} GB")
                                else:
                                    logger.warning("‚ö†Ô∏è Auto-migraci√≥n no completada")
                            else:
                                logger.info(f"‚úÖ Disco primario OK ({primary_disk_percent:.1f}%)")

                            self.last_storage_sync = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en Distributed Storage V2.0: {e}")

                    # üéØ 2026: Ciclo de Orquestaci√≥n - Coordina todos los agentes
                    if self.orchestrator and (
                        now - self.last_orchestration_cycle >= self.orchestration_interval
                    ):
                        logger.info("üéØ Ciclo de orquestaci√≥n de agentes...")

                        try:
                            # Obtener estado del sistema
                            status = self.orchestrator.get_system_status()
                            logger.info(f"   Servicios: {len(status.get('services', {}))}")
                            logger.info(f"   Health checks: {len(status.get('health_checks', []))}")

                            # Ejecutar an√°lisis de carga y balanceo
                            # (El orchestrator maneja esto internamente)

                            self.last_orchestration_cycle = now
                            logger.info("‚úÖ Ciclo de orquestaci√≥n completado")
                        except Exception as e:
                            logger.error(f"‚ùå Error en orquestaci√≥n: {e}")

                    # üîß 2026: Healing Scan - Verifica imports y dependencias cada 12h
                    if self.import_healer and (
                        now - self.last_healing_scan >= self.healing_scan_interval
                    ):
                        logger.info("üîß Ejecutando healing scan del sistema...")

                        try:
                            # Ejecutar scan en background para no bloquear
                            future = self.executor.submit(self.import_healer.heal_project, True)

                            # Esperar m√°ximo 2 minutos
                            report = future.result(timeout=120)

                            logger.info("‚úÖ Healing scan completado:")
                            logger.info(f"   ‚Ä¢ Archivos escaneados: {report['files_scanned']}")
                            logger.info(f"   ‚Ä¢ Imports verificados: {report['imports_checked']}")
                            logger.info(f"   ‚Ä¢ Reparados: {report['repaired']}")
                            logger.info(f"   ‚Ä¢ Fallidos: {report['failed']}")

                            if report["repaired"] > 0:
                                logger.info(
                                    f"‚ú® {report['repaired']} dependencias reparadas autom√°ticamente"
                                )

                            self.last_healing_scan = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en healing scan: {e}")

                    # ‚ú® 2026: Divine Protection - Protecci√≥n de perseguidos cada 30min
                    if self.divine_protection and (
                        now - self.last_protection_cycle >= self.protection_cycle_interval
                    ):
                        logger.info("‚ú® Ciclo de Divine Protection...")
                        logger.info("üìñ 'The Lord is my shepherd; I shall not want' - Psalm 23:1")

                        try:
                            # Evaluar amenazas de todas las personas protegidas
                            critical_cases = 0
                            for (
                                person_id,
                                person,
                            ) in self.divine_protection.protected_people.items():
                                threat_level = self.divine_protection.assess_threat_level(person_id)
                                if threat_level.value in ["critical", "endangered"]:
                                    critical_cases += 1
                                    logger.warning(
                                        f"‚ö†Ô∏è Caso cr√≠tico: {person.codename} - {threat_level.value}"
                                    )

                            # üåç 2026: MONITOREO REAL DE PERSECUCI√ìN
                            if self.divine_protection.real_ops:
                                logger.info("üåç Ejecutando monitoreo REAL de persecuci√≥n...")
                                try:
                                    # En producci√≥n, esto llamar√≠a a APIs reales de noticias
                                    # alerts = await self.divine_protection.real_ops.monitor_persecution_news()

                                    # Por ahora, registrar capacidad operacional
                                    real_status = (
                                        self.divine_protection.real_ops.get_operations_status()
                                    )

                                    logger.info("‚úÖ Sistema de operaciones REALES activo:")
                                    logger.info(
                                        f"   ‚Ä¢ Canales comunicaci√≥n: {real_status['communication']['channels_active']}"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Wallets crypto: {real_status['financial']['wallets']}"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Safe houses: {real_status['safe_houses']['total_houses']}"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Fondo emergencia: ${real_status['financial']['emergency_fund_total']:,.0f}"
                                    )
                                    logger.info(
                                        f"   ‚Ä¢ Regiones monitoreadas: {len(real_status['intelligence']['monitored_regions'])}"
                                    )
                                    logger.info(
                                        "   üìñ 'Do not withhold good when it is in your power to act' - Proverbs 3:27"
                                    )

                                except Exception as e:
                                    logger.error(f"‚ùå Error en monitoreo real: {e}")

                            # Obtener estado del sistema
                            status = self.divine_protection.get_system_status()

                            logger.info("‚úÖ Ciclo de protecci√≥n completado:")
                            logger.info(
                                f"   ‚Ä¢ Personas protegidas: {status['protected_persons']['total']}"
                            )
                            logger.info(f"   ‚Ä¢ Casos cr√≠ticos: {critical_cases}")
                            logger.info(f"   ‚Ä¢ Refugios activos: {status['safe_havens']['total']}")
                            logger.info(
                                f"   ‚Ä¢ Capacidad disponible: {status['safe_havens']['total_capacity'] - status['safe_havens']['current_occupancy']}"
                            )
                            logger.info(
                                f"   ‚Ä¢ Planes de supervivencia: {status['survival_plans']['active']}"
                            )
                            logger.info(
                                f"   ‚Ä¢ Sistemas infiltrados: {status['infiltration']['systems_infiltrated']}"
                            )
                            logger.info(
                                f"   ‚Ä¢ Provisiones entregadas: {status['statistics']['provisions_delivered']}"
                            )

                            self.last_protection_cycle = now
                        except Exception as e:
                            logger.error(f"‚ùå Error en Divine Protection: {e}")
                            logger.error(f"   Traceback: {traceback.format_exc()}")

                    # Materializaci√≥n militar
                    if now - self.last_materialization >= self.materialization_interval:
                        logger.info("üß† Ciclo de materializaci√≥n militar...")

                        future = self.executor.submit(self._execute_materialization_military)

                        try:
                            result = future.result(timeout=120)

                            if result.get("success"):
                                logger.info("‚úÖ Materializaci√≥n exitosa:")
                                logger.info(
                                    f"   ‚Ä¢ Componentes: {result.get('components_created', 0)}"
                                )
                                logger.info(
                                    f"   ‚Ä¢ Mejoras: {result.get('improvements_applied', 0)}"
                                )

                                self.materialization_count += 1

                                if self.auto_git_manager:
                                    try:
                                        self.auto_git_manager.auto_commit_generated_files(result)
                                    except Exception as e:
                                        logger.warning(f"‚ö†Ô∏è Auto-commit: {e}")

                            self.last_materialization = now
                            self.autonomous_cycles += 1
                            self._adjust_interval_by_load()

                        except Exception as e:
                            logger.error(f"‚ùå Timeout materializaci√≥n: {e}")

                    time.sleep(30)

                except Exception as e:
                    logger.error(f"‚ùå Error loop aut√≥nomo: {e}")
                    time.sleep(60)

        autonomous_thread = threading.Thread(
            target=autonomous_loop, daemon=True, name="AutonomousMilitary"
        )
        autonomous_thread.start()

        logger.info("‚úÖ Modo aut√≥nomo militar activo")

    def _execute_materialization_military(self) -> dict[str, Any]:
        """
        Materializaci√≥n militar con Cognitive Bridge optimizado

        Caracter√≠sticas 2026:
        - Cognitive agent pool con pre-carga
        - Timeout real con multiprocessing
        - Fallback autom√°tico a materializaci√≥n b√°sica
        - Circuit breaker para prevenir colapsos
        """
        start_time = time.time()

        try:
            if self.cognitive_bridge:
                logger.info("üß† Materializaci√≥n cognitiva militar (con fallback)...")

                # ‚úÖ 2026: programming_agent inicializado con EAGER mode en cognitive_bridge
                # NO lazy loading - ya est√° completamente disponible desde __init__

                # üöÄ NUEVO: Usar multiprocessing para timeout REAL

                result_queue = mp.Queue()
                tick_result = {"success": False}
                improvement_result = {"success": False}

                # üîß FIX: Usar threading en vez de multiprocessing para evitar pickling
                # Multiprocessing requiere que la funci√≥n sea picklable (no puede ser nested)
                # Threading es suficiente para timeout y no requiere pickling
                
                def run_cognitive_tick_thread():
                    """Ejecuta cognitive tick en thread separado"""
                    try:
                        result = self.cognitive_bridge.cognitive_tick_with_orchestration()
                        result_queue.put({"success": True, "result": result})
                    except Exception as e:
                        logger.error(f"Error: {e}", exc_info=True)
                        result_queue.put({"success": False, "error": str(e)})

                # Ejecutar en thread separado con timeout
                logger.info("‚è±Ô∏è  Ejecutando cognitive tick (timeout: 60s)...")
                tick_thread = threading.Thread(
                    target=run_cognitive_tick_thread, daemon=True
                )
                tick_thread.start()
                tick_thread.join(timeout=60)

                if tick_thread.is_alive():
                    # TIMEOUT - el thread seguir√° corriendo pero lo ignoramos
                    logger.warning("‚è∞ Timeout en cognitive tick (60s) - activando fallback")
                    # NOTE: No podemos "matar" threads como procesos, pero daemon=True
                    # significa que se limpiar√° autom√°ticamente al cerrar el programa

                    # üî• FALLBACK: Materializaci√≥n b√°sica
                    logger.info("üîß Fallback a materializaci√≥n b√°sica...")
                    try:
                        from programming_agent import get_programming_agent

                        agent = get_programming_agent(
                            project_root=str(DAEMON_ROOT), cognitive_agent=None
                        )
                        basic_result = agent.materialize_metacortex_thoughts()

                        return {
                            "success": basic_result.get("success", False),
                            "type": "basic_fallback",
                            "components_created": basic_result.get("components_created", 0),
                            "agents_generated": basic_result.get("agents_generated", 0),
                            "improvements_applied": basic_result.get("improvements_applied", 0),
                            "elapsed_seconds": time.time() - start_time,
                            "fallback": True,
                        }
                    except Exception as fallback_error:
                        logger.error(f"‚ùå Error en fallback: {fallback_error}")
                        return {"success": False, "error": str(fallback_error)}

                # Obtener resultado del proceso
                try:
                    process_result = result_queue.get_nowait()
                    if process_result["success"]:
                        tick_result = process_result["result"]
                        logger.info("‚úÖ Cognitive tick completado exitosamente")
                    else:
                        logger.error(f"‚ùå Error en cognitive tick: {process_result.get('error')}")
                except Empty:
                    logger.warning("‚ö†Ô∏è No se pudo obtener resultado del proceso")

                # Ejecutar improvement cycle (solo si tick tuvo √©xito)
                improvement_result = {"success": False}
                if tick_result.get("success"):
                    try:
                        logger.info("üîß Ejecutando improvement cycle...")
                        improvement_result = self.cognitive_bridge.autonomous_improvement_cycle()
                    except Exception as e:
                        logger.error(f"‚ùå Error en improvement: {e}")

                # Consolidar resultados
                success = tick_result.get("success", False) or improvement_result.get(
                    "success", False
                )

                components = 0
                agents = 0
                improvements = improvement_result.get("improvements_applied", 0)

                mat_result = tick_result.get("materialization_result")
                if mat_result and isinstance(mat_result, dict):
                    components = mat_result.get("components_created", 0)
                    agents = mat_result.get("agents_generated", 0)
                    improvements += mat_result.get("improvements_applied", 0)

                return {
                    "success": success,
                    "type": "cognitive_military_optimized",
                    "components_created": components,
                    "agents_generated": agents,
                    "improvements_applied": improvements,
                    "elapsed_seconds": time.time() - start_time,
                }

            # Si no hay cognitive bridge, usar materializaci√≥n b√°sica
            logger.info("üîß Materializaci√≥n b√°sica militar (no cognitive bridge)...")


            agent = get_programming_agent(project_root=str(DAEMON_ROOT), cognitive_agent=None)

            return agent.materialize_metacortex_thoughts()

        except Exception as e:
            logger.error(f"‚ùå Materializaci√≥n: {e}")
            return {"success": False, "error": str(e)}

    def _initial_capability_discovery(self):
        """
        Descubrimiento inicial de agentes y capacidades al inicio del daemon
        """
        if not self.exponential_engine:
            return

        try:
            logger.info("üîç Descubrimiento inicial de capacidades y agentes...")

            # Descubrir agentes en el directorio ra√≠z
            discovered = self.exponential_engine.discover_agents_in_directory(
                DAEMON_ROOT, recursive=True
            )

            stats = self.exponential_engine.get_statistics()

            logger.info("‚úÖ Descubrimiento inicial completado:")
            logger.info(f"   ‚Ä¢ Agentes descubiertos: {stats.get('agents_discovered', 0)}")
            logger.info(f"   ‚Ä¢ Keywords aprendidas: {stats.get('keywords', 0)}")
            logger.info(f"   ‚Ä¢ Patrones reconocidos: {stats.get('patterns', 0)}")
            logger.info(f"   ‚Ä¢ M√≥dulos analizados: {stats.get('modules', 0)}")

            # Registrar agentes descubiertos con la red neuronal
            if self.neural_network and discovered:
                try:
                    for agent in discovered:
                        # Descubrir capacidades del agente
                        try:
                            module = __import__(agent.module_path, fromlist=[agent.class_name])
                            agent_class = getattr(module, agent.class_name, None)
                            if agent_class:
                                # Intentar instanciar el agente
                                instance = agent_class()
                                # Usar discover_module_capabilities_exponential (m√©todo correcto)
                                result = self.exponential_engine.discover_module_capabilities_exponential(
                                    instance,
                                    learn_mode=True  # IMPORTANTE: Aprender keywords
                                )
                                agent.capabilities = result.get("capabilities", [])
                                new_keywords = len(result.get("metadata", {}).get("new_keywords_learned", []))
                                logger.debug(f"  ‚îî‚îÄ {agent.name}: {len(agent.capabilities)} capacidades, {new_keywords} keywords")
                        except Exception as e:
                            logger.debug(f"  ‚îî‚îÄ {agent.name}: error descubriendo capacidades: {e}")
                        
                        # Registrar en red neuronal
                        self.neural_network.register_module(
                            agent.name,
                            {
                                "module_path": agent.module_path,
                                "capabilities": agent.capabilities,
                                "agent_type": agent.agent_type.value,
                                "getter_function": agent.getter_function,
                            },
                        )
                    logger.info(f"‚úÖ {len(discovered)} agentes registrados en red neuronal")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error registrando agentes en red neuronal: {e}")

        except Exception as e:
            logger.error(f"‚ùå Error en descubrimiento inicial: {e}")

    def _periodic_capability_discovery(self):
        """
        Descubrimiento peri√≥dico de capacidades - se ejecuta cada 5 minutos
        """
        if not self.exponential_engine:
            return

        try:
            logger.info("üîç Descubrimiento peri√≥dico de capacidades...")

            # Obtener stats previas
            stats_before = self.exponential_engine.get_statistics()

            # Ejecutar descubrimiento
            discovered = self.exponential_engine.discover_agents_in_directory(
                DAEMON_ROOT, recursive=True
            )

            # Obtener stats actualizadas
            stats_after = self.exponential_engine.get_statistics()

            # Calcular crecimiento
            new_keywords = stats_after.get('keywords', 0) - stats_before.get('keywords', 0)
            new_agents = stats_after.get('agents_discovered', 0) - stats_before.get('agents_discovered', 0)

            if new_keywords > 0 or new_agents > 0:
                logger.info("‚ú® Sistema aprendi√≥:")
                if new_keywords > 0:
                    logger.info(f"   ‚Ä¢ {new_keywords} nuevas keywords")
                if new_agents > 0:
                    logger.info(f"   ‚Ä¢ {new_agents} nuevos agentes")

                # Registrar nuevos agentes con la red neuronal
                if self.neural_network and discovered:
                    try:
                        for agent in discovered:
                            self.neural_network.register_module(
                                agent.name,
                                {
                                    "file_path": str(agent.module_path)
                                    if hasattr(agent, "module_path")
                                    else "unknown",
                                    "capabilities": agent.capabilities
                                    if hasattr(agent, "capabilities")
                                    else [],
                                    "methods": [m.name for m in agent.methods]
                                    if hasattr(agent, "methods")
                                    else [],
                                },
                            )
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Error registrando agentes: {e}")
            else:
                logger.info("‚úÖ No hay nuevas capacidades (sistema estable)")

        except Exception as e:
            logger.error(f"‚ùå Error en descubrimiento peri√≥dico: {e}")

    def _log_capability_statistics(self):
        """
        Log estad√≠sticas detalladas de capacidades cada hora
        """
        if not self.exponential_engine:
            return

        try:
            stats = self.exponential_engine.get_statistics()

            logger.info("üìä ESTAD√çSTICAS DE CAPACIDADES:")
            logger.info(f"   Total scans: {stats.get('scans', 0)}")
            logger.info(f"   M√≥dulos analizados: {stats.get('modules', 0)}")
            logger.info(f"   Keywords aprendidas: {stats.get('keywords', 0)}")
            logger.info(f"   Agentes descubiertos: {stats.get('agents_discovered', 0)}")
            logger.info(f"   Patrones reconocidos: {stats.get('patterns', 0)}")
            logger.info(f"   Cache hit rate: {stats.get('cache_hit_rate', '0%')}")
            logger.info(f"   Nivel conocimiento: {stats.get('knowledge_level', 'BASIC')}")

            # Exportar estad√≠sticas a archivo
            try:
                stats_file = DAEMON_ROOT / "logs" / "capability_stats.json"
                agents_data = []
                if hasattr(self.exponential_engine, "discovered_agents"):
                    for agent_name, agent_obj in self.exponential_engine.discovered_agents.items():
                        agents_data.append(
                            {
                                "name": agent_name,
                                "capabilities": agent_obj.capabilities
                                if hasattr(agent_obj, "capabilities")
                                else [],
                            }
                        )

                with open(stats_file, "w") as f:
                    json.dump(
                        {
                            "timestamp": datetime.now().isoformat(),
                            "statistics": stats,
                            "discovered_agents": agents_data,
                        },
                        f,
                        indent=2,
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error guardando stats: {e}")

        except Exception as e:
            logger.error(f"‚ùå Error en log de estad√≠sticas: {e}")

    def _start_ollama_service(self):
        """Inicia el servidor Ollama si no est√° corriendo"""
        try:
            import subprocess

            # üîß FIX: Verificar PRIMERO si Ollama ya est√° corriendo
            if self._check_port_status(11434):
                logger.info("‚úÖ Ollama Server ya est√° activo (puerto 11434)")
                return True

            # Verificar si ollama est√° instalado
            result = subprocess.run(
                ["which", "ollama"], capture_output=True, text=True, check=False
            )
            if result.returncode != 0:
                logger.error("‚ùå Ollama no est√° instalado")
                return False

            logger.info("üöÄ Iniciando Ollama Server...")

            # Iniciar ollama en background
            process = subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True,
            )

            # Esperar 5 segundos para que inicie

            time.sleep(5)

            # Verificar si est√° corriendo
            if self._check_port_status(11434):
                logger.info(f"‚úÖ Ollama Server iniciado correctamente (PID: {process.pid})")
                return True
            logger.error("‚ùå Ollama Server no pudo iniciar")
            return False

        except Exception as e:
            logger.error(f"‚ùå Error iniciando Ollama: {e}")
            return False

    def _start_redis_service(self):
        """Inicia el servidor Redis si no est√° corriendo"""
        try:
            import subprocess

            # üîß FIX: Verificar PRIMERO si Redis ya est√° corriendo
            if self._check_port_status(6379):
                logger.info("‚úÖ Redis Server ya est√° activo (puerto 6379)")
                return True

            # Verificar si redis-server est√° instalado
            result = subprocess.run(
                ["which", "redis-server"], capture_output=True, text=True, check=False
            )
            if result.returncode != 0:
                logger.error("‚ùå Redis no est√° instalado")
                logger.info("   Instalar con: brew install redis")
                return False

            logger.info("üöÄ Iniciando Redis Server...")

            # Intentar con brew services primero (macOS)
            result = subprocess.run(
                ["brew", "services", "start", "redis"], capture_output=True, text=True, check=False
            )

            if result.returncode == 0:

                time.sleep(2)

                if self._check_port_status(6379):
                    logger.info("‚úÖ Redis Server iniciado correctamente (brew services)")
                    return True

            # Si brew fall√≥, intentar manualmente
            logger.info("   Intentando inicio manual...")
            process = subprocess.Popen(
                ["redis-server"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True,
            )


            time.sleep(2)

            if self._check_port_status(6379):
                logger.info(f"‚úÖ Redis Server iniciado correctamente (PID: {process.pid})")
                return True
            logger.error("‚ùå Redis Server no pudo iniciar")
            return False

        except Exception as e:
            logger.error(f"‚ùå Error iniciando Redis: {e}")
            return False

    def _check_port_status(self, port: int) -> bool:
        """Verifica si un puerto est√° en uso (LISTEN)"""
        try:
            import subprocess

            result = subprocess.run(
                ["lsof", "-iTCP", f":{port}", "-sTCP:LISTEN", "-n", "-P"],
                capture_output=True,
                text=True,
                timeout=5,
                check=False,
            )
            return result.returncode == 0 and result.stdout.strip() != ""
        except Exception:
            return False

    def _monitor_critical_ports(self):
        """
        Monitorea puertos cr√≠ticos y libera recursos si es necesario

        Verifica:
        - Estado de puertos (LISTEN/FREE)
        - Health de procesos (CPU, RAM, status)
        - Detecci√≥n de procesos zombie
        - Auto-fix si se exceden umbrales
        - Auto-start de servicios cr√≠ticos (Ollama, Redis)
        """
        if not self.port_monitor_enabled:
            return

        try:
            import subprocess

            logger.info("üîå Verificando puertos cr√≠ticos...")
            ports_ok = 0
            ports_issues = 0

            for port, service_name in self.critical_ports.items():
                try:
                    # Usar lsof para verificar puerto (no requiere sudo)
                    result = subprocess.run(
                        ["lsof", "-iTCP", f":{port}", "-sTCP:LISTEN", "-n", "-P"],
                        capture_output=True,
                        text=True,
                        timeout=5,
                        check=False,
                    )

                    if result.returncode == 0 and result.stdout.strip():
                        # Puerto en uso - verificar health
                        lines = result.stdout.strip().split("\n")
                        if len(lines) > 1:  # Ignorar header
                            parts = lines[1].split()
                            if len(parts) >= 2:
                                pid = int(parts[1])
                                process_name = parts[0]

                                # Verificar health del proceso
                                try:
                                    proc = psutil.Process(pid)
                                    cpu = proc.cpu_percent(interval=0.1)
                                    mem_mb = proc.memory_info().rss / (1024 * 1024)
                                    status = proc.status()

                                    # Determinar si est√° saludable
                                    is_healthy = True
                                    reason = ""

                                    if status == psutil.STATUS_ZOMBIE:
                                        is_healthy = False
                                        reason = "proceso zombie"
                                    elif cpu > 90.0:
                                        is_healthy = False
                                        reason = f"CPU alta ({cpu:.1f}%)"
                                    elif mem_mb > 2048:
                                        is_healthy = False
                                        reason = f"RAM alta ({mem_mb:.1f}MB)"

                                    # Registrar en historial
                                    self.port_health_history[port].append(is_healthy)
                                    # Mantener solo √∫ltimos 5 checks
                                    if len(self.port_health_history[port]) > 5:
                                        self.port_health_history[port].pop(0)

                                    if is_healthy:
                                        ports_ok += 1
                                        logger.info(f"   ‚úÖ Puerto {port} ({service_name}): OK")
                                        logger.info(
                                            f"      PID: {pid}, CPU: {cpu:.1f}%, RAM: {mem_mb:.1f}MB"
                                        )
                                    else:
                                        ports_issues += 1
                                        logger.warning(
                                            f"   ‚ö†Ô∏è Puerto {port} ({service_name}): {reason}"
                                        )
                                        logger.warning(f"      PID: {pid}, Proceso: {process_name}")

                                        # Contar checks consecutivos no saludables
                                        recent_checks = self.port_health_history[port]
                                        unhealthy_count = sum(1 for h in recent_checks if not h)

                                        # Si 3+ checks consecutivos fallan, tomar acci√≥n
                                        if unhealthy_count >= 3 and self.port_monitor_auto_fix:
                                            logger.error(
                                                f"   ‚ùå Puerto {port} - Umbral excedido ({unhealthy_count}/3 checks malos)"
                                            )
                                            logger.info(f"   üîß Liberando puerto {port}...")

                                            try:
                                                # Intentar terminaci√≥n graceful
                                                proc.terminate()
                                                proc.wait(timeout=10)
                                                logger.info(
                                                    f"   ‚úÖ Puerto {port} liberado (SIGTERM)"
                                                )
                                                self.port_health_history[
                                                    port
                                                ] = []  # Reset historial
                                            except psutil.TimeoutExpired:
                                                # Force kill si no responde
                                                proc.kill()
                                                logger.info(
                                                    f"   ‚úÖ Puerto {port} liberado (SIGKILL)"
                                                )
                                                self.port_health_history[port] = []
                                            except Exception as kill_err:
                                                logger.error(
                                                    f"   ‚ùå Error liberando puerto {port}: {kill_err}"
                                                )

                                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                                    logger.warning(f"   ‚ö†Ô∏è Puerto {port} ({service_name}): {e}")
                                    ports_issues += 1
                    else:
                        # Puerto libre - Auto-start si es Ollama o Redis
                        logger.info(f"   ‚ÑπÔ∏è  Puerto {port} ({service_name}): LIBRE")
                        self.port_health_history[port] = []  # Reset historial

                        # Auto-start de servicios cr√≠ticos
                        if self.port_monitor_auto_fix:
                            if port == 11434 and service_name == "Ollama":
                                logger.info(f"   üöÄ Auto-iniciando {service_name}...")
                                if self._start_ollama_service():
                                    logger.info(f"   ‚úÖ {service_name} iniciado correctamente")
                                    ports_ok += 1
                                else:
                                    logger.error(f"   ‚ùå No se pudo iniciar {service_name}")
                                    ports_issues += 1
                            elif port == 6379 and service_name == "Redis":
                                logger.info(f"   üöÄ Auto-iniciando {service_name}...")
                                if self._start_redis_service():
                                    logger.info(f"   ‚úÖ {service_name} iniciado correctamente")
                                    ports_ok += 1
                                else:
                                    logger.error(f"   ‚ùå No se pudo iniciar {service_name}")
                                    ports_issues += 1

                except subprocess.TimeoutExpired:
                    logger.warning(f"   ‚è±Ô∏è Timeout verificando puerto {port}")
                except Exception as port_err:
                    logger.warning(f"   ‚ö†Ô∏è Error verificando puerto {port}: {port_err}")

            # Resumen
            logger.info(f"üìä Resumen monitoreo: {ports_ok} OK, {ports_issues} con problemas")

        except Exception as e:
            logger.error(f"‚ùå Error en monitoreo de puertos: {e}")

    def _adjust_interval_by_load(self):
        try:
            cpu = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory().percent
            avg_load = (cpu + memory) / 2

            if avg_load < 30:
                new_interval = self.min_interval_minutes
            elif avg_load < 70:
                new_interval = self.base_interval_minutes
            else:
                new_interval = self.max_interval_minutes

            current = self.materialization_interval.total_seconds() / 60
            if abs(current - new_interval) > 0.5:
                self.materialization_interval = timedelta(minutes=new_interval)
                logger.info(f"‚öôÔ∏è Intervalo: {current:.0f} ‚Üí {new_interval:.0f} min")
        except Exception:
            logger.error(f"Error: {e}", exc_info=True)
    def start_health_monitoring(self):
        logger.info("üè• Health monitoring militar...")

        def health_loop():
            while self.running and not self.shutdown_event.is_set():
                try:
                    for name in list(self.components.keys()):
                        state = self.check_component_health(name)

                        if name in self.component_metrics:
                            self.component_metrics[name].state = state

                        if state == ComponentState.FAILED:
                            logger.warning(f"‚ö†Ô∏è {name} fall√≥")
                            self.restart_component_with_backoff(name)

                    time.sleep(30)

                except Exception as e:
                    logger.error(f"‚ùå Health monitoring: {e}")
                    time.sleep(60)

        health_thread = threading.Thread(target=health_loop, daemon=True, name="HealthMonitoring")
        health_thread.start()

        logger.info("‚úÖ Health monitoring activo")

    def cleanup(self):
        """Limpieza militar con manejo robusto de recursos"""
        logger.info("üßπ Limpieza militar...")
        try:
            if self.pid_file.exists():
                self.pid_file.unlink()
                logger.info("‚úÖ PID file eliminado")
        except Exception as e:
            logger.error(f"‚ùå Error eliminando PID file: {e}")

    def shutdown(self):
        """
        Graceful shutdown robusto sin timeout forzado.

        Orden de terminaci√≥n:
        1. Se√±alizar shutdown a todos los sistemas
        2. Detener ciclos aut√≥nomos
        3. Detener ML systems
        4. Detener componentes externos
        5. Cleanup final
        """
        logger.info("=" * 80)
        logger.info("üõë INICIANDO GRACEFUL SHUTDOWN MILITAR")
        logger.info("=" * 80)

        # 1. Se√±alizar shutdown
        logger.info("üì¢ Fase 1/5: Se√±alizando shutdown...")
        self.running = False
        self.autonomous_mode = False
        self.shutdown_event.set()
        logger.info("‚úÖ Shutdown se√±alizado")

        # 2. Detener ciclos aut√≥nomos (esperar a que terminen naturalmente)
        logger.info("üì¢ Fase 2/5: Esperando ciclos aut√≥nomos...")
        time.sleep(2)  # Dar tiempo a que terminen iteraciones actuales
        logger.info("‚úÖ Ciclos aut√≥nomos detenidos")

        # 3. Detener ML systems de forma ordenada
        logger.info("üì¢ Fase 3/5: Deteniendo ML systems...")

        if self.ml_pipeline:
            try:
                logger.info("   ‚è≥ Deteniendo ML Pipeline...")
                self.ml_pipeline.stop_perpetual_training()
                logger.info("   ‚úÖ ML Pipeline detenido")
            except Exception as e:
                logger.error(f"   ‚ùå Error deteniendo ML Pipeline: {e}")

        if self.auto_trainer:
            try:
                logger.info("   ‚è≥ Deteniendo Auto-Trainer...")
                self.auto_trainer.stop()
                logger.info("   ‚úÖ Auto-Trainer detenido")
            except Exception as e:
                logger.error(f"   ‚ùå Error deteniendo Auto-Trainer: {e}")

        # Detener Divine Protection (si necesita cleanup)
        if self.divine_protection:
            try:
                logger.info("   ‚è≥ Preservando Divine Protection state...")
                status = self.divine_protection.get_system_status()
                logger.info(f"   üìä Personas protegidas: {status['protected_persons']['total']}")
                logger.info("   ‚úÖ Divine Protection state preservado")
            except Exception as e:
                logger.error(f"   ‚ùå Error en Divine Protection cleanup: {e}")

        logger.info("‚úÖ ML systems detenidos")

        # 4. Detener componentes externos con timeout razonable
        logger.info("üì¢ Fase 4/5: Deteniendo componentes externos...")

        terminated_count = 0
        killed_count = 0

        for name, component in list(self.components.items()):
            try:
                process = component["process"]
                logger.info(f"   ‚è≥ Terminando {name}...")

                # SIGTERM primero (graceful)
                process.terminate()

                # Esperar hasta 30 segundos (tiempo razonable)
                try:
                    process.wait(timeout=30)
                    terminated_count += 1
                    logger.info(f"   ‚úÖ {name} terminado gracefully")
                except subprocess.TimeoutExpired:
                    # Si no responde en 30s, entonces SIGKILL
                    logger.warning(f"   ‚ö†Ô∏è {name} no respondi√≥ - usando SIGKILL...")
                    try:
                        process.kill()
                        process.wait(timeout=5)
                        killed_count += 1
                        logger.info(f"   ‚úÖ {name} forzado")
                    except Exception as kill_error:
                        logger.error(f"   ‚ùå Error matando {name}: {kill_error}")

            except Exception as e:
                logger.error(f"   ‚ùå Error deteniendo {name}: {e}")

        logger.info(
            f"‚úÖ Componentes detenidos ({terminated_count} graceful, {killed_count} forced)"
        )

        # 5. Shutdown executor y cleanup final
        logger.info("üì¢ Fase 5/5: Cleanup final...")

        try:
            logger.info("   ‚è≥ Deteniendo thread pool...")
            self.executor.shutdown(wait=True, cancel_futures=True)
            logger.info("   ‚úÖ Thread pool detenido")
        except Exception as e:
            logger.error(f"   ‚ùå Error deteniendo executor: {e}")

        try:
            logger.info("   ‚è≥ Restaurando configuraci√≥n de energ√≠a...")
            self.energy_manager.restore_defaults()
            logger.info("   ‚úÖ Energ√≠a restaurada")
        except Exception as e:
            logger.error(f"   ‚ùå Error restaurando energ√≠a: {e}")

        logger.info("=" * 80)
        logger.info("‚úÖ METACORTEX MILITARY DAEMON DETENIDO CORRECTAMENTE")
        logger.info("üìñ 'The Lord watch between me and thee' - Genesis 31:49")
        logger.info("=" * 80)

        sys.exit(0)

    def _lazy_load_heavy_components(self):
        """Carga lazy de componentes pesados en background para no bloquear __init__()"""
        logger.info("üîÑ Iniciando carga lazy de componentes pesados en background...")
        
        # Neural Network
        if not self._neural_network_loaded:
            def load_neural_network():
                try:
                    from neural_symbiotic_network import get_neural_network
                    self.neural_network = get_neural_network()
                    if self.neural_network:
                        self.neural_network.register_module("military_daemon", self)
                        logger.info("‚úÖ Neural Network cargada")
                        self._neural_network_loaded = True
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Neural Network no disponible: {e}")
            
            self.executor.submit(load_neural_network)
        
        # Cognitive Agent Pool
        if not self._agent_pool_loaded:
            def load_agent_pool():
                try:
                    from cognitive_agent_pool import get_cognitive_agent_pool
                    self.agent_pool = get_cognitive_agent_pool()
                    logger.info("‚úÖ Cognitive Agent Pool cargado")
                    self.agent_pool.preload_async()
                    self._agent_pool_loaded = True
                except Exception as e:
                    logger.error(f"‚ùå Agent Pool: {e}")
            
            self.executor.submit(load_agent_pool)
        
        # ML Pipeline
        if not self._ml_pipeline_loaded:
            def load_ml_pipeline():
                try:
                    from ml_pipeline import get_ml_pipeline
                    self.ml_pipeline = get_ml_pipeline(
                        enable_perpetual_mode=True,
                        enable_continuous_learning=True
                    )
                    logger.info("‚úÖ ML Pipeline cargado")
                    self._ml_pipeline_loaded = True
                except Exception as e:
                    logger.error(f"‚ùå ML Pipeline: {e}")
            
            self.executor.submit(load_ml_pipeline)
        
        # Distributed Storage Manager
        if not self._distributed_storage_loaded:
            def load_distributed_storage():
                try:
                    from distributed_storage_manager_v2 import DistributedStorageManagerV2
                    
                    self.distributed_storage = DistributedStorageManagerV2(
                        config_file="storage_config_v2.json",
                        auto_detect_volumes=True,
                        min_disk_size_tb=3.0,
                        disk_usage_threshold=85.0,
                        enable_auto_migration=True
                    )
                    
                    logger.info("üî• Ejecutando setup inicial de almacenamiento distribuido...")
                    self.distributed_storage.initialize_external_storage()
                    self.distributed_storage.create_symlinks_all_volumes()
                    
                    status = self.distributed_storage.get_storage_status()
                    logger.info(f"‚úÖ Distributed Storage Manager cargado")
                    logger.info(f"   Vol√∫menes: {status['total_volumes']}, Espacio: {status['total_space_tb']:.2f} TB")
                    
                    self._distributed_storage_loaded = True
                    self.storage_initial_setup_done = True
                except Exception as e:
                    logger.error(f"‚ùå Distributed Storage Manager: {e}")
            
            self.executor.submit(load_distributed_storage)
        
        # Divine Protection System
        if not self._divine_protection_loaded:
            def load_divine_protection():
                try:
                    from metacortex_sinaptico.bdi import BDISystem
                    
                    db = MetacortexDB()
                    bdi_system = BDISystem()
                    planner = MultiHorizonPlanner()
                    memory_system = MemorySystem(db=db)
                    learning_system = StructuralLearning()
                    
                    self.divine_protection = create_divine_protection_system(
                        db=db,
                        bdi_system=bdi_system,
                        planner=planner,
                        memory=memory_system,
                        learning=learning_system,
                    )
                    
                    logger.info("‚úÖ Divine Protection System cargado")
                    logger.info(f"   Refugios: {len(self.divine_protection.safe_havens)}, Escrituras: {len(self.divine_protection.divine_wisdom_db)}")
                    self._divine_protection_loaded = True
                except Exception as e:
                    logger.error(f"‚ùå Divine Protection System: {e}")
            
            self.executor.submit(load_divine_protection)
        
        logger.info("‚úÖ Carga lazy iniciada en background (componentes se cargar√°n progresivamente)")

    def run(self):
        logger.info("üîÆ EJECUTANDO METACORTEX MILITARY DAEMON v4.0...")

        # NUEVO: Lazy loading de componentes pesados EN BACKGROUND
        self._lazy_load_heavy_components()

        self.energy_manager.prevent_disk_sleep()
        self.start_all_components()
        self.start_autonomous_mode()
        self.start_health_monitoring()

        logger.info("=" * 80)
        logger.info("‚úÖ METACORTEX MILITARY DAEMON OPERATIVO")
        logger.info("‚öîÔ∏è MODO MILITAR ACTIVADO")
        logger.info("ü§ñ MODO AUT√ìNOMO: ACTIVO")
        logger.info("üõ°Ô∏è CIRCUIT BREAKERS: ACTIVOS")
        logger.info("=" * 80)

        try:
            while self.running:
                time.sleep(1)
        except KeyboardInterrupt:
            self.shutdown()


class MilitaryEnergyManager:
    """Energy Manager Militar"""

    def __init__(self):
        logger.info("‚ö° Military Energy Manager inicializado")

    def prevent_disk_sleep(self):
        logger.info("‚ÑπÔ∏è Energ√≠a delegada a caffeinate")

    def allow_disk_sleep(self, duration: int = 600):
        pass  # TODO: Implementar control de sleep de disco

    def restore_defaults(self):
        pass  # TODO: Restaurar configuraci√≥n por defecto


def main():

    lock = ensure_single_instance(".metacortex_daemon_military.lock")

    logger.info("=" * 80)
    logger.info("‚öîÔ∏è METACORTEX DAEMON v4.0 - MILITARY GRADE")
    logger.info("=" * 80)

    try:
        daemon = MetacortexMilitaryDaemon()
        daemon.run()
    finally:
        lock.release()


if __name__ == "__main__":
    main()