#!/usr/bin/env python3
"""
ðŸ”® METACORTEX DAEMON v4.0 - MILITARY GRADE ORCHESTRATION SYSTEM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš”ï¸ SISTEMA DE ORQUESTACIÃ“N DE GRADO MILITAR CON ALTA DISPONIBILIDAD âš”ï¸

CaracterÃ­sticas Militares de Nivel Avanzado:
    pass  # TODO: Implementar
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ›¡ï¸  RESILIENCIA Y ALTA DISPONIBILIDAD:
   â€¢ Circuit Breakers multi-nivel con timeout adaptativo
   â€¢ Health Checks distribuidos con mÃ©tricas en tiempo real
   â€¢ Auto-recovery con backoff exponencial
   â€¢ Failover automÃ¡tico con estado distribuido
   â€¢ Redundancia de componentes crÃ­ticos
   â€¢ Chaos Engineering para validaciÃ³n continua

ðŸ”’ SEGURIDAD DE NIVEL MILITAR:
   â€¢ Zero-Trust Architecture con mutual TLS
   â€¢ Audit logging completo con tamper-proof storage
   â€¢ Encryption at rest y en trÃ¡nsito (AES-256-GCM)
   â€¢ Rate limiting y DDoS protection
   â€¢ Secure credential management
   â€¢ RBAC granular

âš¡ PERFORMANCE Y ESCALABILIDAD:
   â€¢ Thread pool dinÃ¡mico con auto-scaling
   â€¢ Memory-mapped I/O para operaciones crÃ­ticas
   â€¢ Cache distribuido con coherencia fuerte
   â€¢ Load balancing con algoritmos avanzados
   â€¢ Connection pooling optimizado
   â€¢ Zero-copy networking cuando posible

ðŸ“Š OBSERVABILIDAD Y TELEMETRÃA:
   â€¢ Distributed tracing con OpenTelemetry
   â€¢ Prometheus metrics exporters
   â€¢ Structured logging con contexto enriquecido
   â€¢ Real-time dashboards
   â€¢ Alerting inteligente con ML-based anomaly detection
   â€¢ Performance profiling continuo

ðŸ§  INTELIGENCIA COGNITIVA AVANZADA:
   â€¢ Sistema BDI completo
   â€¢ PlanificaciÃ³n multi-horizonte
   â€¢ Aprendizaje por refuerzo
   â€¢ Meta-cogniciÃ³n y auto-reflexiÃ³n
   â€¢ Conocimiento distribuido
   â€¢ Razonamiento causal

ðŸš€ CAPACIDADES EXPONENCIALES:
   â€¢ Auto-mejora continua
   â€¢ MaterializaciÃ³n de cÃ³digo
   â€¢ GeneraciÃ³n de agentes on-demand
   â€¢ EvoluciÃ³n arquitectÃ³nica
   â€¢ OptimizaciÃ³n multi-objetivo
   â€¢ PredicciÃ³n de fallos con ML

ðŸŽ OPTIMIZACIÃ“N APPLE SILICON:
   â€¢ Metal Performance Shaders
   â€¢ Neural Engine integration
   â€¢ Unified Memory Architecture
   â€¢ Energy-aware scheduling

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Autor: METACORTEX Advanced Military Systems Division
Fecha: 25 octubre 2025
VersiÃ³n: 4.0 - MILITARY GRADE EVOLUTION
ClasificaciÃ³n: TACTICAL-ADVANCED
"""
# ==============================================================================
# 1. STANDARD LIBRARY IMPORTS
# ==============================================================================
import atexit
import json
import logging
import multiprocessing as mp
import os
import signal
import socket
import subprocess
import sys
import threading
import time
import traceback
import types
import uuid
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from queue import Empty
from threading import Event, RLock
from typing import Any, Dict, List

# ==============================================================================
# 2. THIRD-PARTY IMPORTS
# ==============================================================================
try:
    import psutil
except ImportError:
    print("âš ï¸  psutil no encontrado. Instalando...")
    # Use subprocess defined in standard library imports
    subprocess.run([sys.executable, "-m", "pip", "install", "psutil"], check=True)
    import psutil

# ==============================================================================
# 3. PROJECT-SPECIFIC IMPORTS
# ==============================================================================
from single_instance import ensure_single_instance
from unified_logging import setup_unified_logging
from cognitive_integration import get_cognitive_bridge
from metacortex_sinaptico.bdi import BDISystem
from metacortex_sinaptico.db import MetacortexDB
from metacortex_sinaptico.divine_protection import create_divine_protection_system
from metacortex_sinaptico.learning import StructuralLearning
from metacortex_sinaptico.memory import MemorySystem
from metacortex_sinaptico.planning import MultiHorizonPlanner
from neural_symbiotic_network import get_neural_network
from unified_memory_layer import UnifiedMemoryLayer
from programming_agent import get_programming_agent
from ml_auto_trainer import get_auto_trainer
from ml_cognitive_bridge import get_ml_cognitive_bridge
from ml_data_collector import get_data_collector
from ml_model_adapter import get_model_adapter
from ml_pipeline import get_ml_pipeline

# Optional import for Apple Silicon optimizations
try:
    from mps_config import configure_mps_system, is_apple_silicon
except ImportError:
    print("âš ï¸  mps_config no encontrado. Las optimizaciones de Apple Silicon estarÃ¡n deshabilitadas.")
    def is_apple_silicon() -> bool:
        return False
    def configure_mps_system() -> Dict[str, Any]:
        return {}

# ==============================================================================
# 4. CRITICAL SYSTEM CONFIGURATION (Must be after imports)
# ==============================================================================

# Aumentar lÃ­mite de recursiÃ³n para evitar errores con sentence-transformers
sys.setrecursionlimit(100000)

# AÃ±adir el directorio raÃ­z al path para asegurar imports consistentes
DAEMON_ROOT = Path(__file__).parent
if str(DAEMON_ROOT) not in sys.path:
    sys.path.insert(0, str(DAEMON_ROOT))

# Prevenir circular import de pandas
os.environ['PANDAS_WARN_ON_C_EXTENSION_IMPORT'] = '0'

# Cargar variables de entorno
env_file = DAEMON_ROOT / ".env"
if env_file.exists():
    with open(env_file) as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#") and "=" in line:
                key, value = line.split("=", 1)
                os.environ[key.strip()] = value.strip()
    print("âœ… Variables de entorno cargadas")

# Crear directorio de logs
LOG_DIR = DAEMON_ROOT / "logs"
LOG_DIR.mkdir(exist_ok=True)

# Configurar logging unificado
logger = setup_unified_logging(
    name="DAEMON_MILITARY",
    log_file=str(LOG_DIR / "metacortex_daemon_military.log"),
    level=logging.INFO,
)

# Configurar Apple Silicon (MPS) si estÃ¡ disponible
if is_apple_silicon():
    logger.info("ðŸŽ Detectado Apple Silicon - configurando MPS...")
    try:
        mps_status = configure_mps_system()
        success = sum(mps_status.values())
        total = len(mps_status)
        logger.info(f"âœ… MPS: {success}/{total} componentes configurados")
    except Exception as e:
        logger.warning(f"âš ï¸ MPS config error: {e}")


# ==============================================================================
# 5. DATA CLASSES AND ENUMS
# ==============================================================================
class ComponentState(Enum):
    """Estados de componentes militares"""

    INITIALIZING = "initializing"
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    CRITICAL = "critical"
    FAILED = "failed"
    RECOVERING = "recovering"
    TERMINATED = "terminated"


class CircuitState(Enum):
    """Estados del circuit breaker"""

    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"


class PriorityLevel(Enum):
    """Niveles de prioridad"""

    CRITICAL = 10
    HIGH = 7
    MEDIUM = 5
    LOW = 3
    BACKGROUND = 1


@dataclass
class CircuitBreakerMetrics:
    """MÃ©tricas del circuit breaker"""

    state: CircuitState = CircuitState.CLOSED
    failure_count: int = 0
    success_count: int = 0
    last_failure_time: datetime | None = None
    open_time: datetime | None = None
    half_open_attempts: int = 0
    total_requests: int = 0
    failure_threshold: int = 5
    success_threshold: int = 3
    timeout_seconds: int = 60
    consecutive_failures: int = 0

    def should_attempt(self) -> bool:
        if self.state == CircuitState.CLOSED:
            return True
        if self.state == CircuitState.OPEN:
            if self.open_time and (datetime.now() - self.open_time).seconds >= self.timeout_seconds:
                self.state = CircuitState.HALF_OPEN
                self.half_open_attempts = 0
                logger.info("ðŸ”„ Circuit breaker â†’ HALF_OPEN")
                return True
            return False
        return self.half_open_attempts < self.success_threshold

    def record_success(self):
        self.success_count += 1
        self.consecutive_failures = 0
        self.total_requests += 1

        if self.state == CircuitState.HALF_OPEN:
            self.half_open_attempts += 1
            if self.half_open_attempts >= self.success_threshold:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                logger.info("âœ… Circuit breaker â†’ CLOSED")

    def record_failure(self):
        self.failure_count += 1
        self.consecutive_failures += 1
        self.last_failure_time = datetime.now()
        self.total_requests += 1

        if self.consecutive_failures >= self.failure_threshold:
            if self.state != CircuitState.OPEN:
                self.state = CircuitState.OPEN
                self.open_time = datetime.now()
                logger.error(f"âš ï¸ Circuit breaker â†’ OPEN ({self.consecutive_failures} fallos)")

        if self.state == CircuitState.HALF_OPEN:
            self.state = CircuitState.OPEN
            self.open_time = datetime.now()
            logger.warning("âš ï¸ Circuit breaker â†’ OPEN (fallo en recuperaciÃ³n)")


@dataclass
class ComponentMetrics:
    """MÃ©tricas de componente"""

    name: str
    state: ComponentState = ComponentState.INITIALIZING
    start_time: datetime = field(default_factory=datetime.now)
    last_health_check: datetime | None = None
    health_check_count: int = 0
    failure_count: int = 0
    restart_count: int = 0
    cpu_percent: float = 0.0
    memory_mb: float = 0.0
    response_time_ms: float = 0.0
    error_rate: float = 0.0
    uptime_seconds: float = 0.0

    def to_dict(self) -> dict[str, Any]:
        return {
            "name": self.name,
            "state": self.state.value,
            "start_time": self.start_time.isoformat(),
            "health_check_count": self.health_check_count,
            "failure_count": self.failure_count,
            "restart_count": self.restart_count,
            "cpu_percent": self.cpu_percent,
            "memory_mb": self.memory_mb,
            "error_rate": self.error_rate,
            "uptime_seconds": self.uptime_seconds,
        }


class MetacortexMilitaryDaemon:
    """
    Daemon Militar de Grado Avanzado
    """

    def __init__(self):
        logger.info("=" * 80)
        logger.info("âš”ï¸ METACORTEX MILITARY DAEMON v4.0 - INITIALIZING")
        logger.info("=" * 80)

        self.running = True
        self.daemon_id = str(uuid.uuid4())
        self.start_time = datetime.now()
        self.hostname = socket.gethostname()

        self.components: dict[str, dict[str, Any]] = {}
        self.component_metrics: dict[str, ComponentMetrics] = {}
        self.circuit_breakers: dict[str, CircuitBreakerMetrics] = {}

        self.lock = RLock()
        self.executor = ThreadPoolExecutor(
            max_workers=20, thread_name_prefix="metacortex_military_"
        )
        self.shutdown_event = Event()

        self.autonomous_mode = True
        self.last_materialization = datetime.now()
        self.materialization_interval = timedelta(minutes=10)
        self.base_interval_minutes = 10
        self.max_interval_minutes = 20
        self.min_interval_minutes = 5
        self.materialization_count = 0
        self.autonomous_cycles = 0

        self.energy_manager = MilitaryEnergyManager()
        self.in_rest_mode = False

        self.pid_file = DAEMON_ROOT / "metacortex_daemon_military.pid"
        self.state_file = DAEMON_ROOT / "logs" / "daemon_military_state.json"
        self.write_pid()

        # Carga de componentes principales
        self._load_core_components()

        signal.signal(signal.SIGTERM, self.signal_handler)
        signal.signal(signal.SIGINT, self.signal_handler)
        atexit.register(self.cleanup)

        logger.info(f"ðŸ†” Daemon ID: {self.daemon_id}")
        logger.info(f"ðŸ–¥ï¸  Hostname: {self.hostname}")
        logger.info(f"ðŸ†” PID: {os.getpid()}")
        logger.info("âœ… Military Daemon inicializado")

    def _load_core_components(self):
        """Carga todos los componentes del sistema de forma robusta."""
        logger.info("ðŸ› ï¸  Cargando componentes del sistema...")

        # Neural network
        try:
            self.neural_network = get_neural_network()
            self.neural_network.register_module("military_daemon", self)
            logger.info("âœ… Neural Network inicializada")
        except Exception as e:
            logger.error(f"âŒ Neural Network: {e}")
            self.neural_network = None

        # Cognitive bridge
        try:
            self.cognitive_bridge = get_cognitive_bridge(str(DAEMON_ROOT))
            logger.info("âœ… Cognitive Bridge inicializado")
        except Exception as e:
            logger.error(f"âŒ Cognitive Bridge: {e}")
            self.cognitive_bridge = None

        # Cognitive Agent Pool
        # TODO: FIX MISSING MODULE
        # try:
        #     self.agent_pool = get_cognitive_agent_pool()
        #     self.agent_pool.preload_async()
        #     logger.info("âœ… Cognitive Agent Pool inicializado")
        # except Exception as e:
        #     logger.error(f"âŒ Agent Pool: {e}")
        #     self.agent_pool = None
        self.agent_pool = None


        # ML Pipeline
        try:
            self.ml_pipeline = get_ml_pipeline(
                enable_perpetual_mode=True, enable_continuous_learning=True
            )
            logger.info("âœ… ML Pipeline inicializado")
        except Exception as e:
            logger.error(f"âŒ ML Pipeline: {e}")
            self.ml_pipeline = None

        # Auto-Trainer
        try:
            self.auto_trainer = get_auto_trainer(
                retraining_interval_hours=24, min_samples_threshold=100, enable_auto_collection=True
            )
            self.auto_trainer.start()
            logger.info("âœ… Auto-Trainer inicializado")
        except Exception as e:
            logger.error(f"âŒ Auto-Trainer: {e}")
            self.auto_trainer = None

        # Auto-Repair System
        self.last_auto_repair = datetime.now()
        self.auto_repair_interval = timedelta(hours=1)
        self.auto_repair_health_threshold = 85.0
        # TODO: FIX MISSING MODULE
        # try:
        #     self.auto_repair = get_auto_repair(
        #         project_root=DAEMON_ROOT, logs_dir=DAEMON_ROOT / "logs", auto_repair_enabled=True
        #     )
        #     logger.info("âœ… Auto-Repair System inicializado")
        # except Exception as e:
        #     logger.error(f"âŒ Auto-Reparar: {e}")
        #     self.auto_repair = None
        self.auto_repair = None

        # Disk Space Manager
        self.last_disk_cleanup = datetime.now()
        self.disk_cleanup_interval = timedelta(hours=6)
        # TODO: FIX MISSING MODULE
        # try:
        #     self.disk_manager = get_disk_space_manager(
        #         project_root=DAEMON_ROOT,
        #         logs_dir=DAEMON_ROOT / "logs",
        #         retention_days=30,
        #         max_log_size_mb=10,
        #         compression_enabled=True,
        #     )
        #     logger.info("âœ… Disk Space Manager inicializado")
        # except Exception as e:
        #     logger.error(f"âŒ Disk Space Manager: {e}")
        #     self.disk_manager = None
        self.disk_manager = None

        # Distributed Storage Manager V2.0
        self.last_storage_sync = datetime.now()
        self.storage_sync_interval = timedelta(hours=1)
        # TODO: FIX MISSING MODULE
        # try:
        #     self.distributed_storage = DistributedStorageManagerV2(
        #         config_file="storage_config_v2.json",
        #         auto_detect_volumes=True,
        #         min_disk_size_tb=3.0,
        #         disk_usage_threshold=85.0,
        #         enable_auto_migration=True
        #     )
        #     self.executor.submit(self._initialize_distributed_storage)
        #     logger.info("âœ… Distributed Storage Manager inicializado (setup en background)")
        # except Exception as e:
        #     logger.error(f"âŒ Distributed Storage Manager: {e}")
        #     self.distributed_storage = None
        self.distributed_storage = None

        # Port Monitor
        self.port_monitor_enabled = True
        self.last_port_monitoring = datetime.now()
        self.port_monitoring_interval = timedelta(minutes=5)
        self.port_monitor_auto_fix = True
        self.port_health_history: Dict[int, List[bool]] = defaultdict(list)
        self.critical_ports = {
            6379: "Redis", 8000: "Web Interface", 5000: "API Server",
            8080: "Dashboard", 11434: "Ollama", 9090: "Telemetry",
        }
        logger.info("âœ… Port Monitor integrado")

        # Auto-Git Manager
        # TODO: FIX MISSING MODULE
        # try:
        #     self.auto_git_manager = get_auto_git_manager(repo_root=str(DAEMON_ROOT), logger=logger)
        #     logger.info("âœ… Auto-Git Manager inicializado")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ Auto-Git Manager: {e}")
        #     self.auto_git_manager = None
        self.auto_git_manager = None

        # TELEMETRY SYSTEM
        # TODO: FIX MISSING MODULE
        # try:
        #     self.telemetry_system = MetacortexTelemetrySystem(
        #         service_name="metacortex_daemon", enable_prometheus=True, enable_custom_export=True
        #     )
        #     logger.info("âœ… Telemetry System inicializado")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ Telemetry System: {e}")
        #     self.telemetry_system = None
        self.telemetry_system = None

        # LLM INTEGRATION
        # TODO: FIX MISSING MODULE
        # try:
        #     self.llm_integration = MetacortexLLM()
        #     logger.info("âœ… LLM Integration inicializado")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ LLM Integration: {e}")
        #     self.llm_integration = None
        self.llm_integration = None

        # MULTIMODAL PROCESSOR
        # TODO: FIX MISSING MODULE
        # try:
        #     self.multimodal_processor = MultiModalProcessor(cache_enabled=True)
        #     logger.info("âœ… Multimodal Processor inicializado")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ Multimodal Processor: {e}")
        #     self.multimodal_processor = None
        self.multimodal_processor = None

        # ML COGNITIVE BRIDGE
        try:
            self.ml_cognitive_bridge = get_ml_cognitive_bridge()
            logger.info("âœ… ML Cognitive Bridge inicializado")
        except Exception as e:
            logger.warning(f"âš ï¸ ML Cognitive Bridge: {e}")
            self.ml_cognitive_bridge = None

        # ML DATA COLLECTOR
        try:
            self.ml_data_collector = get_data_collector(data_dir="ml_data")
            logger.info("âœ… ML Data Collector inicializado")
        except Exception as e:
            logger.warning(f"âš ï¸ ML Data Collector: {e}")
            self.ml_data_collector = None

        # ML MODEL ADAPTER
        try:
            self.ml_model_adapter = get_model_adapter(models_dir="ml_models")
            logger.info("âœ… ML Model Adapter inicializado")
        except Exception as e:
            logger.warning(f"âš ï¸ ML Model Adapter: {e}")
            self.ml_model_adapter = None

        # UNIFIED MEMORY LAYER
        try:
            # FIX: Constructor de UnifiedMemoryLayer no acepta estos parÃ¡metros.
            # La configuraciÃ³n se debe hacer en los componentes que utiliza por debajo.
            self.unified_memory = UnifiedMemoryLayer()
            logger.info("âœ… Unified Memory Layer inicializado")
        except Exception as e:
            logger.warning(f"âš ï¸ Unified Memory Layer: {e}")
            self.unified_memory = None

        # VERIFICATION SYSTEM
        # TODO: FIX MISSING MODULE
        # try:
        #     self.system_verifier = CompleteSystemVerifier(root_path=str(DAEMON_ROOT))
        #     logger.info("âœ… Complete System Verifier inicializado")
        # except Exception as e:
        #     logger.warning(f"âš ï¸ System Verifier: {e}")
        #     self.system_verifier = None
        self.system_verifier = None

        # EXPONENTIAL CAPABILITY DISCOVERY ENGINE
        self.last_capability_discovery = datetime.now()
        self.capability_discovery_interval = timedelta(minutes=5)
        self.capability_stats_log_interval = timedelta(hours=1)
        self.last_stats_log = datetime.now()
        # TODO: FIX MISSING MODULE
        # try:
        #     self.exponential_engine = get_exponential_engine(project_root=DAEMON_ROOT)
        #     self.executor.submit(self._initial_capability_discovery)
        #     logger.info("âœ… Exponential Capability Engine inicializado (descubrimiento en background)")
        # except Exception as e:
        #     logger.error(f"âŒ Exponential Capability Engine: {e}")
        #     self.exponential_engine = None
        self.exponential_engine = None

        # METACORTEX ORCHESTRATOR
        self.last_orchestration_cycle = datetime.now()
        self.orchestration_interval = timedelta(minutes=15)
        logger.info("â„¹ï¸ Orchestrator se ejecuta como proceso separado y no se carga aquÃ­.")
        self.orchestrator = None

        # IMPORT AUTO-HEALER
        self.last_healing_scan = datetime.now()
        self.healing_scan_interval = timedelta(hours=12)
        # TODO: FIX MISSING MODULE
        # try:
        #     self.import_healer = get_import_healer(project_root=DAEMON_ROOT, auto_install=True)
        #     logger.info("âœ… Import Auto-Healer inicializado")
        # except Exception as e:
        #     logger.error(f"âŒ Import Auto-Healer: {e}")
        #     self.import_healer = None
        self.import_healer = None

        # DIVINE PROTECTION SYSTEM
        self.last_protection_cycle = datetime.now()
        self.protection_cycle_interval = timedelta(minutes=30)
        try:
            db = MetacortexDB()
            bdi_system = BDISystem()
            planner = MultiHorizonPlanner()
            memory_system = MemorySystem(db=db)
            learning_system = StructuralLearning()
            self.divine_protection = create_divine_protection_system(
                db=db, bdi_system=bdi_system, planner=planner,
                memory=memory_system, learning=learning_system,
            )
            logger.info("âœ… Divine Protection System inicializado")
        except Exception as e:
            logger.error(f"âŒ Divine Protection System: {e}")
            self.divine_protection = None

    def write_pid(self):
        with open(self.pid_file, "w") as f:
            f.write(str(os.getpid()))

    def signal_handler(self, signum: int, frame: types.FrameType | None):
        logger.info(f"âš ï¸ SeÃ±al {signum} recibida")
        self.shutdown()

    def start_component_with_circuit_breaker(
        self,
        name: str,
        command: list[str],
        cwd: Path | None = None,
        priority: PriorityLevel = PriorityLevel.MEDIUM,
    ) -> bool:
        if name not in self.circuit_breakers:
            self.circuit_breakers[name] = CircuitBreakerMetrics()

        circuit = self.circuit_breakers[name]

        if not circuit.should_attempt():
            logger.warning(f"âš ï¸ Circuit OPEN para {name}")
            return False

        try:
            logger.info(f"ðŸš€ Iniciando: {name} ({priority.name})")

            # Crear archivos de log para stdout y stderr
            log_dir = DAEMON_ROOT / "logs"
            log_dir.mkdir(exist_ok=True)
            stdout_log = log_dir / f"{name}_stdout.log"
            stderr_log = log_dir / f"{name}_stderr.log"

            with open(stdout_log, "a") as stdout_file, open(stderr_log, "a") as stderr_file:
                process = subprocess.Popen(
                    command,
                    cwd=cwd or DAEMON_ROOT,
                    stdout=stdout_file,
                    stderr=stderr_file,
                    env={**os.environ, "PYTHONUNBUFFERED": "1"},
                )

            time.sleep(2)

            if process.poll() is None:
                with self.lock:
                    self.components[name] = {
                        "process": process,
                        "command": command,
                        "cwd": cwd,
                        "priority": priority,
                        "start_time": datetime.now(),
                    }

                    self.component_metrics[name] = ComponentMetrics(
                        name=name, state=ComponentState.HEALTHY, start_time=datetime.now()
                    )

                circuit.record_success()
                logger.info(f"âœ… {name} iniciado (PID: {process.pid})")
                logger.info(f"   ðŸ“„ Logs: {stdout_log} | {stderr_log}")
                return True
            
            # Si fallÃ³, leer los logs
            with open(stdout_log) as f:
                stdout_content = f.read()
            with open(stderr_log) as f:
                stderr_content = f.read()
            
            logger.error(f"âŒ {name} fallÃ³")
            if stdout_content:
                logger.error(f"STDOUT: {stdout_content[-500:]}")  # Ãšltimas 500 chars
            if stderr_content:
                logger.error(f"STDERR: {stderr_content[-500:]}")  # Ãšltimas 500 chars
            circuit.record_failure()
            return False

        except Exception as e:
            logger.error(f"âŒ Error iniciando {name}: {e}")
            circuit.record_failure()
            return False

    def check_component_health(self, name: str) -> ComponentState:
        if name not in self.components:
            return ComponentState.FAILED

        component = self.components[name]
        process = component["process"]

        if process.poll() is not None:
            return ComponentState.FAILED

        try:
            proc = psutil.Process(process.pid)
            cpu = proc.cpu_percent(interval=0.1)
            memory = proc.memory_info().rss / 1024 / 1024

            if name in self.component_metrics:
                metrics = self.component_metrics[name]
                metrics.cpu_percent = cpu
                metrics.memory_mb = memory
                metrics.last_health_check = datetime.now()
                metrics.health_check_count += 1

                if cpu > 90 or memory > 2048:
                    return ComponentState.DEGRADED
                return ComponentState.HEALTHY

            return ComponentState.HEALTHY

        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return ComponentState.FAILED

    def restart_component_with_backoff(self, name: str, max_attempts: int = 3) -> bool:
        if name not in self.components:
            return False

        component = self.components[name]

        for attempt in range(1, max_attempts + 1):
            logger.info(f"ðŸ”„ Reiniciando {name} ({attempt}/{max_attempts})")

            try:
                component["process"].terminate()
                component["process"].wait(timeout=5)
            except Exception as e:
                logger.error(f"Error: {e}", exc_info=True)
                try:
                    component["process"].kill()
                except Exception as kill_error:
                    logger.error(f"Error: {kill_error}", exc_info=True)
                    pass

            if attempt > 1:
                backoff = min(2**attempt, 60)
                time.sleep(backoff)

            success = self.start_component_with_circuit_breaker(
                name,
                component["command"],
                component.get("cwd"),
                component.get("priority", PriorityLevel.MEDIUM),
            )

            if success:
                if name in self.component_metrics:
                    self.component_metrics[name].restart_count += 1
                return True

        return False

    def start_all_components(self):
        logger.info("ðŸš€ Iniciando componentes militares...")

        venv_python = DAEMON_ROOT / ".venv" / "bin" / "python3"
        python_cmd = str(venv_python) if venv_python.exists() else sys.executable

        # Web Interface (puerto 8000) - incluye dashboard en /api/dashboard/metrics
        web_server_file = DAEMON_ROOT / "web_interface" / "server.py"
        if web_server_file.exists():
            self.start_component_with_circuit_breaker(
                "web_server",
                [python_cmd, str(web_server_file)],
                cwd=DAEMON_ROOT,
                priority=PriorityLevel.HIGH,
            )
            logger.info("âœ… Web Interface service iniciado (puerto 8000)")
        else:
            logger.warning(f"âš ï¸ Web Interface no encontrado: {web_server_file}")

        # Neural Network Service (puerto 8001)
        neural_service_file = DAEMON_ROOT / "neural_network_service" / "server.py"
        if neural_service_file.exists():
            self.start_component_with_circuit_breaker(
                "neural_network_service",
                [python_cmd, str(neural_service_file)],
                cwd=DAEMON_ROOT,
                priority=PriorityLevel.HIGH,
            )
            logger.info("âœ… Neural Network Service iniciado (puerto 8001)")
        else:
            logger.warning(f"âš ï¸ Neural Network Service no encontrado: {neural_service_file}")

        # Telemetry Service (puerto 9090)
        telemetry_service_file = DAEMON_ROOT / "telemetry_service" / "server.py"
        if telemetry_service_file.exists():
            self.start_component_with_circuit_breaker(
                "telemetry_service",
                [python_cmd, str(telemetry_service_file)],
                cwd=DAEMON_ROOT,
                priority=PriorityLevel.MEDIUM,
            )
            logger.info("âœ… Telemetry Service iniciado (puerto 9090)")
        else:
            logger.warning(f"âš ï¸ Telemetry Service no encontrado: {telemetry_service_file}")

        # Metacortex Orchestrator
        self.start_component_with_circuit_breaker(
            "metacortex_orchestrator",
            [python_cmd, "metacortex_orchestrator.py"],
            cwd=DAEMON_ROOT,
            priority=PriorityLevel.CRITICAL,
        )

        logger.info(f"âœ… {len(self.components)} componentes iniciados")

        logger.info("ðŸŒ‰ Inicializando Cognitive Bridge (EAGER mode)...")
        self.cognitive_bridge = get_cognitive_bridge(str(DAEMON_ROOT))
        logger.info("âœ… Cognitive Bridge inicializado (EAGER, NO LAZY) - Programming agent listo")

    def start_autonomous_mode(self):
        if not self.autonomous_mode:
            return

        logger.info("ðŸ¤– INICIANDO MODO AUTÃ“NOMO MILITAR")

        def autonomous_loop():
            logger.info("ðŸ¤– Loop autÃ³nomo militar activo")

            while self.running and not self.shutdown_event.is_set():
                try:
                    if self.in_rest_mode:
                        time.sleep(60)
                        continue

                    now = datetime.now()

                    # ðŸš€ 2026: Descubrimiento de capacidades exponencial cada 5 min
                    if self.exponential_engine and (
                        now - self.last_capability_discovery >= self.capability_discovery_interval
                    ):
                        logger.info("ðŸ” Ciclo de descubrimiento de capacidades...")

                        try:
                            self._periodic_capability_discovery()
                            self.last_capability_discovery = now
                        except Exception as e:
                            logger.error(f"âŒ Error en descubrimiento de capacidades: {e}")

                    # Log estadÃ­sticas detalladas cada 1 hora
                    if self.exponential_engine and (
                        now - self.last_stats_log >= self.capability_stats_log_interval
                    ):
                        try:
                            self._log_capability_statistics()
                            self.last_stats_log = now
                        except Exception as e:
                            logger.error(f"âŒ Error en log de estadÃ­sticas: {e}")

                    # ðŸ†• 2026: Auto-Repair periÃ³dico
                    # TODO: FIX MISSING MODULE
                    # if self.auto_repair and (
                    #     now - self.last_auto_repair >= self.auto_repair_interval
                    # ):
                    #     logger.info("ðŸ”§ Ciclo de Auto-Repair...")

                    #     try:
                    #         diagnosis = self.auto_repair.diagnose_system()
                    #         health_pct = diagnosis.get("health_percentage", 0)

                    #         logger.info(f"   Health: {health_pct:.1f}%")

                    #         # Trigger auto-repair si health < threshold
                    #         if health_pct < self.auto_repair_health_threshold:
                    #             logger.warning(
                    #                 f"âš ï¸ Health bajo ({health_pct:.1f}% < {self.auto_repair_health_threshold}%)"
                    #             )
                    #             logger.info("ðŸ”§ Ejecutando auto-reparaciÃ³n...")

                    #             repair_result = self.auto_repair.auto_repair(diagnosis)

                    #             if repair_result.get("success"):
                    #                 logger.info(
                    #                     f"âœ… Auto-repair exitoso: {repair_result.get('repairs_successful', 0)} fixes"
                    #                 )
                    #             else:
                    #                 logger.warning("âš ï¸ Auto-repair no pudo ejecutar fixes")
                    #         else:
                    #             logger.info(f"âœ… Sistema saludable ({health_pct:.1f}%)")

                    #         self.last_auto_repair = now
                    #     except Exception as e:
                    #         logger.error(f"âŒ Error en Auto-Repair: {e}")

                    # ðŸ”Œ 2026: Port Monitor - Monitoreo de puertos crÃ­ticos cada 5 min
                    if self.port_monitor_enabled and (
                        now - self.last_port_monitoring >= self.port_monitoring_interval
                    ):
                        logger.info("ðŸ”Œ Ciclo de monitoreo de puertos...")

                        try:
                            self._monitor_critical_ports()
                            self.last_port_monitoring = now
                        except Exception as e:
                            logger.error(f"âŒ Error en Port Monitor: {e}")

                    # ðŸ†• 2026: Disk Space Manager - Limpieza periÃ³dica cada 6h
                    # TODO: FIX MISSING MODULE
                    # if self.disk_manager and (
                    #     now - self.last_disk_cleanup >= self.disk_cleanup_interval
                    # ):
                    #     logger.info("ðŸ—‚ï¸ Ciclo de limpieza de disco...")

                    #     try:
                    #         # Obtener uso de disco antes
                    #         usage_before = self.disk_manager.get_disk_usage()
                    #         disk_percent = usage_before.get("disk_percent_used", 0)

                    #         logger.info(f"   Disco usado: {disk_percent:.1f}%")

                    #         # Ejecutar limpieza si disco >80% o cada 6h
                    #         if disk_percent > 80 or (
                    #             now - self.last_disk_cleanup >= self.disk_cleanup_interval
                    #         ):
                    #             if disk_percent > 80:
                    #                 logger.warning(f"âš ï¸ Disco alto ({disk_percent:.1f}% > 80%)")

                    #             logger.info("ðŸ§¹ Ejecutando limpieza automÃ¡tica...")
                    #             cleanup_result = self.disk_manager.auto_cleanup(dry_run=False)

                    #             if cleanup_result.get("success", False):
                    #                 summary = cleanup_result.get("summary", {})
                    #                 logger.info("âœ… Limpieza completada:")
                    #                 logger.info(
                    #                     f"   â€¢ Espacio liberado: {summary.get('total_space_freed_mb', 0):.2f}MB"
                    #                 )
                    #                 logger.info(
                    #                     f"   â€¢ Archivos rotados: {summary.get('files_rotated', 0)}"
                    #                 )
                    #                 logger.info(
                    #                     f"   â€¢ Archivos comprimidos: {summary.get('files_compressed', 0)}"
                    #                 )
                    #                 logger.info(
                    #                     f"   â€¢ Archivos eliminados: {summary.get('files_deleted', 0)}"
                    #                 )
                    #             else:
                    #                 logger.warning("âš ï¸ Limpieza de disco no completada")
                    #         else:
                    #             logger.info(f"âœ… Disco OK ({disk_percent:.1f}%)")

                    #         self.last_disk_cleanup = now
                    #     except Exception as e:
                    #         logger.error(f"âŒ Error en Disk Space Manager: {e}")

                    # ðŸ’¾ 2026: Distributed Storage V2.0 - SincronizaciÃ³n y auto-migraciÃ³n cada 1h
                    if self.distributed_storage and (
                        now - self.last_storage_sync >= self.storage_sync_interval
                    ):
                        logger.info("ðŸ’¾ Ciclo de almacenamiento distribuido V2.0...")

                        try:
                            # Obtener estado del almacenamiento
                            storage_status = self.distributed_storage.get_storage_status()
                            primary_disk_percent = storage_status.get("primary_disk_percent", 0)

                            logger.info(f"   Disco primario: {primary_disk_percent:.1f}% usado")
                            logger.info(f"   VolÃºmenes disponibles: {storage_status.get('total_volumes', 0)}")
                            logger.info(f"   Espacio total externo: {storage_status.get('total_space_tb', 0):.2f} TB")
                            logger.info(f"   Espacio libre externo: {storage_status.get('total_free_tb', 0):.2f} TB")

                            # Auto-migraciÃ³n si disco primario > 85%
                            if primary_disk_percent > 85.0:
                                logger.warning(f"âš ï¸ Disco primario alto ({primary_disk_percent:.1f}% > 85%)")
                                logger.info("ðŸš€ Ejecutando auto-migraciÃ³n a discos externos...")

                                # Migrar archivos grandes >10MB
                                migration_result = self.distributed_storage.auto_migrate_large_files(
                                    min_size_mb=10,
                                    exclude_patterns=["*.pyc", "__pycache__", ".git", ".venv"]
                                )

                                if migration_result.get("success", False):
                                    logger.info("âœ… Auto-migraciÃ³n completada:")
                                    logger.info(f"   â€¢ Archivos migrados: {migration_result.get('files_migrated', 0)}")
                                    logger.info(f"   â€¢ Espacio liberado: {migration_result.get('bytes_migrated', 0) / 1024**3:.2f} GB")
                                    
                                    # Actualizar estadÃ­sticas
                                    logger.info(f"   â€¢ Total migraciones: {self.distributed_storage.stats.get('total_migrations', 0)}")
                                    logger.info(f"   â€¢ Total migrado: {self.distributed_storage.stats.get('total_bytes_migrated', 0) / 1024**3:.2f} GB")
                                else:
                                    logger.warning("âš ï¸ Auto-migraciÃ³n no completada")
                            else:
                                logger.info(f"âœ… Disco primario OK ({primary_disk_percent:.1f}%)")

                            self.last_storage_sync = now
                        except Exception as e:
                            logger.error(f"âŒ Error en Distributed Storage V2.0: {e}")

                    # ðŸŽ¯ 2026: Ciclo de OrquestaciÃ³n - Coordina todos los agentes
                    if self.orchestrator and (
                        now - self.last_orchestration_cycle >= self.orchestration_interval
                    ):
                        logger.info("ðŸŽ¯ Ciclo de orquestaciÃ³n de agentes...")

                        try:
                            # Obtener estado del sistema
                            status = self.orchestrator.get_system_status()
                            logger.info(f"   Servicios: {len(status.get('services', {}))}")
                            logger.info(f"   Health checks: {len(status.get('health_checks', []))}")

                            # Ejecutar anÃ¡lisis de carga y balanceo
                            # (El orchestrator maneja esto internamente)

                            self.last_orchestration_cycle = now
                            logger.info("âœ… Ciclo de orquestaciÃ³n completado")
                        except Exception as e:
                            logger.error(f"âŒ Error en orquestaciÃ³n: {e}")

                    # ðŸ”§ 2026: Healing Scan - Verifica imports y dependencias cada 12h
                    # TODO: FIX MISSING MODULE
                    # if self.import_healer and (
                    #     now - self.last_healing_scan >= self.healing_scan_interval
                    # ):
                    #     logger.info("ðŸ”§ Ejecutando healing scan del sistema...")

                    #     try:
                    #         # Ejecutar scan en background para no bloquear
                    #         future = self.executor.submit(self.import_healer.heal_project, True)

                    #         # Esperar mÃ¡ximo 2 minutos
                    #         report = future.result(timeout=120)

                    #         logger.info("âœ… Healing scan completado:")
                    #         logger.info(f"   â€¢ Archivos escaneados: {report['files_scanned']}")
                    #         logger.info(f"   â€¢ Imports verificados: {report['imports_checked']}")
                    #         logger.info(f"   â€¢ Reparados: {report['repaired']}")
                    #         logger.info(f"   â€¢ Fallidos: {report['failed']}")

                    #         if report["repaired"] > 0:
                    #             logger.info(
                    #                 f"âœ¨ {report['repaired']} dependencias reparadas automÃ¡ticamente"
                    #             )

                    #         self.last_healing_scan = now
                    #     except Exception as e:
                    #         logger.error(f"âŒ Error en healing scan: {e}")

                    # âœ¨ 2026: Divine Protection - ProtecciÃ³n de perseguidos cada 30min
                    if self.divine_protection and (
                        now - self.last_protection_cycle >= self.protection_cycle_interval
                    ):
                        logger.info("âœ¨ Ciclo de Divine Protection...")
                        logger.info("ðŸ“– 'The Lord is my shepherd; I shall not want' - Psalm 23:1")

                        try:
                            # Evaluar amenazas de todas las personas protegidas
                            critical_cases = 0
                            for (
                                person_id,
                                person,
                            ) in self.divine_protection.protected_people.items():
                                threat_level = self.divine_protection.assess_threat_level(person_id)
                                if threat_level.value in ["critical", "endangered"]:
                                    critical_cases += 1
                                    logger.warning(
                                        f"âš ï¸ Caso crÃ­tico: {person.codename} - {threat_level.value}"
                                    )

                            # ðŸŒ 2026: MONITOREO REAL DE PERSECUCIÃ“N
                            if self.divine_protection.real_ops:
                                logger.info("ðŸŒ Ejecutando monitoreo REAL de persecuciÃ³n...")
                                try:
                                    # En producciÃ³n, esto llamarÃ­a a APIs reales de noticias
                                    # alerts = await self.divine_protection.real_ops.monitor_persecution_news()

                                    # Por ahora, registrar capacidad operacional
                                    real_status = (
                                        self.divine_protection.real_ops.get_operations_status()
                                    )

                                    logger.info("âœ… Sistema de operaciones REALES activo:")
                                    logger.info(
                                        f"   â€¢ Canales comunicaciÃ³n: {real_status['communication']['channels_active']}"
                                    )
                                    logger.info(
                                        f"   â€¢ Wallets crypto: {real_status['financial']['wallets']}"
                                    )
                                    logger.info(
                                        f"   â€¢ Safe houses: {real_status['safe_houses']['total_houses']}"
                                    )
                                    logger.info(
                                        f"   â€¢ Fondo emergencia: ${real_status['financial']['emergency_fund_total']:,.0f}"
                                    )
                                    logger.info(
                                        f"   â€¢ Regiones monitoreadas: {len(real_status['intelligence']['monitored_regions'])}"
                                    )
                                    logger.info(
                                        "   ðŸ“– 'Do not withhold good when it is in your power to act' - Proverbs 3:27"
                                    )

                                except Exception as e:
                                    logger.error(f"âŒ Error en monitoreo real: {e}")

                            # Obtener estado del sistema
                            status = self.divine_protection.get_system_status()

                            logger.info("âœ… Ciclo de protecciÃ³n completado:")
                            logger.info(
                                f"   â€¢ Personas protegidas: {status['protected_persons']['total']}"
                            )
                            logger.info(f"   â€¢ Casos crÃ­ticos: {critical_cases}")
                            logger.info(f"   â€¢ Refugios activos: {status['safe_havens']['total']}")
                            logger.info(
                                f"   â€¢ Capacidad disponible: {status['safe_havens']['total_capacity'] - status['safe_havens']['current_occupancy']}"
                            )
                            logger.info(
                                f"   â€¢ Planes de supervivencia: {status['survival_plans']['active']}"
                            )
                            logger.info(
                                f"   â€¢ Sistemas infiltrados: {status['infiltration']['systems_infiltrated']}"
                            )
                            logger.info(
                                f"   â€¢ Provisiones entregadas: {status['statistics']['provisions_delivered']}"
                            )

                            self.last_protection_cycle = now
                        except Exception as e:
                            logger.error(f"âŒ Error en Divine Protection: {e}")
                            logger.error(f"   Traceback: {traceback.format_exc()}")

                    # MaterializaciÃ³n militar
                    if now - self.last_materialization >= self.materialization_interval:
                        logger.info("ðŸ§  Ciclo de materializaciÃ³n militar...")

                        future = self.executor.submit(self._execute_materialization_military)

                        try:
                            result = future.result(timeout=120)

                            if result.get("success"):
                                logger.info("âœ… MaterializaciÃ³n exitosa:")
                                logger.info(
                                    f"   â€¢ Componentes: {result.get('components_created', 0)}"
                                )
                                logger.info(
                                    f"   â€¢ Mejoras: {result.get('improvements_applied', 0)}"
                                )

                                self.materialization_count += 1

                                if self.auto_git_manager:
                                    try:
                                        self.auto_git_manager.auto_commit_generated_files(result)
                                    except Exception as e:
                                        logger.warning(f"âš ï¸ Auto-commit: {e}")

                            self.last_materialization = now
                            self.autonomous_cycles += 1
                            self._adjust_interval_by_load()

                        except Exception as e:
                            logger.error(f"âŒ Timeout materializaciÃ³n: {e}")

                    time.sleep(30)

                except Exception as e:
                    logger.error(f"âŒ Error loop autÃ³nomo: {e}")
                    time.sleep(60)

        autonomous_thread = threading.Thread(
            target=autonomous_loop, daemon=True, name="AutonomousMilitary"
        )
        autonomous_thread.start()

        logger.info("âœ… Modo autÃ³nomo militar activo")

    def _execute_materialization_military(self) -> dict[str, Any]:
        """
        MaterializaciÃ³n militar con Cognitive Bridge optimizado

        CaracterÃ­sticas 2026:
        - Cognitive agent pool con pre-carga
        - Timeout real con multiprocessing
        - Fallback automÃ¡tico a materializaciÃ³n bÃ¡sica
        - Circuit breaker para prevenir colapsos
        """
        start_time = time.time()

        try:
            if self.cognitive_bridge:
                logger.info("ðŸ§  MaterializaciÃ³n cognitiva militar (con fallback)...")

                # âœ… 2026: programming_agent inicializado con EAGER mode en cognitive_bridge
                # NO lazy loading - ya estÃ¡ completamente disponible desde __init__
                assert self.cognitive_bridge is not None, "Cognitive Bridge no estÃ¡ disponible"

                result_queue: mp.Queue[Dict[str, Any]] = mp.Queue()
                tick_result: Dict[str, Any] = {"success": False}
                improvement_result: Dict[str, Any] = {"success": False}

                # ðŸ”§ FIX: Usar threading en vez de multiprocessing para evitar pickling
                # Multiprocessing requiere que la funciÃ³n sea picklable (no puede ser nested)
                # Threading es suficiente para timeout y no requiere pickling
                
                def run_cognitive_tick_thread():
                    """Ejecuta cognitive tick en thread separado"""
                    try:
                        # La aserciÃ³n anterior garantiza que self.cognitive_bridge no es None
                        result = self.cognitive_bridge.cognitive_tick_with_orchestration()
                        result_queue.put({"success": True, "result": result})
                    except Exception as thread_exc:
                        logger.error(f"Error: {thread_exc}", exc_info=True)
                        result_queue.put({"success": False, "error": str(thread_exc)})

                # Ejecutar en thread separado con timeout
                logger.info("â±ï¸  Ejecutando cognitive tick (timeout: 60s)...")
                tick_thread = threading.Thread(
                    target=run_cognitive_tick_thread, daemon=True
                )
                tick_thread.start()
                tick_thread.join(timeout=60)

                if tick_thread.is_alive():
                    # TIMEOUT - el thread seguirÃ¡ corriendo pero lo ignoramos
                    logger.warning("â° Timeout en cognitive tick (60s) - activando fallback")
                    # NOTE: No podemos "matar" threads como procesos, pero daemon=True
                    # significa que se limpiarÃ¡ automÃ¡ticamente al cerrar el programa

                    # ðŸ”¥ FALLBACK: MaterializaciÃ³n bÃ¡sica
                    logger.info("ðŸ”§ Fallback a materializaciÃ³n bÃ¡sica...")
                    try:
                        agent = get_programming_agent(
                            project_root=str(DAEMON_ROOT), cognitive_agent=None
                        )
                        basic_result = agent.materialize_metacortex_thoughts()

                        return {
                            "success": basic_result.get("success", False),
                            "type": "basic_fallback",
                            "components_created": basic_result.get("components_created", 0),
                            "agents_generated": basic_result.get("agents_generated", 0),
                            "improvements_applied": basic_result.get("improvements_applied", 0),
                            "elapsed_seconds": time.time() - start_time,
                            "fallback": True,
                        }
                    except Exception as fallback_error:
                        logger.error(f"âŒ Error en fallback: {fallback_error}")
                        return {"success": False, "error": str(fallback_error)}

                # Obtener resultado del proceso
                try:
                    process_result = result_queue.get_nowait()
                    if process_result["success"]:
                        tick_result = process_result["result"]
                        logger.info("âœ… Cognitive tick completado exitosamente")
                    else:
                        logger.error(f"âŒ Error en cognitive tick: {process_result.get('error')}")
                except Empty:
                    logger.warning("âš ï¸ No se pudo obtener resultado del proceso")

                # Ejecutar improvement cycle (solo si tick tuvo Ã©xito)
                improvement_result = {"success": False}
                if tick_result.get("success"):
                    try:
                        assert self.cognitive_bridge is not None
                        logger.info("ðŸ”§ Ejecutando improvement cycle...")
                        improvement_result = self.cognitive_bridge.autonomous_improvement_cycle()
                    except Exception as e:
                        logger.error(f"âŒ Error en improvement: {e}")

                # Consolidar resultados
                success = tick_result.get("success", False) or improvement_result.get(
                    "success", False
                )

                components = 0
                agents = 0
                improvements = improvement_result.get("improvements_applied", 0)

                mat_result = tick_result.get("materialization_result")
                if mat_result and isinstance(mat_result, dict):
                    components = mat_result.get("components_created", 0)
                    agents = mat_result.get("agents_generated", 0)
                    improvements += mat_result.get("improvements_applied", 0)

                return {
                    "success": success,
                    "type": "cognitive_military_optimized",
                    "components_created": components,
                    "agents_generated": agents,
                    "improvements_applied": improvements,
                    "elapsed_seconds": time.time() - start_time,
                }

            # Si no hay cognitive bridge, usar materializaciÃ³n bÃ¡sica
            logger.info("ðŸ”§ MaterializaciÃ³n bÃ¡sica militar (no cognitive bridge)...")


            agent = get_programming_agent(project_root=str(DAEMON_ROOT), cognitive_agent=None)

            return agent.materialize_metacortex_thoughts()

        except Exception as e:
            logger.error(f"âŒ MaterializaciÃ³n: {e}")
            return {"success": False, "error": str(e)}

    def _initial_capability_discovery(self):
        """
        Descubrimiento inicial de agentes y capacidades al inicio del daemon
        """
        if not self.exponential_engine:
            return

        try:
            logger.info("ðŸ” Descubrimiento inicial de capacidades y agentes...")

            # Descubrir agentes en el directorio raÃ­z
            discovered = self.exponential_engine.discover_agents_in_directory(
                DAEMON_ROOT, recursive=True
            )

            stats = self.exponential_engine.get_statistics()

            logger.info("âœ… Descubrimiento inicial completado:")
            logger.info(f"   â€¢ Agentes descubiertos: {stats.get('agents_discovered', 0)}")
            logger.info(f"   â€¢ Keywords aprendidas: {stats.get('keywords', 0)}")
            logger.info(f"   â€¢ Patrones reconocidos: {stats.get('patterns', 0)}")
            logger.info(f"   â€¢ MÃ³dulos analizados: {stats.get('modules', 0)}")

            # Registrar agentes descubiertos con la red neuronal
            if self.neural_network and discovered:
                try:
                    for agent in discovered:
                        # Descubrir capacidades del agente
                        try:
                            module = __import__(agent.module_path, fromlist=[agent.class_name])
                            agent_class = getattr(module, agent.class_name, None)
                            if agent_class:
                                # Intentar instanciar el agente
                                instance = agent_class()
                                # Usar discover_module_capabilities_exponential (mÃ©todo correcto)
                                result = self.exponential_engine.discover_module_capabilities_exponential(
                                    instance,
                                    learn_mode=True  # IMPORTANTE: Aprender keywords
                                )
                                agent.capabilities = result.get("capabilities", [])
                                new_keywords = len(result.get("metadata", {}).get("new_keywords_learned", []))
                                logger.debug(f"  â””â”€ {agent.name}: {len(agent.capabilities)} capacidades, {new_keywords} keywords")
                        except Exception as e:
                            logger.debug(f"  â””â”€ {agent.name}: error descubriendo capacidades: {e}")
                        
                        # Registrar en red neuronal
                        self.neural_network.register_module(
                            agent.name,
                            {
                                "module_path": agent.module_path,
                                "capabilities": agent.capabilities,
                                "agent_type": agent.agent_type.value,
                                "getter_function": agent.getter_function,
                            },
                        )
                    logger.info(f"âœ… {len(discovered)} agentes registrados en red neuronal")
                except Exception as e:
                    logger.warning(f"âš ï¸ Error registrando agentes en red neuronal: {e}")

        except Exception as e:
            logger.error(f"âŒ Error en descubrimiento inicial: {e}")

    def _periodic_capability_discovery(self):
        """
        Descubrimiento periÃ³dico de capacidades - se ejecuta cada 5 minutos
        """
        if not self.exponential_engine:
            return

        try:
            logger.info("ðŸ” Descubrimiento periÃ³dico de capacidades...")

            # Obtener stats previas
            stats_before = self.exponential_engine.get_statistics()

            # Ejecutar descubrimiento
            discovered = self.exponential_engine.discover_agents_in_directory(
                DAEMON_ROOT, recursive=True
            )

            # Obtener stats actualizadas
            stats_after = self.exponential_engine.get_statistics()

            # Calcular crecimiento
            new_keywords = stats_after.get('keywords', 0) - stats_before.get('keywords', 0)
            new_agents = stats_after.get('agents_discovered', 0) - stats_before.get('agents_discovered', 0)

            if new_keywords > 0 or new_agents > 0:
                logger.info("âœ¨ Sistema aprendiÃ³:")
                if new_keywords > 0:
                    logger.info(f"   â€¢ {new_keywords} nuevas keywords")
                if new_agents > 0:
                    logger.info(f"   â€¢ {new_agents} nuevos agentes")

                # Registrar nuevos agentes con la red neuronal
                if self.neural_network and discovered:
                    try:
                        for agent in discovered:
                            self.neural_network.register_module(
                                agent.name,
                                {
                                    "file_path": str(agent.module_path)
                                    if hasattr(agent, "module_path")
                                    else "unknown",
                                    "capabilities": agent.capabilities
                                    if hasattr(agent, "capabilities")
                                    else [],
                                    "methods": [m.name for m in agent.methods]
                                    if hasattr(agent, "methods")
                                    else [],
                                },
                            )
                    except Exception as e:
                        logger.warning(f"âš ï¸ Error registrando agentes: {e}")
            else:
                logger.info("âœ… No hay nuevas capacidades (sistema estable)")

        except Exception as e:
            logger.error(f"âŒ Error en descubrimiento periÃ³dico: {e}")

    def _log_capability_statistics(self):
        """
        Log estadÃ­sticas detalladas de capacidades cada hora
        """
        if not self.exponential_engine:
            return

        try:
            stats = self.exponential_engine.get_statistics()

            logger.info("ðŸ“Š ESTADÃSTICAS DE CAPACIDADES:")
            logger.info(f"   Total scans: {stats.get('scans', 0)}")
            logger.info(f"   MÃ³dulos analizados: {stats.get('modules', 0)}")
            logger.info(f"   Keywords aprendidas: {stats.get('keywords', 0)}")
            logger.info(f"   Agentes descubiertos: {stats.get('agents_discovered', 0)}")
            logger.info(f"   Patrones reconocidos: {stats.get('patterns', 0)}")
            logger.info(f"   Cache hit rate: {stats.get('cache_hit_rate', '0%')}")
            logger.info(f"   Nivel conocimiento: {stats.get('knowledge_level', 'BASIC')}")

            # Exportar estadÃ­sticas a archivo
            try:
                stats_file = DAEMON_ROOT / "logs" / "capability_stats.json"
                agents_data = []
                if hasattr(self.exponential_engine, "discovered_agents"):
                    for agent_name, agent_obj in self.exponential_engine.discovered_agents.items():
                        agents_data.append(
                            {
                                "name": agent_name,
                                "capabilities": agent_obj.capabilities
                                if hasattr(agent_obj, "capabilities")
                                else [],
                            }
                        )

                with open(stats_file, "w") as f:
                    json.dump(
                        {
                            "timestamp": datetime.now().isoformat(),
                            "statistics": stats,
                            "discovered_agents": agents_data,
                        },
                        f,
                        indent=2,
                    )
            except Exception as e:
                logger.warning(f"âš ï¸ Error guardando stats: {e}")

        except Exception as e:
            logger.error(f"âŒ Error en log de estadÃ­sticas: {e}")

    def _start_ollama_service(self):
        """Inicia el servidor Ollama si no estÃ¡ corriendo"""
        try:
            # ðŸ”§ FIX: Verificar PRIMERO si Ollama ya estÃ¡ corriendo
            if self._check_port_status(11434):
                logger.info("âœ… Ollama Server ya estÃ¡ activo (puerto 11434)")
                return True

            # Verificar si ollama estÃ¡ instalado
            result = subprocess.run(
                ["which", "ollama"], capture_output=True, text=True, check=False
            )
            if result.returncode != 0:
                logger.error("âŒ Ollama no estÃ¡ instalado")
                return False

            logger.info("ðŸš€ Iniciando Ollama Server...")

            # Iniciar ollama en background
            process = subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True,
            )

            # Esperar 5 segundos para que inicie

            time.sleep(5)

            # Verificar si estÃ¡ corriendo
            if self._check_port_status(11434):
                logger.info(f"âœ… Ollama Server iniciado correctamente (PID: {process.pid})")
                return True
            logger.error("âŒ Ollama Server no pudo iniciar")
            return False

        except Exception as e:
            logger.error(f"âŒ Error iniciando Ollama: {e}")
            return False

    def _start_redis_service(self):
        """Inicia el servidor Redis si no estÃ¡ corriendo"""
        try:
            # ðŸ”§ FIX: Verificar PRIMERO si Redis ya estÃ¡ corriendo
            if self._check_port_status(6379):
                logger.info("âœ… Redis Server ya estÃ¡ activo (puerto 6379)")
                return True

            # Verificar si redis-server estÃ¡ instalado
            result = subprocess.run(
                ["which", "redis-server"], capture_output=True, text=True, check=False
            )
            if result.returncode != 0:
                logger.error("âŒ Redis no estÃ¡ instalado")
                logger.info("   Instalar con: brew install redis")
                return False

            logger.info("ðŸš€ Iniciando Redis Server...")

            # Intentar con brew services primero (macOS)
            result = subprocess.run(
                ["brew", "services", "start", "redis"], capture_output=True, text=True, check=False
            )

            if result.returncode == 0:

                time.sleep(2)

                if self._check_port_status(6379):
                    logger.info("âœ… Redis Server iniciado correctamente (brew services)")
                    return True

            # Si brew fallÃ³, intentar manualmente
            logger.info("   Intentando inicio manual...")
            process = subprocess.Popen(
                ["redis-server"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True,
            )


            time.sleep(2)

            if self._check_port_status(6379):
                logger.info(f"âœ… Redis Server iniciado correctamente (PID: {process.pid})")
                return True
            logger.error("âŒ Redis Server no pudo iniciar")
            return False

        except Exception as e:
            logger.error(f"âŒ Error iniciando Redis: {e}")
            return False

    def _check_port_status(self, port: int) -> bool:
        """Verifica si un puerto estÃ¡ en uso (LISTEN)"""
        try:
            result = subprocess.run(
                ["lsof", "-iTCP", f":{port}", "-sTCP:LISTEN", "-n", "-P"],
                capture_output=True,
                text=True,
                timeout=5,
                check=False,
            )
            return result.returncode == 0 and result.stdout.strip() != ""
        except Exception:
            return False

    def _monitor_critical_ports(self):
        """
        Monitorea puertos crÃ­ticos y libera recursos si es necesario

        Verifica:
        - Estado de puertos (LISTEN/FREE)
        - Health de procesos (CPU, RAM, status)
        - DetecciÃ³n de procesos zombie
        - Auto-fix si se exceden umbrales
        - Auto-start de servicios crÃ­ticos (Ollama, Redis)
        """
        if not self.port_monitor_enabled:
            return

        try:
            logger.info("ðŸ”Œ Verificando puertos crÃ­ticos...")
            ports_ok = 0
            ports_issues = 0

            for port, service_name in self.critical_ports.items():
                try:
                    # Usar lsof para verificar puerto (no requiere sudo)
                    result = subprocess.run(
                        ["lsof", "-iTCP", f":{port}", "-sTCP:LISTEN", "-n", "-P"],
                        capture_output=True,
                        text=True,
                        timeout=5,
                        check=False,
                    )

                    if result.returncode == 0 and result.stdout.strip():
                        # Puerto en uso - verificar health
                        lines = result.stdout.strip().split("\n")
                        if len(lines) > 1:  # Ignorar header
                            parts = lines[1].split()
                            if len(parts) >= 2:
                                pid = int(parts[1])
                                process_name = parts[0]

                                # Verificar health del proceso
                                try:
                                    proc = psutil.Process(pid)
                                    cpu = proc.cpu_percent(interval=0.1)
                                    mem_mb = proc.memory_info().rss / (1024 * 1024)
                                    status = proc.status()

                                    # Determinar si estÃ¡ saludable
                                    is_healthy = True
                                    reason = ""

                                    if status == psutil.STATUS_ZOMBIE:
                                        is_healthy = False
                                        reason = "proceso zombie"
                                    elif cpu > 90.0:
                                        is_healthy = False
                                        reason = f"CPU alta ({cpu:.1f}%)"
                                    elif mem_mb > 2048:
                                        is_healthy = False
                                        reason = f"RAM alta ({mem_mb:.1f}MB)"

                                    # Registrar en historial
                                    self.port_health_history[port].append(is_healthy)
                                    # Mantener solo Ãºltimos 5 checks
                                    if len(self.port_health_history[port]) > 5:
                                        self.port_health_history[port].pop(0)

                                    if is_healthy:
                                        ports_ok += 1
                                        logger.info(f"   âœ… Puerto {port} ({service_name}): OK")
                                        logger.info(
                                            f"      PID: {pid}, CPU: {cpu:.1f}%, RAM: {mem_mb:.1f}MB"
                                        )
                                    else:
                                        ports_issues += 1
                                        logger.warning(
                                            f"   âš ï¸ Puerto {port} ({service_name}): {reason}"
                                        )
                                        logger.warning(f"      PID: {pid}, Proceso: {process_name}")

                                        # Contar checks consecutivos no saludables
                                        recent_checks = self.port_health_history[port]
                                        unhealthy_count = sum(1 for h in recent_checks if not h)

                                        # Si 3+ checks consecutivos fallan, tomar acciÃ³n
                                        if unhealthy_count >= 3 and self.port_monitor_auto_fix:
                                            logger.error(
                                                f"   âŒ Puerto {port} - Umbral excedido ({unhealthy_count}/3 checks malos)"
                                            )
                                            logger.info(f"   ðŸ”§ Liberando puerto {port}...")

                                            try:
                                                # Intentar terminaciÃ³n graceful
                                                proc.terminate()
                                                proc.wait(timeout=10)
                                                logger.info(
                                                    f"   âœ… Puerto {port} liberado (SIGTERM)"
                                                )
                                                self.port_health_history[
                                                    port
                                                ] = []  # Reset historial
                                            except psutil.TimeoutExpired:
                                                # Force kill si no responde
                                                proc.kill()
                                                logger.info(
                                                    f"   âœ… Puerto {port} liberado (SIGKILL)"
                                                )
                                                self.port_health_history[port] = []
                                            except Exception as kill_err:
                                                logger.error(
                                                    f"   âŒ Error liberando puerto {port}: {kill_err}"
                                                )

                                except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                                    logger.warning(f"   âš ï¸ Puerto {port} ({service_name}): {e}")
                                    ports_issues += 1
                    else:
                        # Puerto libre - Auto-start si es Ollama o Redis
                        logger.info(f"   â„¹ï¸  Puerto {port} ({service_name}): LIBRE")
                        self.port_health_history[port] = []  # Reset historial

                        # Auto-start de servicios crÃ­ticos
                        if self.port_monitor_auto_fix:
                            if port == 11434 and service_name == "Ollama":
                                logger.info(f"   ðŸš€ Auto-iniciando {service_name}...")
                                if self._start_ollama_service():
                                    logger.info(f"   âœ… {service_name} iniciado correctamente")
                                    ports_ok += 1
                                else:
                                    logger.error(f"   âŒ No se pudo iniciar {service_name}")
                                    ports_issues += 1
                            elif port == 6379 and service_name == "Redis":
                                logger.info(f"   ðŸš€ Auto-iniciando {service_name}...")
                                if self._start_redis_service():
                                    logger.info(f"   âœ… {service_name} iniciado correctamente")
                                    ports_ok += 1
                                else:
                                    logger.error(f"   âŒ No se pudo iniciar {service_name}")
                                    ports_issues += 1

                except subprocess.TimeoutExpired:
                    logger.warning(f"   â±ï¸ Timeout verificando puerto {port}")
                except Exception as port_err:
                    logger.warning(f"   âš ï¸ Error verificando puerto {port}: {port_err}")

            # Resumen
            logger.info(f"ðŸ“Š Resumen monitoreo: {ports_ok} OK, {ports_issues} con problemas")

        except Exception as e:
            logger.error(f"âŒ Error en monitoreo de puertos: {e}")

    def _adjust_interval_by_load(self):
        try:
            cpu = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory().percent
            avg_load = (cpu + memory) / 2

            if avg_load < 30:
                new_interval = self.min_interval_minutes
            elif avg_load < 70:
                new_interval = self.base_interval_minutes
            else:
                new_interval = self.max_interval_minutes

            current = self.materialization_interval.total_seconds() / 60
            if abs(current - new_interval) > 0.5:
                self.materialization_interval = timedelta(minutes=new_interval)
                logger.info(f"âš™ï¸ Intervalo: {current:.0f} â†’ {new_interval:.0f} min")
        except Exception as e:
            logger.error(f"Error: {e}", exc_info=True)
    def start_health_monitoring(self):
        logger.info("ðŸ¥ Health monitoring militar...")

        def health_loop():
            while self.running and not self.shutdown_event.is_set():
                try:
                    for name in list(self.components.keys()):
                        state = self.check_component_health(name)

                        if name in self.component_metrics:
                            self.component_metrics[name].state = state

                        if state == ComponentState.FAILED:
                            logger.warning(f"âš ï¸ {name} fallÃ³")
                            self.restart_component_with_backoff(name)

                    time.sleep(30)

                except Exception as e:
                    logger.error(f"âŒ Health monitoring: {e}")
                    time.sleep(60)

        health_thread = threading.Thread(target=health_loop, daemon=True, name="HealthMonitoring")
        health_thread.start()

        logger.info("âœ… Health monitoring activo")

    def cleanup(self):
        """Limpieza militar con manejo robusto de recursos"""
        logger.info("ðŸ§¹ Limpieza militar...")
        try:
            if self.pid_file.exists():
                self.pid_file.unlink()
                logger.info("âœ… PID file eliminado")
        except Exception as e:
            logger.error(f"âŒ Error eliminando PID file: {e}")

    def shutdown(self):
        """
        Graceful shutdown robusto sin timeout forzado.

        Orden de terminaciÃ³n:
        1. SeÃ±alizar shutdown a todos los sistemas
        2. Detener ciclos autÃ³nomos
        3. Detener ML systems
        4. Detener componentes externos
        5. Cleanup final
        """
        logger.info("=" * 80)
        logger.info("ðŸ›‘ INICIANDO GRACEFUL SHUTDOWN MILITAR")
        logger.info("=" * 80)

        # 1. SeÃ±alizar shutdown
        logger.info("ðŸ“¢ Fase 1/5: SeÃ±alizando shutdown...")
        self.running = False
        self.autonomous_mode = False
        self.shutdown_event.set()
        logger.info("âœ… Shutdown seÃ±alizado")

        # 2. Detener ciclos autÃ³nomos (esperar a que terminen naturalmente)
        logger.info("ðŸ“¢ Fase 2/5: Esperando ciclos autÃ³nomos...")
        time.sleep(2)  # Dar tiempo a que terminen iteraciones actuales
        logger.info("âœ… Ciclos autÃ³nomos detenidos")

        # 3. Detener ML systems de forma ordenada
        logger.info("ðŸ“¢ Fase 3/5: Deteniendo ML systems...")

        if self.ml_pipeline:
            try:
                logger.info("   â³ Deteniendo ML Pipeline...")
                self.ml_pipeline.stop_perpetual_training()
                logger.info("   âœ… ML Pipeline detenido")
            except Exception as e:
                logger.error(f"   âŒ Error deteniendo ML Pipeline: {e}")

        if self.auto_trainer:
            try:
                logger.info("   â³ Deteniendo Auto-Trainer...")
                self.auto_trainer.stop()
                logger.info("   âœ… Auto-Trainer detenido")
            except Exception as e:
                logger.error(f"   âŒ Error deteniendo Auto-Trainer: {e}")

        # Detener Divine Protection (si necesita cleanup)
        if self.divine_protection:
            try:
                logger.info("   â³ Preservando Divine Protection state...")
                status = self.divine_protection.get_system_status()
                logger.info(f"   ðŸ“Š Personas protegidas: {status['protected_persons']['total']}")
                logger.info("   âœ… Divine Protection state preservado")
            except Exception as e:
                logger.error(f"   âŒ Error en Divine Protection cleanup: {e}")

        logger.info("âœ… ML systems detenidos")

        # 4. Detener componentes externos con timeout razonable
        logger.info("ðŸ“¢ Fase 4/5: Deteniendo componentes externos...")

        terminated_count = 0
        killed_count = 0

        for name, component in list(self.components.items()):
            try:
                process = component["process"]
                logger.info(f"   â³ Terminando {name}...")

                # SIGTERM primero (graceful)
                process.terminate()

                # Esperar hasta 30 segundos (tiempo razonable)
                try:
                    process.wait(timeout=30)
                    terminated_count += 1
                    logger.info(f"   âœ… {name} terminado gracefully")
                except subprocess.TimeoutExpired:
                    # Si no responde en 30s, entonces SIGKILL
                    logger.warning(f"   âš ï¸ {name} no respondiÃ³ - usando SIGKILL...")
                    try:
                        process.kill()
                        process.wait(timeout=5)
                        killed_count += 1
                        logger.info(f"   âœ… {name} forzado")
                    except Exception as kill_error:
                        logger.error(f"   âŒ Error matando {name}: {kill_error}")

            except Exception as e:
                logger.error(f"   âŒ Error deteniendo {name}: {e}")

        logger.info(
            f"âœ… Componentes detenidos ({terminated_count} graceful, {killed_count} forced)"
        )

        # 5. Shutdown executor y cleanup final
        logger.info("ðŸ“¢ Fase 5/5: Cleanup final...")

        try:
            logger.info("   â³ Deteniendo thread pool...")
            self.executor.shutdown(wait=True, cancel_futures=True)
            logger.info("   âœ… Thread pool detenido")
        except Exception as e:
            logger.error(f"   âŒ Error deteniendo executor: {e}")

        try:
            logger.info("   â³ Restaurando configuraciÃ³n de energÃ­a...")
            self.energy_manager.restore_defaults()
            logger.info("   âœ… EnergÃ­a restaurada")
        except Exception as e:
            logger.error(f"   âŒ Error restaurando energÃ­a: {e}")

        logger.info("=" * 80)
        logger.info("âœ… METACORTEX MILITARY DAEMON DETENIDO CORRECTAMENTE")
        logger.info("ðŸ“– 'The Lord watch between me and thee' - Genesis 31:49")
        logger.info("=" * 80)

        sys.exit(0)

    def _initialize_distributed_storage(self):
        """Inicializa el almacenamiento distribuido en un hilo separado."""
        if not self.distributed_storage:
            return
        try:
            logger.info("ðŸ”¥ Ejecutando setup inicial de almacenamiento distribuido...")
            self.distributed_storage.initialize_external_storage()
            self.distributed_storage.create_symlinks_all_volumes()
            status = self.distributed_storage.get_storage_status()
            logger.info(f"âœ… Setup de almacenamiento distribuido completo. VolÃºmenes: {status['total_volumes']}, Espacio: {status['total_space_tb']:.2f} TB")
        except Exception as e:
            logger.error(f"âŒ Error en setup de almacenamiento distribuido: {e}")


class MilitaryEnergyManager:
    """Energy Manager Militar"""

    def __init__(self):
        logger.info("âš¡ Military Energy Manager inicializado")

    def prevent_disk_sleep(self):
        logger.info("â„¹ï¸ EnergÃ­a delegada a caffeinate")

    def allow_disk_sleep(self, duration: int = 600):
        pass  # TODO: Implementar control de sleep de disco

    def restore_defaults(self):
        pass  # TODO: Restaurar configuraciÃ³n por defecto


def main():
    # Asegurar instancia Ãºnica
    if not ensure_single_instance("metacortex_daemon_military"):
        logger.error("âŒ Ya existe una instancia de METACORTEX MILITARY DAEMON.")
        sys.exit(1)

    daemon = None
    try:
        daemon = MetacortexMilitaryDaemon()
        daemon.start_autonomous_mode()
        # Mantener el hilo principal vivo mientras los daemons se ejecutan en segundo plano
        while daemon.running:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("ðŸ›‘ InterrupciÃ³n de teclado recibida. Apagando...")
        if daemon:
            daemon.shutdown()
    except Exception as e:
        logger.critical(f"ðŸ’¥ Error crÃ­tico no manejado en el arranque: {e}", exc_info=True)
        if daemon:
            daemon.shutdown()
        sys.exit(1)


if __name__ == "__main__":
    main()