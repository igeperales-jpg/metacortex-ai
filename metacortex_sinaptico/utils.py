#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
METACORTEX - Utilidades y Configuraci√≥n
========================================

Tipos de datos, configuraci√≥n y herramientas comunes para el sistema cognitivo.
"""

from __future__ import annotations

import hashlib
import json
import logging
import os
import random
import sys
import threading
import time
from contextlib import contextmanager
from datetime import datetime
from functools import lru_cache, wraps
from pathlib import Path
from typing import Any, Callable, Dict, Generator, List, Optional, TypeVar, Union

from pydantic import BaseModel, Field, field_validator, model_validator


# === CONFIGURACI√ìN DEL AGENTE - SINGLETON VERDADERO ===


class AgentConfig:
    """
    Configuraci√≥n del agente cognitivo - TRUE SINGLETON PATTERN.

    üî• IMPLEMENTACI√ìN SINGLETON THREAD-SAFE:
        pass  # TODO: Implementar
    - Solo UNA instancia en toda la aplicaci√≥n
    - Thread-safe con threading.Lock
    - Previene duplicaci√≥n completa
    """

    _instance = None
    _lock = threading.Lock()
    _initialized = False

    def __new__(cls):
        """Singleton pattern verdadero con thread safety."""
        if cls._instance is None:
            with cls._lock:
                # Double-checked locking pattern
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    print("üî• AgentConfig SINGLETON: Nueva instancia √∫nica creada")
                # else: Reutilizaci√≥n silenciosa - no necesita warning
        # else: Retorno silencioso - no necesita warning
        return cls._instance

    def __init__(self):
        """Inicializaci√≥n √∫nica - solo se ejecuta UNA vez."""
        if AgentConfig._initialized:
            return  # Ya inicializado, no repetir

        print("üß† AgentConfig SINGLETON: Inicializando configuraci√≥n √∫nica")

        # === CONFIGURACI√ìN UNIFICADA MAESTRA ===
        # üî• UNA SOLA FUENTE DE VERDAD - NO M√ÅS CONFLICTOS

        # Par√°metros b√°sicos UNIFICADOS
        self.learning_rate = 0.001  # üî• MAESTRA: 0.001 (no 0.1)
        self.exploration_rate = 0.1
        self.memory_size = 1000
        self.context_window = 50  # üî• MAESTRA: 50 (no 100)
        self.seed = 42

        # Base de datos UNIFICADA
        self.db_path = "metacortex.sqlite"
        self.history_window = 100  # üî• MAESTRA: 100
        self.anomaly_threshold = 2.0  # üî• MAESTRA: 2.0

        # Percepci√≥n UNIFICADA
        self.perception_threshold = 0.5
        self.attention_span = 10

        # Cognici√≥n UNIFICADA
        self.reasoning_depth = 3
        self.creativity_factor = 0.2

        # Aprendizaje UNIFICADO
        self.curiosity_drive = 0.3
        self.novelty_threshold = 0.15  # üî• OPTIMIZADO: 0.15 (antes 0.3) para permitir m√°s crecimiento del grafo

        # üß† CONEXI√ìN A RED NEURONAL SIMBI√ìTICA
        try:
            from neural_symbiotic_network import get_neural_network

            self.neural_network = get_neural_network()
            self.neural_network.register_module("agent_config", self)
            print("‚úÖ 'agent_config' conectado a red neuronal")
        except Exception as e:
            logger.error(f"Error: {e}", exc_info=True)
            print(f"‚ö†Ô∏è No se pudo conectar a red neuronal: {e}")
            self.neural_network = None

        # Metacognici√≥n UNIFICADA
        self.wellbeing_threshold = 0.4

        # Configurar semilla para reproducibilidad
        random.seed(self.seed)

        # üî• LOGGING UNIFICADO - SIN DUPLICACI√ìN
        self._setup_unified_logging()

        # Marcar como inicializado
        AgentConfig._initialized = True
        print("‚úÖ AgentConfig SINGLETON: Configuraci√≥n unificada completada")

    def _setup_unified_logging(self):
        """Configurar logging unificado sin duplicaci√≥n."""
        # Obtener root logger
        root_logger = logging.getLogger()

        # Limpiar handlers existentes para evitar duplicaci√≥n
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)

        # Configurar √öNICO handler
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(levelname)s - %(message)s",  # üî• Sin duplicar "METACORTEX"
            force=True,  # Forzar reconfiguraci√≥n
        )
        print("üîß Logging unificado configurado (sin duplicaci√≥n)")

    @classmethod
    def get_instance(cls):
        """M√©todo de clase para obtener la instancia singleton."""
        return cls()  # __new__ maneja el singleton

    @classmethod
    def reset_singleton(cls):
        """SOLO para testing - reinicia el singleton."""
        with cls._lock:
            cls._instance = None
            cls._initialized = False
            print("üîÑ AgentConfig SINGLETON: Reiniciado (solo testing)")


# üî• FUNCI√ìN GLOBAL UNIFICADA
def get_singleton_config() -> AgentConfig:
    """
    Retorna la instancia singleton VERDADERA de AgentConfig.

    üî• GARANT√çA: Solo UNA instancia en toda la aplicaci√≥n.
    """
    return AgentConfig.get_instance()


# === MODELOS PYDANTIC PARA API ===


class PerceptionInput(BaseModel):
    """Input para el endpoint de percepci√≥n."""

    name: str = Field(..., description="Nombre del evento percibido")
    payload: Dict[str, Any] = Field(..., description="Datos del evento")


class PerceptionOutput(BaseModel):
    """Output del endpoint de percepci√≥n."""

    anomaly: bool = Field(..., description="Si se detect√≥ una anomal√≠a")
    z_score: Optional[float] = Field(None, description="Puntuaci√≥n Z si es anomal√≠a")
    stored: bool = Field(..., description="Si se almacen√≥ en memoria")


class MetaReport(BaseModel):
    """Reporte del estado metacognitivo."""

    wellbeing: float = Field(..., description="Nivel de bienestar (0-1)")
    anomalies: int = Field(..., description="N√∫mero de anomal√≠as detectadas")
    intention: Optional[str] = Field(None, description="Intenci√≥n actual")
    notes: List[str] = Field(default_factory=list, description="Notas del sistema")
    timestamp: float = Field(..., description="Timestamp del reporte")


class GraphSnapshot(BaseModel):
    """Snapshot del grafo de conocimiento."""

    nodes: List[str] = Field(..., description="Lista de nodos")
    edges: List[Dict[str, Any]] = Field(..., description="Lista de aristas con pesos")
    metrics: Dict[str, float] = Field(..., description="M√©tricas del grafo")


class SystemStatus(BaseModel):
    """Estado general del sistema."""

    active: bool = Field(..., description="Si el sistema est√° activo")
    uptime: float = Field(..., description="Tiempo activo en segundos")
    memory_usage: Dict[str, int] = Field(..., description="Uso de memoria")
    last_tick: Optional[float] = Field(None, description="√öltimo tick procesado")


# === UTILIDADES ===


def get_env_config() -> AgentConfig:
    """
    Obtiene configuraci√≥n desde variables de entorno.

    üî• GARANT√çA: Usa SINGLETON VERDADERO - no crea nueva instancia.
    """
    config = get_singleton_config()  # ‚úÖ Retorna √öNICA instancia

    # üî• CONFIGURACI√ìN MAESTRA desde ENV (si existe)
    # Solo actualiza valores si las variables de entorno est√°n definidas
    seed_env = os.getenv("AGENT_SEED")
    if seed_env:
        config.seed = int(seed_env)
        random.seed(config.seed)  # Reconfigurar seed
        print(f"üîß ENV Override: seed={config.seed}")

    db_path_env = os.getenv("METACORTEX_DB_PATH")
    if db_path_env:
        config.db_path = db_path_env
        print(f"üîß ENV Override: db_path={config.db_path}")

    anomaly_env = os.getenv("ANOMALY_THRESHOLD")
    if anomaly_env:
        config.anomaly_threshold = float(anomaly_env)
        print(f"üîß ENV Override: anomaly_threshold={config.anomaly_threshold}")

    wellbeing_env = os.getenv("WELLBEING_THRESHOLD")
    if wellbeing_env:
        config.wellbeing_threshold = float(wellbeing_env)
        print(f"üîß ENV Override: wellbeing_threshold={config.wellbeing_threshold}")

    return config


# === LOGGING SINGLETON - SOLUCI√ìN DE RA√çZ ===

_logging_initialized = False
_logging_lock = threading.Lock()


def setup_logging(level: str = "INFO") -> logging.Logger:
    """
    Configura y retorna logger del sistema (SINGLETON).

    üî• SOLUCI√ìN DE RA√çZ: Solo configura handlers UNA vez usando flag global.
    Previene duplicaci√≥n de mensajes cuando se llama m√∫ltiples veces.
    """
    global _logging_initialized

    logger = logging.getLogger("metacortex")

    # Thread-safe initialization
    with _logging_lock:
        if not _logging_initialized:
            # Configurar nivel
            logger.setLevel(getattr(logging, level.upper()))

            # Limpiar handlers existentes (por si acaso)
            logger.handlers.clear()

            # Prevenir propagaci√≥n al root logger
            logger.propagate = False

            # Crear √öNICO handler
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

            _logging_initialized = True
            logger.debug("üîß Logging singleton inicializado (primera vez)")
        else:
            # Ya inicializado, solo retornar
            logger.debug("üîß Logging singleton ya inicializado (reutilizando)")

    return logger


def clamp(value: float, min_val: float, max_val: float) -> float:
    """Limita un valor entre min y max."""
    return max(min_val, min(value, max_val))


def normalize(value: float, min_val: float, max_val: float) -> float:
    """Normaliza un valor al rango [0, 1]."""
    if max_val == min_val:
        return 0.5
    return (value - min_val) / (max_val - min_val)


# === EXCEPCIONES PERSONALIZADAS ===


class MetacortexError(Exception):
    """Excepci√≥n base para errores de Metacortex."""

    # IMPLEMENTED: Implement this functionality


class DatabaseError(MetacortexError):
    """Error de base de datos."""

    # IMPLEMENTED: Implement this functionality


class ConfigurationError(MetacortexError):
    """Error de configuraci√≥n."""

    # IMPLEMENTED: Implement this functionality


class CognitiveError(MetacortexError):
    """Error en procesos cognitivos."""

    # IMPLEMENTED: Implement this functionality


# === DECORADORES AVANZADOS ===

T = TypeVar("T")


def retry(max_attempts: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """
    Decorador para reintentar funciones que fallan.
    
    Args:
        max_attempts: N√∫mero m√°ximo de intentos
        delay: Delay inicial entre intentos (segundos)
        backoff: Factor multiplicador del delay en cada intento
        
    Ejemplo:
        @retry(max_attempts=3, delay=0.5, backoff=2.0)
        def api_call():
            return requests.get(url)
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> T:
            current_delay = delay
            last_exception = None
            logger = logging.getLogger("metacortex")
            
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    logger.error(f"Error: {e}", exc_info=True)
                    last_exception = e
                    if attempt < max_attempts:
                        logger.warning(
                            f"Intento {attempt}/{max_attempts} fall√≥ para {func.__name__}: {e}. "
                            f"Reintentando en {current_delay}s..."
                        )
                        time.sleep(current_delay)
                        current_delay *= backoff
                    else:
                        logger.error(f"Todos los intentos fallaron para {func.__name__}")
            
            # Si llegamos aqu√≠, todos los intentos fallaron
            raise last_exception  # type: ignore
        
        return wrapper
    return decorator


def rate_limit(calls: int = 10, period: float = 1.0):
    """
    Decorador para limitar la tasa de llamadas a una funci√≥n.
    
    Args:
        calls: N√∫mero m√°ximo de llamadas permitidas
        period: Per√≠odo de tiempo en segundos
        
    Ejemplo:
        @rate_limit(calls=5, period=1.0)  # 5 llamadas por segundo
        def api_request():
            # IMPLEMENTED: Implement this functionality
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        timestamps: List[float] = []
        lock = threading.Lock()
        
        @wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> T:
            with lock:
                now = time.time()
                # Limpiar timestamps antiguos
                timestamps[:] = [ts for ts in timestamps if now - ts < period]
                
                if len(timestamps) >= calls:
                    # Calcular tiempo de espera
                    sleep_time = period - (now - timestamps[0])
                    if sleep_time > 0:
                        time.sleep(sleep_time)
                        now = time.time()
                        timestamps[:] = [ts for ts in timestamps if now - ts < period]
                
                timestamps.append(now)
            
            return func(*args, **kwargs)
        
        return wrapper
    return decorator


@contextmanager
def timer(name: str = "Operation") -> Generator[Dict[str, float], None, None]:
    """
    Context manager para medir tiempo de ejecuci√≥n.
    
    Ejemplo:
        with timer("Database query") as t:
            execute_query()
        print(f"Tiempo: {t['elapsed']}s")
    """
    result: Dict[str, float] = {"start": 0.0, "end": 0.0, "elapsed": 0.0}
    logger = logging.getLogger("metacortex")
    
    result["start"] = time.time()
    logger.debug(f"‚è±Ô∏è  {name}: Iniciando...")
    
    try:
        yield result
    finally:
        result["end"] = time.time()
        result["elapsed"] = result["end"] - result["start"]
        logger.info(f"‚è±Ô∏è  {name}: Completado en {result['elapsed']:.4f}s")


def memoize_with_ttl(ttl: float = 60.0):
    """
    Decorador para cachear resultados con tiempo de vida.
    
    Args:
        ttl: Tiempo de vida del cache en segundos
        
    Ejemplo:
        @memoize_with_ttl(ttl=30.0)
        def expensive_calculation(x):
            return x ** 2
    """
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        cache: Dict[str, tuple[float, T]] = {}
        lock = threading.Lock()
        
        @wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> T:
            # Crear clave del cache
            key = str(args) + str(sorted(kwargs.items()))
            
            with lock:
                now = time.time()
                
                # Verificar si existe en cache y no ha expirado
                if key in cache:
                    timestamp, value = cache[key]
                    if now - timestamp < ttl:
                        return value
                
                # Calcular nuevo valor
                result = func(*args, **kwargs)
                cache[key] = (now, result)
                
                # Limpiar entradas expiradas
                expired_keys = [
                    k for k, (ts, _) in cache.items()
                    if now - ts >= ttl
                ]
                for k in expired_keys:
                    del cache[k]
                
                return result
        
        return wrapper
    return decorator


# === UTILIDADES DE HASHING Y SERIALIZACI√ìN ===


def compute_hash(data: Union[str, bytes, Dict[str, Any]], algorithm: str = "sha256") -> str:
    """
    Calcula hash de datos.
    
    Args:
        data: Datos a hashear (string, bytes o dict)
        algorithm: Algoritmo de hash (md5, sha1, sha256, sha512)
        
    Returns:
        Hash hexadecimal
        
    Ejemplo:
        >>> compute_hash({"key": "value"})
        'a1b2c3...'
    """
    # Convertir a bytes
    if isinstance(data, dict):
        data_bytes = json.dumps(data, sort_keys=True).encode("utf-8")
    elif isinstance(data, str):
        data_bytes = data.encode("utf-8")
    else:
        data_bytes = data
    
    # Calcular hash
    hasher = hashlib.new(algorithm)
    hasher.update(data_bytes)
    return hasher.hexdigest()


def safe_json_loads(data: str, default: Any = None) -> Any:
    """
    Carga JSON de forma segura.
    
    Args:
        data: String JSON
        default: Valor por defecto si falla
        
    Returns:
        Objeto parseado o default
    """
    try:
        return json.loads(data)
    except (json.JSONDecodeError, TypeError) as e:
        logger = logging.getLogger("metacortex")
        logger.warning(f"Error parseando JSON: {e}")
        return default


def safe_json_dumps(data: Any, default: str = "{}") -> str:
    """
    Serializa a JSON de forma segura.
    
    Args:
        data: Objeto a serializar
        default: String por defecto si falla
        
    Returns:
        String JSON o default
    """
    try:
        return json.dumps(data, ensure_ascii=False, indent=2)
    except (TypeError, ValueError) as e:
        logger = logging.getLogger("metacortex")
        logger.warning(f"Error serializando JSON: {e}")
        return default


# === UTILIDADES DE PATHS ===


def ensure_dir(path: Union[str, Path]) -> Path:
    """
    Asegura que un directorio existe, cre√°ndolo si es necesario.
    
    Args:
        path: Ruta del directorio
        
    Returns:
        Path object del directorio
        
    Ejemplo:
        data_dir = ensure_dir("./data/models")
    """
    path_obj = Path(path)
    path_obj.mkdir(parents=True, exist_ok=True)
    return path_obj


def get_project_root() -> Path:
    """
    Obtiene la ra√≠z del proyecto.
    
    Returns:
        Path a la ra√≠z del proyecto
    """
    # Buscar archivo setup.py, pyproject.toml, o .git
    current = Path.cwd()
    
    for _ in range(10):  # Limitar b√∫squeda a 10 niveles
        if any((current / marker).exists() for marker in [
            "setup.py", "pyproject.toml", ".git", "requirements.txt"
        ]):
            return current
        
        parent = current.parent
        if parent == current:  # Llegamos a la ra√≠z del sistema
            break
        current = parent
    
    # Si no encontramos, usar directorio actual
    return Path.cwd()


def safe_file_read(path: Union[str, Path], default: str = "") -> str:
    """
    Lee archivo de forma segura.
    
    Args:
        path: Ruta del archivo
        default: Contenido por defecto si falla
        
    Returns:
        Contenido del archivo o default
    """
    try:
        return Path(path).read_text(encoding="utf-8")
    except (IOError, OSError) as e:
        logger = logging.getLogger("metacortex")
        logger.warning(f"Error leyendo archivo {path}: {e}")
        return default


def safe_file_write(path: Union[str, Path], content: str) -> bool:
    """
    Escribe archivo de forma segura.
    
    Args:
        path: Ruta del archivo
        content: Contenido a escribir
        
    Returns:
        True si √©xito, False si error
    """
    try:
        path_obj = Path(path)
        path_obj.parent.mkdir(parents=True, exist_ok=True)
        path_obj.write_text(content, encoding="utf-8")
        return True
    except (IOError, OSError) as e:
        logger = logging.getLogger("metacortex")
        logger.error(f"Error escribiendo archivo {path}: {e}")
        return False


# === VALIDADORES PYDANTIC CUSTOM ===


def validate_probability(value: float) -> float:
    """
    Valida que un valor sea una probabilidad v√°lida [0, 1].
    
    Raises:
        ValueError: Si el valor est√° fuera del rango
    """
    if not 0.0 <= value <= 1.0:
        raise ValueError(f"Probability must be between 0 and 1, got {value}")
    return value


def validate_positive(value: Union[int, float]) -> Union[int, float]:
    """
    Valida que un valor sea positivo.
    
    Raises:
        ValueError: Si el valor no es positivo
    """
    if value <= 0:
        raise ValueError(f"Value must be positive, got {value}")
    return value


def sanitize_string(value: str, max_length: int = 1000) -> str:
    """
    Sanitiza un string para prevenir inyecci√≥n.
    
    Args:
        value: String a sanitizar
        max_length: Longitud m√°xima permitida
        
    Returns:
        String sanitizado
    """
    # Remover caracteres de control
    sanitized = "".join(char for char in value if char.isprintable() or char.isspace())
    
    # Limitar longitud
    if len(sanitized) > max_length:
        sanitized = sanitized[:max_length]
    
    # Remover espacios extras
    sanitized = " ".join(sanitized.split())
    
    return sanitized


# === UTILIDADES DE M√âTRICAS Y ESTAD√çSTICAS ===


@lru_cache(maxsize=128)
def moving_average(values: tuple[float, ...], window: int = 5) -> float:
    """
    Calcula promedio m√≥vil de valores.
    
    Args:
        values: Tupla de valores (debe ser tupla para cache)
        window: Tama√±o de la ventana
        
    Returns:
        Promedio m√≥vil
    """
    if not values:
        return 0.0
    
    recent = values[-window:]
    return sum(recent) / len(recent)


def calculate_percentile(values: List[float], percentile: float) -> float:
    """
    Calcula percentil de una lista de valores.
    
    Args:
        values: Lista de valores
        percentile: Percentil a calcular (0-100)
        
    Returns:
        Valor en el percentil especificado
    """
    if not values:
        return 0.0
    
    sorted_values = sorted(values)
    index = int(len(sorted_values) * (percentile / 100.0))
    index = max(0, min(index, len(sorted_values) - 1))
    
    return sorted_values[index]


def calculate_variance(values: List[float]) -> float:
    """
    Calcula varianza de valores.
    
    Args:
        values: Lista de valores
        
    Returns:
        Varianza
    """
    if len(values) < 2:
        return 0.0
    
    mean = sum(values) / len(values)
    return sum((x - mean) ** 2 for x in values) / len(values)


def calculate_std_dev(values: List[float]) -> float:
    """
    Calcula desviaci√≥n est√°ndar.
    
    Args:
        values: Lista de valores
        
    Returns:
        Desviaci√≥n est√°ndar
    """
    return calculate_variance(values) ** 0.5


# === UTILIDADES DE SISTEMA ===


def get_memory_usage() -> Dict[str, int]:
    """
    Obtiene uso de memoria del proceso actual.
    
    Returns:
        Dict con rss, vms en bytes
    """
    try:
        import resource
        usage = resource.getrusage(resource.RUSAGE_SELF)
        return {
            "rss": usage.ru_maxrss * 1024,  # KB to bytes on Linux
            "vms": 0,  # No disponible f√°cilmente
        }
    except ImportError:
        # Fallback para Windows
        try:
            import psutil
            process = psutil.Process()
            mem_info = process.memory_info()
            return {
                "rss": mem_info.rss,
                "vms": mem_info.vms,
            }
        except ImportError:
            return {"rss": 0, "vms": 0}


def get_system_info() -> Dict[str, Any]:
    """
    Obtiene informaci√≥n del sistema.
    
    Returns:
        Dict con platform, python_version, etc.
    """
    return {
        "platform": sys.platform,
        "python_version": sys.version,
        "python_implementation": sys.implementation.name,
        "timestamp": datetime.now().isoformat(),
    }


# === UTILIDADES DE CONFIGURACI√ìN MEJORADAS ===


@lru_cache(maxsize=1)
def get_cached_config() -> AgentConfig:
    """
    Obtiene configuraci√≥n cacheada (singleton con LRU cache adicional).
    
    Returns:
        AgentConfig singleton instance
    """
    return get_singleton_config()


def validate_config(config: AgentConfig) -> List[str]:
    """
    Valida configuraci√≥n y retorna lista de advertencias.
    
    Args:
        config: Configuraci√≥n a validar
        
    Returns:
        Lista de mensajes de advertencia (vac√≠a si todo est√° bien)
    """
    warnings: List[str] = []
    
    # Validar learning_rate
    if not 0.0 < config.learning_rate <= 1.0:
        warnings.append(f"learning_rate deber√≠a estar entre 0 y 1, got {config.learning_rate}")
    
    # Validar exploration_rate
    if not 0.0 <= config.exploration_rate <= 1.0:
        warnings.append(f"exploration_rate debe ser probabilidad [0,1], got {config.exploration_rate}")
    
    # Validar memory_size
    if config.memory_size <= 0:
        warnings.append(f"memory_size debe ser positivo, got {config.memory_size}")
    
    # Validar context_window
    if config.context_window <= 0:
        warnings.append(f"context_window debe ser positivo, got {config.context_window}")
    
    # Validar anomaly_threshold
    if config.anomaly_threshold <= 0:
        warnings.append(f"anomaly_threshold debe ser positivo, got {config.anomaly_threshold}")
    
    # Validar wellbeing_threshold
    if not 0.0 <= config.wellbeing_threshold <= 1.0:
        warnings.append(f"wellbeing_threshold debe estar en [0,1], got {config.wellbeing_threshold}")
    
    # Validar db_path
    if not config.db_path:
        warnings.append("db_path est√° vac√≠o")
    
    return warnings