"""
ðŸ§  AI INTEGRATION LAYER - Capa de IntegraciÃ³n de IA para TODOS los Sistemas
=============================================================================

Esta capa conecta TODOS los modelos de lenguaje y ML con TODOS los canales
de comunicaciÃ³n (Telegram, WhatsApp, Web, etc.) de forma UNIFICADA.

Componentes:
1. Ollama Integration - Modelos de lenguaje grandes
2. ML Models Manager - 956+ modelos entrenados
3. Response Generator - Respuestas inteligentes contextuales
4. Threat Analyzer - AnÃ¡lisis de amenazas con IA
5. Divine Protection Bridge - ConexiÃ³n con sistema de protecciÃ³n

Autor: METACORTEX AI Team
Fecha: 24 de Noviembre de 2025
VersiÃ³n: 1.0.0 - Full Integration
"""

import logging
import asyncio
import json
import pickle
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime
import httpx

logger = logging.getLogger(__name__)


# ============================================================================
# OLLAMA INTEGRATION (Modelos de Lenguaje)
# ============================================================================

class OllamaAIEngine:
    """Motor de IA con Ollama para respuestas inteligentes"""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.models = {
            "fast": "mistral:latest",        # 7B - Respuestas rÃ¡pidas
            "instruct": "mistral:instruct",  # 7B - Instrucciones
            "advanced": "mistral-nemo:latest" # 12B - AnÃ¡lisis profundo
        }
        self.client = httpx.AsyncClient(timeout=60.0)
        
    async def generate_response(
        self,
        prompt: str,
        context: Optional[str] = None,
        model_type: str = "fast",
        max_tokens: int = 500
    ) -> Dict[str, Any]:
        """
        Genera respuesta inteligente usando Ollama
        
        Args:
            prompt: Mensaje del usuario
            context: Contexto adicional
            model_type: Tipo de modelo (fast/instruct/advanced)
            max_tokens: MÃ¡ximo de tokens
            
        Returns:
            Dict con respuesta y metadata
        """
        try:
            model = self.models.get(model_type, self.models["fast"])
            
            # Construir prompt completo
            full_prompt = self._build_prompt(prompt, context)
            
            # Llamar a Ollama
            response = await self.client.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": model,
                    "prompt": full_prompt,
                    "stream": False,
                    "options": {
                        "num_predict": max_tokens,
                        "temperature": 0.7,
                        "top_p": 0.9
                    }
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                return {
                    "success": True,
                    "response": result.get("response", ""),
                    "model": model,
                    "tokens": result.get("eval_count", 0),
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"Ollama error: {response.status_code}")
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}",
                    "fallback_response": self._get_fallback_response(prompt)
                }
                
        except Exception as e:
            logger.exception(f"Error calling Ollama: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback_response": self._get_fallback_response(prompt)
            }
    
    def _build_prompt(self, user_message: str, context: Optional[str] = None) -> str:
        """Construye prompt con contexto de Divine Protection"""
        
        system_context = """You are METACORTEX Divine Protection AI Assistant.

Your purpose:
- Help people who are persecuted for their faith
- Provide compassionate, practical assistance
- Assess emergency situations
- Connect people with resources and protection

Guidelines:
- Be empathetic and understanding
- Prioritize safety and security
- Provide actionable guidance
- Respect religious beliefs
- Maintain confidentiality
"""
        
        if context:
            return f"{system_context}\n\nContext: {context}\n\nUser: {user_message}\n\nAssistant:"
        else:
            return f"{system_context}\n\nUser: {user_message}\n\nAssistant:"
    
    def _get_fallback_response(self, message: str) -> str:
        """Respuesta de respaldo si Ollama falla"""
        
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["help", "ayuda", "emergency", "emergencia"]):
            return "ðŸ†˜ I understand you need help. Your message has been received and will be reviewed immediately by our emergency response team. You are not alone."
        
        elif any(word in message_lower for word in ["danger", "peligro", "threat", "amenaza"]):
            return "ðŸ”´ Your safety is our priority. We're processing your urgent request. Please stay safe and wait for our response. If in immediate danger, contact local emergency services."
        
        elif any(word in message_lower for word in ["faith", "fe", "pray", "orar"]):
            return "ðŸ™ 'The Lord is my shepherd; I shall not want' - Psalm 23:1. We're here to support you in your faith journey. How can we assist you?"
        
        else:
            return "âœ… Message received. A team member will review your request and respond soon. In the meantime, know that you are being heard and help is on the way."
    
    async def analyze_threat_level(
        self,
        message: str,
        threat_type: str,
        location: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analiza nivel de amenaza usando IA
        
        Returns:
            Dict con anÃ¡lisis de amenaza
        """
        
        prompt = f"""Analyze this emergency situation and assess the threat level:

Message: {message}
Threat Type: {threat_type}
Location: {location or "Not specified"}

Provide analysis in JSON format:
{{
    "threat_level": "critical|high|medium|low",
    "urgency": "immediate|urgent|moderate|low",
    "risk_factors": ["factor1", "factor2"],
    "recommended_actions": ["action1", "action2"],
    "requires_immediate_intervention": true/false
}}
"""
        
        response = await self.generate_response(
            prompt,
            context="Threat Assessment Mode",
            model_type="advanced",
            max_tokens=300
        )
        
        if response["success"]:
            try:
                # Intentar parsear JSON de la respuesta
                text = response["response"]
                # Buscar JSON en la respuesta
                start = text.find("{")
                end = text.rfind("}") + 1
                if start >= 0 and end > start:
                    analysis = json.loads(text[start:end])
                    return analysis
            except:
                pass
        
        # AnÃ¡lisis de respaldo basado en keywords
        return self._keyword_threat_analysis(message, threat_type)
    
    def _keyword_threat_analysis(self, message: str, threat_type: str) -> Dict[str, Any]:
        """AnÃ¡lisis de amenaza basado en keywords"""
        
        message_lower = message.lower()
        
        critical_keywords = [
            "now", "ahora", "immediate", "inmediato",
            "dying", "muriendo", "attack", "ataque",
            "gun", "arma", "violence", "violencia"
        ]
        
        high_keywords = [
            "danger", "peligro", "threat", "amenaza",
            "persecution", "persecuciÃ³n", "hiding", "escondido"
        ]
        
        # Determinar nivel
        if any(kw in message_lower for kw in critical_keywords):
            threat_level = "critical"
            urgency = "immediate"
        elif any(kw in message_lower for kw in high_keywords):
            threat_level = "high"
            urgency = "urgent"
        else:
            threat_level = "medium"
            urgency = "moderate"
        
        return {
            "threat_level": threat_level,
            "urgency": urgency,
            "risk_factors": ["keyword_analysis"],
            "recommended_actions": ["immediate_response", "human_review"],
            "requires_immediate_intervention": threat_level == "critical"
        }
    
    async def close(self):
        """Cierra conexiones"""
        await self.client.aclose()


# ============================================================================
# ML MODELS MANAGER (956+ modelos entrenados)
# ============================================================================

class MLModelsManager:
    """Gestiona los 956+ modelos ML entrenados"""
    
    def __init__(self, models_dir: Path):
        self.models_dir = models_dir
        self.loaded_models: Dict[str, Any] = {}
        self.model_cache_size = 10  # Mantener 10 modelos en cache
        
    def list_available_models(self) -> List[str]:
        """Lista todos los modelos disponibles"""
        return [f.stem for f in self.models_dir.glob("*.pkl")]
    
    def load_model(self, model_id: str) -> Optional[Any]:
        """Carga un modelo especÃ­fico"""
        
        # Verificar cache
        if model_id in self.loaded_models:
            return self.loaded_models[model_id]
        
        # Cargar desde disco
        model_path = self.models_dir / f"{model_id}.pkl"
        if not model_path.exists():
            logger.warning(f"Model not found: {model_id}")
            return None
        
        try:
            with open(model_path, "rb") as f:
                model = pickle.load(f)
            
            # AÃ±adir a cache (con lÃ­mite)
            if len(self.loaded_models) >= self.model_cache_size:
                # Eliminar el mÃ¡s antiguo
                oldest_key = next(iter(self.loaded_models))
                del self.loaded_models[oldest_key]
            
            self.loaded_models[model_id] = model
            logger.info(f"âœ… Model loaded: {model_id}")
            return model
            
        except Exception as e:
            logger.error(f"Error loading model {model_id}: {e}")
            return None
    
    def predict(self, model_id: str, features: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Hace predicciÃ³n con un modelo"""
        
        model = self.load_model(model_id)
        if not model:
            return None
        
        try:
            # AquÃ­ irÃ­a la lÃ³gica especÃ­fica de predicciÃ³n
            # Dependiendo del tipo de modelo
            result = {
                "model_id": model_id,
                "prediction": "placeholder",  # Implementar segÃºn modelo
                "confidence": 0.0,
                "timestamp": datetime.now().isoformat()
            }
            return result
        except Exception as e:
            logger.error(f"Prediction error: {e}")
            return None


# ============================================================================
# UNIFIED AI INTEGRATION LAYER
# ============================================================================

class UnifiedAIIntegration:
    """Capa unificada que integra TODOS los sistemas de IA"""
    
    def __init__(
        self,
        project_root: Path,
        ollama_url: str = "http://localhost:11434"
    ):
        self.project_root = project_root
        
        # Inicializar componentes
        self.ollama = OllamaAIEngine(ollama_url)
        self.ml_models = MLModelsManager(project_root / "ml_models")
        
        # Referencias a otros sistemas (se conectarÃ¡n despuÃ©s)
        self.divine_protection = None
        self.emergency_contact = None
        
        logger.info("ðŸ§  Unified AI Integration Layer initialized")
    
    def connect_divine_protection(self, divine_protection_system):
        """Conecta con Divine Protection System"""
        self.divine_protection = divine_protection_system
        logger.info("âœ… AI Layer â†â†’ Divine Protection CONNECTED")
    
    def connect_emergency_contact(self, emergency_contact_system):
        """Conecta con Emergency Contact System"""
        self.emergency_contact = emergency_contact_system
        logger.info("âœ… AI Layer â†â†’ Emergency Contact CONNECTED")
    
    async def process_emergency_message(
        self,
        message: str,
        channel: str,
        user_id: str,
        threat_type: Optional[str] = None,
        location: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Procesa mensaje de emergencia con IA completa
        
        Returns:
            Dict con respuesta, anÃ¡lisis y acciones recomendadas
        """
        
        logger.info(f"ðŸ§  Processing emergency message from {channel}")
        
        # 1. AnÃ¡lisis de amenaza con IA
        threat_analysis = await self.ollama.analyze_threat_level(
            message=message,
            threat_type=threat_type or "unknown",
            location=location
        )
        
        # 2. Generar respuesta inteligente
        response_data = await self.ollama.generate_response(
            prompt=message,
            context=f"Emergency request via {channel}. Threat level: {threat_analysis['threat_level']}",
            model_type="instruct"
        )
        
        # 3. Integrar con Divine Protection si es crÃ­tico
        divine_action = None
        if threat_analysis.get("requires_immediate_intervention"):
            if self.divine_protection:
                try:
                    # Registrar persona en sistema de protecciÃ³n
                    divine_action = await self._activate_divine_protection(
                        user_id=user_id,
                        threat_analysis=threat_analysis,
                        location=location
                    )
                except Exception as e:
                    logger.error(f"Error activating divine protection: {e}")
        
        # 4. Compilar respuesta completa
        result = {
            "response_text": response_data.get("response") or response_data.get("fallback_response"),
            "threat_analysis": threat_analysis,
            "ai_model_used": response_data.get("model"),
            "divine_protection_activated": divine_action is not None,
            "recommended_actions": threat_analysis.get("recommended_actions", []),
            "requires_human_review": threat_analysis["threat_level"] in ["critical", "high"],
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"âœ… Message processed - Threat: {threat_analysis['threat_level']}, Divine: {divine_action is not None}")
        
        return result
    
    async def _activate_divine_protection(
        self,
        user_id: str,
        threat_analysis: Dict[str, Any],
        location: Optional[str]
    ) -> Dict[str, Any]:
        """Activa sistema de Divine Protection para persona en peligro"""
        
        if not self.divine_protection:
            return None
        
        try:
            # Registrar persona protegida
            person = self.divine_protection.register_protected_person(
                person_id=f"EMERGENCY_{user_id}",
                location_zone=location or "UNKNOWN",
                skills=[],
                initial_needs={}
            )
            
            # Evaluar amenaza
            threat_level = self.divine_protection.assess_threat_level(person.person_id)
            
            logger.warning(f"ðŸ›¡ï¸ DIVINE PROTECTION ACTIVATED for {user_id} - Threat: {threat_level.value}")
            
            return {
                "person_id": person.person_id,
                "threat_level": threat_level.value,
                "protection_activated": True
            }
            
        except Exception as e:
            logger.exception(f"Error in divine protection activation: {e}")
            return None
    
    async def generate_telegram_response(
        self,
        message: str,
        chat_id: str,
        username: Optional[str] = None,
        conversation_history: Optional[List[Dict[str, Any]]] = None,
        cognitive_insights: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Genera respuesta especÃ­fica para Telegram con MEMORIA y METACORTEX Core.
        
        Args:
            message: Mensaje actual del usuario
            chat_id: ID Ãºnico del chat
            username: Nombre de usuario (opcional)
            conversation_history: Historial de conversaciÃ³n previo
            cognitive_insights: Insights del CognitiveAgent (BDI, afecto, planificaciÃ³n)
        
        Returns:
            Texto de respuesta formateado para Telegram
        """
        
        # Construir contexto enriquecido
        enriched_message = message
        if conversation_history:
            # Agregar contexto de conversaciÃ³n previa
            history_summary = "\n".join([
                f"{msg['sender']}: {msg['message'][:50]}..." 
                for msg in conversation_history[-3:]  # Ãšltimos 3 mensajes
            ])
            enriched_message = f"[Contexto previo:\n{history_summary}\n]\n\nMensaje actual: {message}"
        
        result = await self.process_emergency_message(
            message=enriched_message,
            channel="telegram",
            user_id=chat_id,
            threat_type="unknown"
        )
        
        # Formatear para Telegram con informaciÃ³n cognitiva
        response = f"ðŸ›¡ï¸ *METACORTEX Divine Protection*\n\n"
        
        # Si hay insights cognitivos, usar informaciÃ³n mÃ¡s rica
        if cognitive_insights:
            if cognitive_insights.get('empathy_level', 0) > 0.7:
                response += "_I understand this is a difficult situation. You are not alone._\n\n"
            
            if cognitive_insights.get('action_plan'):
                response += f"ðŸ“‹ *Recommended Actions*:\n"
                for step in cognitive_insights['action_plan'][:3]:  # Primeros 3 pasos
                    response += f"  â€¢ {step}\n"
                response += "\n"
        
        response += f"{result['response_text']}\n\n"
        
        if result['divine_protection_activated']:
            response += "âœ… *Divine Protection System ACTIVATED*\n"
            response += "You are now under our protection network.\n\n"
        
        if result['threat_analysis']['threat_level'] == 'critical':
            response += "ðŸš¨ *CRITICAL SITUATION DETECTED*\n"
            response += "Emergency response team notified.\n"
            response += "Expected response: < 5 minutes\n\n"
        
        # Agregar memoria de conversaciÃ³n
        if conversation_history and len(conversation_history) > 1:
            response += f"_I remember our previous conversation. How can I help you further?_\n\n"
        
        response += "_Your request has been recorded and is being processed._"
        
        return response
    
    async def generate_whatsapp_response(
        self,
        message: str,
        phone_number: str
    ) -> str:
        """Genera respuesta para WhatsApp"""
        
        result = await self.process_emergency_message(
            message=message,
            channel="whatsapp",
            user_id=phone_number
        )
        
        # Formato mÃ¡s simple para WhatsApp (sin markdown)
        response = "ðŸ›¡ï¸ METACORTEX Divine Protection\n\n"
        response += f"{result['response_text']}\n\n"
        
        if result['divine_protection_activated']:
            response += "âœ… Divine Protection ACTIVE\n\n"
        
        response += "Your message is being processed by our team."
        
        return response
    
    async def generate_web_response(
        self,
        message: str,
        session_id: str,
        additional_data: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Genera respuesta para interfaz web"""
        
        result = await self.process_emergency_message(
            message=message,
            channel="web",
            user_id=session_id,
            threat_type=additional_data.get("threat_type") if additional_data else None,
            location=additional_data.get("location") if additional_data else None
        )
        
        # Respuesta estructurada para web
        return {
            "success": True,
            "message": result['response_text'],
            "threat_level": result['threat_analysis']['threat_level'],
            "urgency": result['threat_analysis']['urgency'],
            "protection_active": result['divine_protection_activated'],
            "next_steps": result['recommended_actions'],
            "requires_follow_up": result['requires_human_review'],
            "timestamp": result['timestamp']
        }
    
    async def close(self):
        """Cierra todas las conexiones"""
        await self.ollama.close()
        logger.info("ðŸ§  AI Integration Layer closed")


# ============================================================================
# GLOBAL INSTANCE
# ============================================================================

_global_ai_integration: Optional[UnifiedAIIntegration] = None


def get_ai_integration(project_root: Optional[Path] = None) -> UnifiedAIIntegration:
    """Obtiene instancia global de AI Integration"""
    global _global_ai_integration
    
    if _global_ai_integration is None:
        if project_root is None:
            project_root = Path.cwd()
        
        _global_ai_integration = UnifiedAIIntegration(project_root)
        logger.info("âœ… Global AI Integration initialized")
    
    return _global_ai_integration


# ============================================================================
# TESTING
# ============================================================================

async def test_ai_integration():
    """Test bÃ¡sico del sistema"""
    
    ai = get_ai_integration()
    
    # Test 1: Respuesta bÃ¡sica
    response = await ai.ollama.generate_response(
        "I need help, I'm being persecuted for my faith"
    )
    print("Response:", response)
    
    # Test 2: AnÃ¡lisis de amenaza
    threat = await ai.ollama.analyze_threat_level(
        message="I'm in immediate danger, they found my location",
        threat_type="persecution_religious",
        location="Middle East"
    )
    print("Threat Analysis:", threat)
    
    await ai.close()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(test_ai_integration())
