from metacortex_sinaptico.utils import AgentConfig
from metacortex_sinaptico.utils import AgentConfig
#!/usr/bin/env python3
"""
ğŸ¤–ğŸ–ï¸âš¡ METACORTEX ML Pipeline v3.0 - MILITARY GRADE EVOLUTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ARQUITECTURA EVOLUCIONADA - GRADO MILITAR AVANZADO:
    pass  # TODO: Implementar
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ–ï¸ CARACTERÃSTICAS MILITARY GRADE v3.0:
â”œâ”€â”€ ğŸ§¬ Adaptive ML Operations (MLOps auto-ajustables)
â”œâ”€â”€ ğŸ”® Predictive Model Scaling (escalado predictivo con RL)
â”œâ”€â”€ ğŸ¥ Self-Healing Training (auto-correcciÃ³n de entrenamientos)
â”œâ”€â”€ ğŸ“ˆ Intelligent Hyperparameter Optimization (auto-tuning)
â”œâ”€â”€ ğŸ“Š Advanced Telemetry (telemetrÃ­a militar multi-nivel)
â”œâ”€â”€ ğŸ›£ï¸ Neural Model Routing (rutas de modelos optimizadas)
â”œâ”€â”€ ğŸŒ Distributed Training (entrenamiento distribuido)
â”œâ”€â”€ ğŸ§¬ Auto-Evolution (auto-evoluciÃ³n de modelos)
â”œâ”€â”€ ğŸ” Military-Grade Model Security (seguridad de modelos)
â”œâ”€â”€ ğŸ¯ Adaptive Resource Allocation (asignaciÃ³n adaptativa)
â”œâ”€â”€ ğŸ§  Cognitive Model Selection (selecciÃ³n cognitiva)
â”œâ”€â”€ ğŸ’¾ Persistent Training State (gestiÃ³n de estado persistente)
â””â”€â”€ ğŸš€ Zero-Downtime Model Updates (actualizaciones sin downtime)

ğŸ”— CONEXIONES SIMBIÃ“TICAS AVANZADAS v3.0:
â”œâ”€â”€ ML Pipeline â†” Neural Network (mensajerÃ­a asÃ­ncrona)
â”œâ”€â”€ ML Pipeline â†” Cognitive Agent (razonamiento ML distribuido)
â”œâ”€â”€ ML Pipeline â†” Memory System (aprendizaje con contexto)
â”œâ”€â”€ ML Pipeline â†” Advanced Cache (cachÃ© de modelos multi-nivel)
â”œâ”€â”€ ML Pipeline â†” Ollama Integration (generaciÃ³n aumentada)
â”œâ”€â”€ ML Pipeline â†” Programming Agent (materializaciÃ³n de cÃ³digo ML)
â”œâ”€â”€ ML Pipeline â†” Knowledge Connector (conocimiento de dominio)
â”œâ”€â”€ ML Pipeline â†” Telemetry System (mÃ©tricas militar-grade)
â””â”€â”€ ML Pipeline â†” Event Sourcing (registro completo de eventos)

ğŸ¯ FEATURES MILITARES ACTIVADOS:
â”œâ”€â”€ âš¡ Circuit Breaker Adaptativo (fallas de entrenamiento)
â”œâ”€â”€ ğŸšï¸ Rate Limiting Inteligente (control de recursos)
â”œâ”€â”€ ğŸ“ Event Sourcing (10,000 eventos de entrenamiento)
â”œâ”€â”€ ğŸ“Š SLA Monitoring (99.9% uptime target)
â”œâ”€â”€ ğŸ”„ Auto-Retry con Backoff Exponencial
â”œâ”€â”€ ğŸ§  Model Performance Prediction (predicciÃ³n de rendimiento)
â”œâ”€â”€ ğŸŒŠ Backpressure Control (control de carga)
â”œâ”€â”€ ğŸ­ Multi-Model Ensemble (ensambles adaptativos)
â”œâ”€â”€ ğŸ” Model Versioning & Rollback (versiones + rollback)
â””â”€â”€ ğŸš€ Continuous Model Deployment (despliegue continuo)

ğŸ—ï¸ ARQUITECTURA MULTI-CAPA:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 1: NEURAL SYMBIOTIC CONNECTIONS                      â”‚
â”‚  â†“ ComunicaciÃ³n bidireccional con todo el ecosistema       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 2: MEMORY TRIAD INTEGRATION                          â”‚
â”‚  â†“ Episodic + Semantic + Working Memory para contexto      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 3: INTELLIGENT TRAINING ORCHESTRATION                â”‚
â”‚  â†“ Auto-tuning, auto-scaling, auto-healing                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 4: MILITARY FEATURES                                 â”‚
â”‚  â†“ Circuit breakers, rate limiting, event sourcing         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 5: ADVANCED TELEMETRY                                â”‚
â”‚  â†“ MÃ©tricas, SLA, performance tracking                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CAPA 6: MODEL LIFECYCLE MANAGEMENT                        â”‚
â”‚  â†“ Versioning, deployment, rollback, monitoring            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš™ï¸ VERSIÃ“N: 3.0.0 (MILITARY GRADE EVOLUTION)
ğŸ“… EVOLUTION DATE: 2025-01-06
ğŸ‘¨â€ğŸ’» ARCHITECT: METACORTEX AUTONOMOUS SYSTEM
ğŸ¯ MISSION: MÃXIMA CONFIABILIDAD + INTELIGENCIA ADAPTATIVA

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import hashlib
import json
import logging
import pickle
import queue
import threading
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any

import numpy as np
from collections import deque
from collections import Counter
import pandas as pd  # Lazy import para evitar circular imports
# pandas se importa lazy dentro de funciones para evitar circular imports

# ML Core
try:
    from sklearn.ensemble import (
        GradientBoostingClassifier,
        GradientBoostingRegressor,
        RandomForestClassifier,
        RandomForestRegressor,
    )
    from sklearn.linear_model import Lasso, LinearRegression, LogisticRegression, Ridge
    from sklearn.metrics import (
        accuracy_score,
        confusion_matrix,
        f1_score,
        mean_squared_error,
        precision_score,
        r2_score,
        recall_score,
    )
    from sklearn.model_selection import cross_val_score, train_test_split
    from sklearn.neural_network import MLPClassifier, MLPRegressor
    from sklearn.preprocessing import LabelEncoder, StandardScaler
    from sklearn.svm import SVC, SVR
    from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

    SKLEARN_AVAILABLE = True
except ImportError as e:
    logger.error(f"Error: {e}", exc_info=True)
    SKLEARN_AVAILABLE = False
    # No usar logging aquÃ­ porque aÃºn no estÃ¡ configurado
    print(f"âš ï¸ scikit-learn no disponible: {e}")

# Deep Learning
try:
    import torch
    from torch import nn

    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# Transformers
try:
    from transformers import AutoModel, AutoTokenizer

    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

# ğŸ§  INTEGRACIÃ“N CON METACORTEX
try:
    from neural_symbiotic_network import get_neural_network

    NEURAL_NETWORK_AVAILABLE = True
except ImportError:
    NEURAL_NETWORK_AVAILABLE = False
    logging.warning("âš ï¸ Neural network no disponible")

try:
    from memory_system import get_memory

    MEMORY_AVAILABLE = True
except ImportError:
    MEMORY_AVAILABLE = False
    logging.warning("âš ï¸ Memory system no disponible")

try:
    from advanced_cache_system import get_global_cache

    CACHE_AVAILABLE = True
except ImportError:
    CACHE_AVAILABLE = False
    logging.warning("âš ï¸ Cache system no disponible")

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ–ï¸ ENUMERATIONS v3.0 - MILITARY GRADE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ModelType(Enum):
    """Tipos de modelos soportados (v3.0 expandido)"""

    CLASSIFICATION = "classification"
    REGRESSION = "regression"
    CLUSTERING = "clustering"
    NLP = "nlp"
    VISION = "vision"
    TIME_SERIES = "time_series"
    # ğŸ†• v3.0
    REINFORCEMENT_LEARNING = "reinforcement_learning"  # RL agents
    ENSEMBLE = "ensemble"  # Ensambles multi-modelo
    AUTOML = "automl"  # AutoML meta-learning


class TrainingStatus(Enum):
    """Estados de entrenamiento (v3.0 mejorado)"""

    PENDING = "pending"
    PREPROCESSING = "preprocessing"
    TRAINING = "training"
    EVALUATING = "evaluating"
    COMPLETED = "completed"
    FAILED = "failed"
    DEPLOYED = "deployed"
    # ğŸ†• v3.0
    OPTIMIZING = "optimizing"  # Hyperparameter tuning
    RECOVERING = "recovering"  # Auto-healing training
    HIBERNATING = "hibernating"  # Modelo pausado
    ROLLING_BACK = "rolling_back"  # Rollback a versiÃ³n anterior
    UPGRADING = "upgrading"  # Upgrade del modelo


class ModelHealth(Enum):
    """ğŸ†• v3.0: Estado de salud del modelo"""

    EXCELLENT = "excellent"  # >95% performance
    GOOD = "good"  # 85-95% performance
    FAIR = "fair"  # 75-85% performance
    DEGRADED = "degraded"  # 60-75% performance
    CRITICAL = "critical"  # <60% performance


class TrainingPriority(Enum):
    """ğŸ†• v3.0: Prioridades de entrenamiento"""

    CRITICAL = "critical"  # Entrenamiento urgente
    HIGH = "high"  # Alta prioridad
    NORMAL = "normal"  # Prioridad normal
    LOW = "low"  # Baja prioridad
    BACKGROUND = "background"  # Entrenamiento en segundo plano


class DeploymentMode(Enum):
    """ğŸ†• v3.0: Modos de despliegue"""

    CANARY = "canary"  # Despliegue gradual (10% trÃ¡fico)
    BLUE_GREEN = "blue_green"  # Dos versiones simultÃ¡neas
    SHADOW = "shadow"  # Modo shadow (sin exponer)
    FULL = "full"  # Despliegue completo
    A_B_TEST = "a_b_test"  # A/B testing
    ROLLBACK = "rollback"  # Rollback a versiÃ³n anterior


@dataclass
class TrainingConfig:
    """ConfiguraciÃ³n de entrenamiento"""

    model_type: ModelType
    model_name: str
    algorithm: str
    hyperparameters: dict[str, Any] = field(default_factory=dict)

    # Data
    train_data_path: str | None = None
    validation_split: float = 0.2
    test_split: float = 0.1

    # Training
    epochs: int = 10
    batch_size: int = 32
    learning_rate: float = 0.001
    early_stopping: bool = True
    patience: int = 5

    # Evaluation
    metrics: list[str] = field(default_factory=lambda: ["accuracy", "f1"])
    cross_validation_folds: int = 5

    # MLOps
    auto_deploy: bool = False
    min_accuracy: float = 0.8
    save_checkpoints: bool = True
    checkpoint_frequency: int = 5


@dataclass
class TrainingResult:
    """Resultado de entrenamiento"""

    model_id: str
    model_type: ModelType
    algorithm: str
    status: TrainingStatus

    # Metrics
    train_metrics: dict[str, float] = field(default_factory=dict)
    val_metrics: dict[str, float] = field(default_factory=dict)
    test_metrics: dict[str, float] = field(default_factory=dict)

    # Model info
    model_path: str | None = None
    model_size_mb: float = 0.0
    training_time_seconds: float = 0.0

    # Data info
    num_train_samples: int = 0
    num_val_samples: int = 0
    num_test_samples: int = 0
    num_features: int = 0

    # Timestamps
    started_at: datetime = field(default_factory=datetime.now)
    completed_at: datetime | None = None

    # Metadata
    metadata: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        """Convertir a diccionario"""
        return {
            "model_id": self.model_id,
            "model_type": self.model_type.value,
            "algorithm": self.algorithm,
            "status": self.status.value,
            "train_metrics": self.train_metrics,
            "val_metrics": self.val_metrics,
            "test_metrics": self.test_metrics,
            "model_path": self.model_path,
            "model_size_mb": self.model_size_mb,
            "training_time_seconds": self.training_time_seconds,
            "num_train_samples": self.num_train_samples,
            "num_val_samples": self.num_val_samples,
            "num_test_samples": self.num_test_samples,
            "num_features": self.num_features,
            "started_at": self.started_at.isoformat(),
            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
            "metadata": self.metadata,
        }


class MilitaryGradeMLPipeline:
    """
    ğŸ–ï¸ ML Pipeline de Grado Militar con Conexiones SimbiÃ³ticas v3.0

    ARQUITECTURA AVANZADA:
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

    1. NEURAL SYMBIOTIC CONNECTIONS (Conexiones SimbiÃ³ticas)
       - Neural Network (red neuronal simbiÃ³tica asÃ­ncrona)
       - Cognitive Agent (agente cognitivo BDI con razonamiento ML)
       - Programming Agent (materializaciÃ³n de pipelines ML)
       - Knowledge Connector (acceso a conocimiento de dominio ML)
       - Ollama Integration (generaciÃ³n aumentada de modelos)

    2. MEMORY TRIAD (TrÃ­o de Memoria)
       - Episodic Memory (historial de entrenamientos)
       - Semantic Memory (conocimiento ML acumulado)
       - Working Memory (contexto activo de entrenamiento)

    3. INTELLIGENT TRAINING ORCHESTRATION (OrquestaciÃ³n Inteligente)
       - Auto-tuning (ajuste automÃ¡tico de hiperparÃ¡metros)
       - Auto-scaling (escalado dinÃ¡mico de recursos)
       - Auto-healing (recuperaciÃ³n automÃ¡tica de fallos)

    4. MILITARY FEATURES (CaracterÃ­sticas Militares)
       - Circuit Breaker (protecciÃ³n contra fallos en cascada)
       - Rate Limiting (control de carga de entrenamiento)
       - Event Sourcing (registro completo de eventos ML)
       - SLA Monitoring (monitoreo de objetivos de rendimiento)

    5. ADVANCED TELEMETRY (TelemetrÃ­a Avanzada)
       - MÃ©tricas de entrenamiento multi-nivel
       - Performance tracking en tiempo real
       - Resource utilization monitoring
       - Model drift detection

    6. MODEL LIFECYCLE MANAGEMENT (GestiÃ³n de Ciclo de Vida)
       - Versioning (control de versiones de modelos)
       - Deployment strategies (canary, blue-green, shadow)
       - Rollback automÃ¡tico
       - A/B testing integrado
    """

    def __init__(
        self,
        models_dir: str = "ml_models",
        data_dir: str = "ml_data",
        enable_cache: bool = True,
        enable_continuous_learning: bool = True,
        enable_perpetual_mode: bool = True,
        # ğŸ†• v3.0 MILITARY FEATURES
        enable_circuit_breaker: bool = True,
        enable_rate_limiting: bool = True,
        enable_event_sourcing: bool = True,
        enable_telemetry: bool = True,
        enable_auto_healing: bool = True,
    ):
        """
        ğŸ–ï¸ Inicializar ML Pipeline MILITARY GRADE con 6 FASES

        FASE 1: Setup Base
        FASE 2: Memory Triad
        FASE 3: Symbiotic Connections (8+ conexiones bidireccionales)
        FASE 4: Military Features
        FASE 5: Advanced Telemetry
        FASE 6: Perpetual Training Mode

        Args:
            models_dir: Directorio para guardar modelos
            data_dir: Directorio para datos de entrenamiento
            enable_cache: Habilitar cachÃ© de resultados
            enable_continuous_learning: Habilitar aprendizaje continuo
            enable_perpetual_mode: Habilitar entrenamiento perpetuo
            enable_circuit_breaker: Habilitar circuit breaker adaptativo
            enable_rate_limiting: Habilitar rate limiting inteligente
            enable_event_sourcing: Habilitar event sourcing
            enable_telemetry: Habilitar telemetrÃ­a avanzada
            enable_auto_healing: Habilitar auto-healing
        """
        logger.info("ğŸ–ï¸ Inicializando ML Pipeline MILITARY GRADE v3.0...")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 1: SETUP BASE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        self.models_dir = Path(models_dir)
        self.data_dir = Path(data_dir)
        self.models_dir.mkdir(exist_ok=True, parents=True)
        self.data_dir.mkdir(exist_ok=True, parents=True)

        self.enable_cache = enable_cache and CACHE_AVAILABLE
        self.enable_continuous_learning = enable_continuous_learning
        self.enable_perpetual_mode = enable_perpetual_mode

        # ğŸ†• v3.0 Military Flags
        self.enable_circuit_breaker = enable_circuit_breaker
        self.enable_rate_limiting = enable_rate_limiting
        self.enable_event_sourcing = enable_event_sourcing
        self.enable_telemetry = enable_telemetry
        self.enable_auto_healing = enable_auto_healing

        logger.info("âœ… FASE 1: Setup Base completado")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 2: MEMORY TRIAD INTEGRATION
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # Memory System (Episodic + Semantic)
        self.memory = get_memory() if MEMORY_AVAILABLE else None

        # Advanced Cache (L1/L2/L3)
        self.cache = get_global_cache() if self.enable_cache else None

        # Working Memory (contexto activo)
        self.working_memory: dict[str, Any] = {
            "active_trainings": {},
            "recent_evaluations": [],
            "current_context": {},
        }

        logger.info("âœ… FASE 2: Memory Triad configurado")
        if self.memory:
            logger.info("   â”œâ”€ Episodic Memory: âœ“")
            logger.info("   â”œâ”€ Semantic Memory: âœ“")
        if self.cache:
            logger.info("   â””â”€ Cache System (L1/L2/L3): âœ“")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 2.5: INITIALIZE METRICS (ANTES de conexiones)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        self.metrics: dict[str, Any] = {
            "models_trained": 0,
            "models_deployed": 0,
            "training_failures": 0,
            "training_success_rate": 0.0,
            "avg_training_time_seconds": 0.0,
            "total_predictions": 0,
            "circuit_breaker_trips": 0,
            "rate_limit_hits": 0,
            "auto_healing_activations": 0,
            "symbiotic_messages_sent": 0,
            "symbiotic_messages_received": 0,
            "neural_connections_active": 0,
        }

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 3: SYMBIOTIC CONNECTIONS (8+ CONEXIONES BIDIRECCIONALES)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        self.symbiotic_connections: dict[str, Any] = {}
        self._establish_symbiotic_connections()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 4: MILITARY FEATURES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        self._activate_military_features()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 5: ADVANCED TELEMETRY (Ya inicializado en FASE 2.5)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("âœ… FASE 5: Advanced Telemetry activado")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FASE 6: STATE MANAGEMENT
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # Training history
        self.training_history: list[TrainingResult] = []
        self._load_training_history()

        # Active models
        self.active_models: dict[str, Any] = {}

        # Deployed models (para retrocompatibilidad)
        self.deployed_models: dict[str, Any] = {}

        # Auto-load deployed models
        self._auto_load_deployed_models()

        # Queue de entrenamiento
        self.training_queue: queue.Queue = queue.Queue()
        self.training_thread: threading.Thread | None = None
        self.perpetual_running = False

        # Auto-reentrenamiento
        self.retraining_schedule: dict[str, datetime] = {}
        self.retraining_interval = timedelta(hours=24)

        logger.info("âœ… FASE 6: State Management completado")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SYSTEM STATUS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("âœ… ML Pipeline MILITARY GRADE v3.0 inicializado")
        logger.info(f"   Sklearn: {'âœ“' if SKLEARN_AVAILABLE else 'âœ—'}")
        logger.info(f"   PyTorch: {'âœ“' if TORCH_AVAILABLE else 'âœ—'}")
        logger.info(f"   Transformers: {'âœ“' if TRANSFORMERS_AVAILABLE else 'âœ—'}")
        logger.info(f"   Neural Network: {'âœ“' if 'neural_network' in self.symbiotic_connections else 'âœ—'}")
        logger.info(f"   Memory System: {'âœ“' if self.memory else 'âœ—'}")
        logger.info(f"   Cache: {'âœ“' if self.cache else 'âœ—'}")
        logger.info(f"   Cognitive Agent: {'âœ“' if 'cognitive_agent' in self.symbiotic_connections else 'âœ—'}")
        logger.info(f"   Military Features: {'âœ“' if self.enable_circuit_breaker else 'âœ—'}")
        logger.info(f"   Conexiones SimbiÃ³ticas: {self.metrics['neural_connections_active']}")
        logger.info(f"   Modo perpetuo: {'âœ“' if self.enable_perpetual_mode else 'âœ—'}")

        # Iniciar modo perpetuo si estÃ¡ habilitado
        if self.enable_perpetual_mode:
            self.start_perpetual_training()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”— SYMBIOTIC CONNECTIONS (v3.0 MILITARY GRADE)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _establish_symbiotic_connections(self):
        """
        ğŸ”— Establecer CONEXIONES SIMBIÃ“TICAS con todo el ecosistema METACORTEX

        CONEXIONES BIDIRECCIONALES:
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        ML Pipeline â†” Neural Network (mensajerÃ­a asÃ­ncrona)
        ML Pipeline â†” Cognitive Agent (influencia cognitiva ML)
        ML Pipeline â†” Programming Agent (materializaciÃ³n de cÃ³digo ML)
        ML Pipeline â†” Knowledge Connector (conocimiento de dominio)
        ML Pipeline â†” Ollama Integration (generaciÃ³n aumentada)
        ML Pipeline â†” Memory System (aprendizaje con contexto)
        ML Pipeline â†” Advanced Cache (cachÃ© de modelos)
        ML Pipeline â†” Telemetry System (mÃ©tricas avanzadas)
        """
        logger.info("ğŸ”— Estableciendo conexiones simbiÃ³ticas v3.0...")
        
        # Inicializar neural_network como None
        self.neural_network = None

        # 1. Neural Network (Red Neuronal SimbiÃ³tica AsÃ­ncrona)
        if NEURAL_NETWORK_AVAILABLE:
            try:
                from neural_symbiotic_network import get_neural_network

                neural_net = get_neural_network()
                neural_net.register_module(
                    "ml_pipeline_military_v3",
                    self,
                    capabilities=[
                        "train_model_advanced",
                        "evaluate_model_cognitive",
                        "deploy_model_zero_downtime",
                        "continuous_training_adaptive",
                        "auto_retraining_intelligent",
                        "hyperparameter_optimization",
                        "model_ensemble_creation",
                        "model_drift_detection",
                        "auto_healing_training",
                        "predictive_scaling",
                    ],
                )
                self.symbiotic_connections["neural_network"] = neural_net
                self.neural_network = neural_net  # TambiÃ©n como atributo directo
                self.metrics["neural_connections_active"] += 1
                logger.info("âœ… Neural Network â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
            except Exception as e:
                logger.warning(f"âš ï¸ Neural Network no disponible: {e}")

        # 2. Cognitive Agent (Agente Cognitivo BDI con Razonamiento ML)
        try:
            from cognitive_agent import CognitiveAgent

            cognitive = CognitiveAgent()
            self.symbiotic_connections["cognitive_agent"] = cognitive
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… Cognitive Agent â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")

            # IntegraciÃ³n cognitiva avanzada (si existe metacortex_sinaptico) - USANDO SINGLETON
            try:
                from metacortex_sinaptico.core import get_cognitive_agent  # âœ… Singleton factory

                config = AgentConfig()
                cognitive_v2 = get_cognitive_agent(config=config)  # âœ… Singleton

                if hasattr(cognitive_v2, "neural_network") and cognitive_v2.neural_network:
                    cognitive_v2.neural_network.register_module(
                        "ml_pipeline_cognitive_bridge",
                        self,
                        capabilities=["ml_training", "ml_prediction", "ml_optimization"],
                    )
                    logger.info("âœ… ML Pipeline registrado en red neuronal cognitiva v2")

                self.symbiotic_connections["cognitive_agent_v2"] = cognitive_v2
                logger.info("ğŸ”„ Flujo BIDIRECCIONAL: ML â†â†’ CogniciÃ³n v2 activado")
            except Exception:
                pass  # Cognitive v2 es opcional

        except Exception as e:
            logger.warning(f"âš ï¸ Cognitive Agent no disponible: {e}")

        # 3. Programming Agent (MaterializaciÃ³n de cÃ³digo ML)
        try:
            from programming_agent import MetacortexUniversalProgrammingAgent

            prog_agent = MetacortexUniversalProgrammingAgent()
            self.symbiotic_connections["programming_agent"] = prog_agent
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… Programming Agent â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
        except Exception as e:
            logger.warning(f"âš ï¸ Programming Agent no disponible: {e}")

        # 4. Knowledge Connector (Acceso a Conocimiento de Dominio ML)
        try:
            from universal_knowledge_connector import get_knowledge_connector

            knowledge = get_knowledge_connector()
            self.symbiotic_connections["knowledge_connector"] = knowledge
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… Knowledge Connector â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
        except Exception as e:
            logger.warning(f"âš ï¸ Knowledge Connector no disponible: {e}")

        # 5. Ollama Integration (GeneraciÃ³n Aumentada de Modelos)
        try:
            from ollama_integration import get_ollama_integration

            ollama = get_ollama_integration()
            self.symbiotic_connections["ollama_integration"] = ollama
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… Ollama Integration â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
        except Exception as e:
            logger.warning(f"âš ï¸ Ollama Integration no disponible: {e}")

        # 6. LLM Integration (Compatibilidad con sistema existente)
        try:
            from llm_integration import get_llm

            llm = get_llm()
            self.symbiotic_connections["llm_integration"] = llm
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… LLM Integration â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
        except Exception as e:
            logger.warning(f"âš ï¸ LLM Integration no disponible: {e}")

        # 7. Cognitive Integration Bridge (Puente ML â†â†’ Cognitive)
        try:
            from cognitive_integration import get_cognitive_bridge

            bridge = get_cognitive_bridge()
            self.symbiotic_connections["cognitive_bridge"] = bridge
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… Cognitive Bridge â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
        except Exception as e:
            logger.warning(f"âš ï¸ Cognitive Bridge no disponible: {e}")

        # 8. Telemetry System (MÃ©tricas Avanzadas)
        try:
            from military_modules.telemetry_system import TelemetrySystem

            telemetry = TelemetrySystem()
            self.symbiotic_connections["telemetry"] = telemetry
            self.metrics["neural_connections_active"] += 1
            logger.info("âœ… Telemetry System â†â†’ ML Pipeline: CONECTADO BIDIRECCIONAL")
        except Exception as e:
            logger.warning(f"âš ï¸ Telemetry System no disponible: {e}")

        logger.info(f"âœ… FASE 3: {self.metrics['neural_connections_active']} conexiones simbiÃ³ticas establecidas")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ–ï¸ MILITARY FEATURES (v3.0)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _activate_military_features(self):
        """
        ğŸ–ï¸ Activar CARACTERÃSTICAS MILITARES v3.0

        FEATURES:
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        1. Circuit Breaker Adaptativo (protecciÃ³n contra fallos)
        2. Rate Limiting Inteligente (60 trainings/minute)
        3. Event Sourcing (10,000 eventos de entrenamiento)
        4. SLA Monitoring (99.9% uptime target)
        """
        logger.info("ğŸ–ï¸ Activando Military Features...")

        # 1. Circuit Breaker (usando Neural Network v3.0)
        if self.enable_circuit_breaker and "neural_network" in self.symbiotic_connections:
            self.circuit_breaker = {
                "enabled": True,
                "failure_threshold": 5,
                "success_threshold": 2,
                "timeout_seconds": 60,
                "state": "CLOSED",  # CLOSED, OPEN, HALF_OPEN
                "failures": 0,
                "successes": 0,
                "last_failure_time": None,
            }
            logger.info("   â”œâ”€ Circuit Breaker: âœ“ (threshold=5)")
        else:
            self.circuit_breaker = {"enabled": False}

        # 2. Rate Limiter (60 trainings por minuto)
        if self.enable_rate_limiting:
            self.rate_limiter = {
                "enabled": True,
                "max_trainings_per_minute": 60,
                "current_window": [],
                "window_size_seconds": 60,
            }
            logger.info("   â”œâ”€ Rate Limiter: âœ“ (60 train/min)")
        else:
            self.rate_limiter = {"enabled": False}

        # 3. Event Sourcing (registro completo de eventos ML)
        if self.enable_event_sourcing:

            self.event_log: deque = deque(maxlen=10000)
            logger.info("   â”œâ”€ Event Sourcing: âœ“ (10,000 eventos)")
        else:
            self.event_log = None

        # 4. SLA Targets (Service Level Agreement)
        self.sla_targets = {
            "training_success_rate": 0.999,  # 99.9% Ã©xito
            "max_training_time_seconds": 300,  # 5 min max
            "max_deployment_time_seconds": 30,  # 30s max
            "model_availability": 0.999,  # 99.9% uptime
        }
        logger.info("   â””â”€ SLA Monitoring: âœ“ (99.9% targets)")

        logger.info("âœ… FASE 4: Military Features activados")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”„ HELPER METHODS (Circuit Breaker, Rate Limiting, Event Sourcing)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _check_circuit_breaker(self) -> bool:
        """Verificar estado del circuit breaker"""
        if not self.circuit_breaker.get("enabled"):
            return True

        cb = self.circuit_breaker
        if cb["state"] == "OPEN":
            # Verificar si debemos intentar de nuevo
            if cb["last_failure_time"]:
                elapsed = (datetime.now() - cb["last_failure_time"]).total_seconds()
                if elapsed > cb["timeout_seconds"]:
                    cb["state"] = "HALF_OPEN"
                    cb["failures"] = 0
                    logger.info("ğŸ”„ Circuit Breaker: HALF_OPEN (intentando recuperaciÃ³n)")
                else:
                    logger.warning("âš ï¸ Circuit Breaker: OPEN (bloqueando entrenamiento)")
                    self.metrics["circuit_breaker_trips"] += 1
                    return False

        return True

    def _record_training_success(self):
        """Registrar entrenamiento exitoso (Circuit Breaker)"""
        if not self.circuit_breaker.get("enabled"):
            return

        cb = self.circuit_breaker
        cb["successes"] += 1
        cb["failures"] = 0

        if cb["state"] == "HALF_OPEN" and cb["successes"] >= cb["success_threshold"]:
            cb["state"] = "CLOSED"
            logger.info("âœ… Circuit Breaker: CLOSED (recuperado)")

    def _record_training_failure(self):
        """Registrar fallo de entrenamiento (Circuit Breaker)"""
        if not self.circuit_breaker.get("enabled"):
            return

        cb = self.circuit_breaker
        cb["failures"] += 1
        cb["successes"] = 0
        cb["last_failure_time"] = datetime.now()

        if cb["failures"] >= cb["failure_threshold"]:
            cb["state"] = "OPEN"
            logger.error("âŒ Circuit Breaker: OPEN (demasiados fallos)")

    def _check_rate_limit(self) -> bool:
        """Verificar rate limiting"""
        if not self.rate_limiter.get("enabled"):
            return True

        rl = self.rate_limiter
        now = time.time()

        # Limpiar ventana antigua
        rl["current_window"] = [t for t in rl["current_window"] if now - t < rl["window_size_seconds"]]

        # Verificar lÃ­mite
        if len(rl["current_window"]) >= rl["max_trainings_per_minute"]:
            logger.warning("âš ï¸ Rate Limit alcanzado (60 train/min)")
            self.metrics["rate_limit_hits"] += 1
            return False

        # Agregar timestamp actual
        rl["current_window"].append(now)
        return True

    def _log_event(self, event_type: str, data: dict[str, Any]):
        """Registrar evento en Event Sourcing"""
        if not self.event_log:
            return

        event = {
            "timestamp": datetime.now().isoformat(),
            "type": event_type,
            "data": data,
        }
        self.event_log.append(event)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ§  COGNITIVE AGENT INTEGRATION (Metacortex SinÃ¡ptico)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _notify_cognitive_agent(self, event_type: str, data: dict[str, Any]):
        """Notificar al Cognitive Agent sobre eventos ML"""
        if "cognitive_bridge" in self.symbiotic_connections:
            try:
                bridge = self.symbiotic_connections["cognitive_bridge"]
                if event_type == "ml_prediction":
                    bridge.notify_ml_prediction(data.get("prediction_type", "general"), data)
                elif event_type == "ml_training_completed":
                    bridge.notify_ml_feedback(data.get("model_id", "unknown"), data)
            except Exception as e:
                logger.debug(f"Error notificando al Cognitive: {e}")

        # ğŸ†• CONEXIÃ“N A METACORTEX SINÃPTICO (Sistema Cognitivo)
        self.cognitive_agent = None
        try:
            from metacortex_sinaptico.core import get_cognitive_agent  # âœ… Singleton factory

            # Crear configuraciÃ³n para el agente cognitivo
            config = AgentConfig()

            # Crear agente cognitivo (SINGLETON - evita 261 duplicados)
            self.cognitive_agent = get_cognitive_agent(config=config)

            # Registrar este mÃ³dulo en la red neuronal del agente cognitivo
            if (
                hasattr(self.cognitive_agent, "neural_network")
                and self.cognitive_agent.neural_network
            ):
                self.cognitive_agent.neural_network.register_module(
                    "ml_pipeline_cognitive",
                    self,
                    capabilities=["ml_training", "ml_prediction", "ml_optimization"],
                )
                logger.info("âœ… ML Pipeline registrado en red neuronal cognitiva")

            logger.info("âœ… ML Pipeline integrado con Metacortex SinÃ¡ptico")
            logger.info("ğŸ”„ Flujo BIDIRECCIONAL: ML â†â†’ CogniciÃ³n activado")

        except ImportError as e:
            logger.warning(f"âš ï¸ Metacortex SinÃ¡ptico no disponible: {e}")
        except Exception as e:
            logger.warning(f"âš ï¸ Error integrando con sistema cognitivo: {e}")

        # Training history
        self.training_history: list[TrainingResult] = []
        self._load_training_history()

        # Active models
        self.active_models: dict[str, Any] = {}

        # ğŸ†• DEPLOYED MODELS (para retrocompatibilidad)
        self.deployed_models: dict[str, Any] = {}

        # ğŸ†• AUTO-LOAD DEPLOYED MODELS
        self._auto_load_deployed_models()

        # ğŸ†• QUEUE DE ENTRENAMIENTO
        self.training_queue: queue.Queue = queue.Queue()
        self.training_thread: threading.Thread | None = None
        self.perpetual_running = False

        # ğŸ†• AUTO-REENTRENAMIENTO
        self.retraining_schedule: dict[str, datetime] = {}
        self.retraining_interval = timedelta(hours=24)  # Reentrenar cada 24h

        logger.info("âœ… ML Pipeline inicializado")
        logger.info(f"   Sklearn: {'âœ“' if SKLEARN_AVAILABLE else 'âœ—'}")
        logger.info(f"   PyTorch: {'âœ“' if TORCH_AVAILABLE else 'âœ—'}")
        logger.info(f"   Transformers: {'âœ“' if TRANSFORMERS_AVAILABLE else 'âœ—'}")
        logger.info(f"   Neural Network: {'âœ“' if self.neural_network else 'âœ—'}")
        logger.info(f"   Memory System: {'âœ“' if self.memory else 'âœ—'}")
        logger.info(f"   Cache: {'âœ“' if self.cache else 'âœ—'}")
        logger.info(f"   Modo perpetuo: {'âœ“' if self.enable_perpetual_mode else 'âœ—'}")
        logger.info(f"   Modelos: {self.models_dir}")
        logger.info(f"   Datos: {self.data_dir}")

        # ğŸ†• INICIAR MODO PERPETUO
        if self.enable_perpetual_mode:
            self.start_perpetual_training()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”„ MODO PERPETUO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def start_perpetual_training(self):
        """ğŸ†• Inicia el modo de entrenamiento perpetuo"""
        if self.training_thread and self.training_thread.is_alive():
            logger.warning("âš ï¸ Modo perpetuo ya estÃ¡ activo")
            return

        self.perpetual_running = True
        self.training_thread = threading.Thread(
            target=self._perpetual_training_loop,
            daemon=True,
            name="MLPipelinePerpetual",
        )
        self.training_thread.start()
        logger.info("ğŸ¤– Modo perpetuo de ML Pipeline iniciado")

    def stop_perpetual_training(self):
        """ğŸ†• Detiene el modo perpetuo"""
        self.perpetual_running = False
        if self.training_thread:
            self.training_thread.join(timeout=10)
        logger.info("ğŸ›‘ Modo perpetuo de ML Pipeline detenido")

    def _perpetual_training_loop(self):
        """ğŸ†• Loop perpetuo de entrenamiento"""
        logger.info("ğŸ”„ Loop perpetuo iniciado")

        while self.perpetual_running:
            try:
                # 1. Procesar queue de entrenamientos
                try:
                    config = self.training_queue.get(timeout=60)
                    logger.info(f"ğŸ“‹ Procesando entrenamiento: {config.model_name}")

                    # Entrenar modelo
                    result = self.train_model(config)

                    if result.status == TrainingStatus.COMPLETED:
                        logger.info(f"âœ… Modelo entrenado: {result.model_id}")
                    else:
                        logger.warning(f"âš ï¸ Entrenamiento fallÃ³: {result.metadata.get('error')}")

                except queue.Empty:
                    pass  # No hay trabajos pendientes

                # 2. Verificar modelos que necesitan reentrenamiento
                self._check_retraining_schedule()

                # 3. Breve pausa
                time.sleep(10)

            except Exception as e:
                logger.error(f"âŒ Error en loop perpetuo: {e}", exc_info=True)
                time.sleep(60)

        logger.info("ğŸ›‘ Loop perpetuo detenido")

    def _check_retraining_schedule(self):
        """ğŸ†• Verifica si hay modelos que necesitan reentrenamiento"""
        now = datetime.now()

        for model_id, next_training in list(self.retraining_schedule.items()):
            if now >= next_training:
                logger.info(f"ğŸ“… Reentrenamiento programado para: {model_id}")

                # Buscar configuraciÃ³n original
                for result in self.training_history:
                    if result.model_id == model_id and result.status == TrainingStatus.DEPLOYED:
                        # Crear nueva config basada en la original
                        # (simplificado - en producciÃ³n cargar metadata completo)
                        config = TrainingConfig(
                            model_type=result.model_type,
                            model_name=result.metadata.get("model_name", f"retrain_{model_id}"),
                            algorithm=result.algorithm,
                            train_data_path=result.metadata.get("train_data_path"),
                        )

                        # Agregar a queue
                        self.enqueue_training(config)

                        # Reprogramar
                        self.retraining_schedule[model_id] = now + self.retraining_interval
                        break

    def enqueue_training(self, config: TrainingConfig):
        """ğŸ†• Agrega un entrenamiento a la queue"""
        self.training_queue.put(config)
        logger.info(f"ğŸ“¬ Entrenamiento encolado: {config.model_name}")

    def schedule_retraining(self, model_id: str, interval: timedelta | None = None):
        """ğŸ†• Programa reentrenamiento automÃ¡tico de un modelo"""
        interval = interval or self.retraining_interval
        next_training = datetime.now() + interval
        self.retraining_schedule[model_id] = next_training
        logger.info(f"ğŸ“… Reentrenamiento programado para {model_id}: {next_training.isoformat()}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ENTRENAMIENTO DE MODELOS (cÃ³digo existente mejorado)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def train_model(
        self,
        config: TrainingConfig,
        X_train: np.ndarray | None = None,
        y_train: np.ndarray | None = None,
        X_val: np.ndarray | None = None,
        y_val: np.ndarray | None = None,
    ) -> TrainingResult:
        """
        ğŸ–ï¸ Entrenar modelo con MILITARY FEATURES v3.0

        PROTECCIONES MILITARES:
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        1. Circuit Breaker (protecciÃ³n contra fallos en cascada)
        2. Rate Limiting (60 trainings/min)
        3. Event Sourcing (registro completo)
        4. Auto-Healing (recuperaciÃ³n automÃ¡tica)
        """

        # ğŸ–ï¸ MILITARY PROTECTIONS
        # 1. Circuit Breaker Check
        if not self._check_circuit_breaker():
            return TrainingResult(
                model_id="circuit_breaker_open",
                model_type=config.model_type,
                algorithm=config.algorithm,
                status=TrainingStatus.FAILED,
                metadata={"error": "Circuit breaker open - too many failures"},
            )

        # 2. Rate Limiting Check
        if not self._check_rate_limit():
            return TrainingResult(
                model_id="rate_limit_exceeded",
                model_type=config.model_type,
                algorithm=config.algorithm,
                status=TrainingStatus.FAILED,
                metadata={"error": "Rate limit exceeded (60 trainings/min)"},
            )

        # 3. Log Event (Event Sourcing)
        self._log_event("training_started", {
            "model_name": config.model_name,
            "algorithm": config.algorithm,
            "model_type": config.model_type.value,
        })

        if not SKLEARN_AVAILABLE:
            logger.error("âŒ scikit-learn no disponible")
            self._record_training_failure()
            return TrainingResult(
                model_id="error",
                model_type=config.model_type,
                algorithm=config.algorithm,
                status=TrainingStatus.FAILED,
                metadata={"error": "scikit-learn not available"},
            )

        logger.info(f"ğŸš€ Iniciando entrenamiento MILITARY GRADE: {config.model_name}")

        start_time = time.time()
        model_id = self._generate_model_id(config)

        result = TrainingResult(
            model_id=model_id,
            model_type=config.model_type,
            algorithm=config.algorithm,
            status=TrainingStatus.PENDING,
        )

        try:
            # 1. Cargar datos
            result.status = TrainingStatus.PREPROCESSING
            if X_train is None or y_train is None:
                if not config.train_data_path:
                    raise ValueError("Se requiere train_data_path o datos directos")
                X_train, y_train, X_val, y_val = self._load_and_prepare_data(config)

            # Split si no hay validaciÃ³n
            if X_val is None or y_val is None:
                X_train, X_val, y_train, y_val = train_test_split(
                    X_train, y_train, test_size=config.validation_split, random_state=42
                )

            result.num_train_samples = len(X_train)
            result.num_val_samples = len(X_val)
            result.num_features = X_train.shape[1] if len(X_train.shape) > 1 else 1

            logger.info(
                f"ğŸ“Š Datos preparados: {result.num_train_samples} train, {result.num_val_samples} val"
            )

            # 2. Entrenar
            result.status = TrainingStatus.TRAINING
            model = self._create_model(config)

            if config.model_type == ModelType.CLASSIFICATION:
                model = self._train_classification_model(
                    model, config, X_train, y_train, X_val, y_val, result
                )
            elif config.model_type == ModelType.REGRESSION:
                model = self._train_regression_model(
                    model, config, X_train, y_train, X_val, y_val, result
                )
            else:
                raise ValueError(f"Tipo no soportado: {config.model_type}")

            # 3. Evaluar
            result.status = TrainingStatus.EVALUATING
            self._evaluate_model(model, config, X_train, y_train, X_val, y_val, result)

            # 4. Guardar
            model_path = self._save_model(model, config, result)
            result.model_path = str(model_path)
            result.model_size_mb = model_path.stat().st_size / (1024 * 1024)

            # 5. Completar
            result.status = TrainingStatus.COMPLETED
            result.completed_at = datetime.now()
            result.training_time_seconds = time.time() - start_time

            logger.info(f"âœ… Entrenamiento completado en {result.training_time_seconds:.2f}s")
            logger.info(f"ğŸ“ˆ MÃ©tricas: {result.val_metrics}")

            # ğŸ–ï¸ MILITARY SUCCESS TRACKING
            self._record_training_success()
            self.metrics["models_trained"] += 1
            self._update_success_rate()

            # 6. Auto-deploy
            if config.auto_deploy and self._meets_deployment_criteria(result, config):
                self.deploy_model(result.model_id)

                # Programar reentrenamiento
                if self.enable_continuous_learning:
                    self.schedule_retraining(result.model_id)

            # 7. Guardar historial
            self.training_history.append(result)
            self._save_training_history()

            # 8. Guardar en memoria (si estÃ¡ disponible)
            if self.memory:
                try:
                    self.memory.store_episode(
                        content=f"Model trained: {config.model_name}",
                        context={
                            "model_id": model_id,
                            "algorithm": config.algorithm,
                            "metrics": result.val_metrics,
                        },
                        importance=0.9,
                    )
                except Exception as e:
                    logger.debug(f"No se pudo guardar en memoria: {e}")

            # 9. Event Sourcing
            self._log_event("training_completed", {
                "model_id": model_id,
                "training_time": result.training_time_seconds,
                "metrics": result.val_metrics,
            })

            # 10. Notificar Cognitive Agent
            self._notify_cognitive_agent("ml_training_completed", {
                "model_id": model_id,
                "metrics": result.val_metrics,
                "algorithm": config.algorithm,
            })

            return result

        except Exception as e:
            logger.error(f"âŒ Error en entrenamiento: {e}", exc_info=True)

            # ğŸ–ï¸ MILITARY FAILURE TRACKING
            self._record_training_failure()
            self.metrics["training_failures"] += 1
            self._update_success_rate()

            # ğŸ¥ AUTO-HEALING (si estÃ¡ habilitado)
            if self.enable_auto_healing:
                self._attempt_auto_healing(config, e)

            result.status = TrainingStatus.FAILED
            result.completed_at = datetime.now()
            result.metadata["error"] = str(e)

            # Event Sourcing
            self._log_event("training_failed", {
                "model_name": config.model_name,
                "error": str(e),
            })

            return result

    def _update_success_rate(self):
        """Actualizar tasa de Ã©xito de entrenamiento"""
        total = self.metrics["models_trained"] + self.metrics["training_failures"]
        if total > 0:
            self.metrics["training_success_rate"] = self.metrics["models_trained"] / total

    def _attempt_auto_healing(self, config: TrainingConfig, error: Exception):
        """ğŸ¥ Intentar auto-healing del entrenamiento fallido"""
        self.metrics["auto_healing_activations"] += 1
        logger.info(f"ğŸ¥ Auto-Healing: Intentando recuperaciÃ³n para {config.model_name}")

        # IMPLEMENTED: Implementar estrategias de auto-healing
        # - Reducir batch size
        # - Simplificar modelo
        # - Aumentar tiempo de timeout
        # - Reintentar con hiperparÃ¡metros alternativos

    def _create_model(self, config: TrainingConfig) -> Any:
        """Crear modelo"""
        algorithm = config.algorithm.lower()
        params = config.hyperparameters

        if config.model_type == ModelType.CLASSIFICATION:
            if algorithm == "random_forest":
                return RandomForestClassifier(**params) if params else RandomForestClassifier()
            if algorithm == "logistic_regression":
                return LogisticRegression(**params) if params else LogisticRegression()
            return RandomForestClassifier()  # Default
        if config.model_type == ModelType.REGRESSION:
            if algorithm == "random_forest":
                return RandomForestRegressor(**params) if params else RandomForestRegressor()
            if algorithm == "linear_regression":
                return LinearRegression(**params) if params else LinearRegression()
            return RandomForestRegressor()  # Default
        raise ValueError(f"Tipo no soportado: {config.model_type}")

    def _train_classification_model(self, model, config, X_train, y_train, X_val, y_val, result):
        """Entrenar clasificador"""
        model.fit(X_train, y_train)

        y_train_pred = model.predict(X_train)
        result.train_metrics = {
            "accuracy": accuracy_score(y_train, y_train_pred),
            "f1": f1_score(y_train, y_train_pred, average="weighted", zero_division=0),
        }

        y_val_pred = model.predict(X_val)
        result.val_metrics = {
            "accuracy": accuracy_score(y_val, y_val_pred),
            "f1": f1_score(y_val, y_val_pred, average="weighted", zero_division=0),
        }

        return model

    def _train_regression_model(self, model, config, X_train, y_train, X_val, y_val, result):
        """Entrenar regresor"""
        model.fit(X_train, y_train)

        y_train_pred = model.predict(X_train)
        result.train_metrics = {
            "mse": mean_squared_error(y_train, y_train_pred),
            "r2": r2_score(y_train, y_train_pred),
        }

        y_val_pred = model.predict(X_val)
        result.val_metrics = {
            "mse": mean_squared_error(y_val, y_val_pred),
            "r2": r2_score(y_val, y_val_pred),
        }

        return model

    def _evaluate_model(self, model, config, X_train, y_train, X_val, y_val, result):
        """Evaluar con cross-validation adaptativo"""
        if config.cross_validation_folds > 0:
            # ğŸ”§ CORRECCIÃ“N: Ajustar folds basado en la clase menos poblada
            n_folds = config.cross_validation_folds

            if config.model_type == ModelType.CLASSIFICATION:
                # Contar la clase menos poblada

                class_counts = Counter(y_train)
                min_class_size = min(class_counts.values()) if class_counts else 1

                # Ajustar folds para evitar warning de sklearn
                # Necesitamos al menos 2 ejemplos por fold
                max_safe_folds = max(2, min(min_class_size // 2, n_folds))

                if max_safe_folds < n_folds:
                    logger.warning(
                        f"âš ï¸ Reduciendo folds de {n_folds} a {max_safe_folds} "
                        f"(clase mÃ­nima: {min_class_size} ejemplos)"
                    )
                    n_folds = max_safe_folds

            # Cross-validation solo si tenemos suficientes datos
            if len(y_train) >= n_folds * 2:
                try:
                    cv_scores = cross_val_score(
                        model,
                        X_train,
                        y_train,
                        cv=n_folds,
                        scoring="accuracy"
                        if config.model_type == ModelType.CLASSIFICATION
                        else "r2",
                    )
                    result.metadata["cv_mean"] = float(cv_scores.mean())
                    result.metadata["cv_std"] = float(cv_scores.std())
                    result.metadata["cv_folds_used"] = n_folds
                except Exception as e:
                    logger.warning(f"âš ï¸ Error en cross-validation: {e}")
                    result.metadata["cv_error"] = str(e)
            else:
                logger.warning(
                    f"âš ï¸ Datos insuficientes para CV ({len(y_train)} samples < {n_folds * 2})"
                )
                result.metadata["cv_skipped"] = "insufficient_data"

    def _save_model(self, model, config, result) -> Path:
        """Guardar modelo"""
        model_path = self.models_dir / f"{result.model_id}.pkl"

        with open(model_path, "wb") as f:
            pickle.dump(model, f)

        metadata_path = self.models_dir / f"{result.model_id}_metadata.json"
        with open(metadata_path, "w") as f:
            json.dump(result.to_dict(), f, indent=2)

        logger.info(f"ğŸ’¾ Modelo guardado: {model_path}")
        return model_path

    def _load_and_prepare_data(self, config):
        """Cargar datos desde CSV"""
        
        data_path = Path(config.train_data_path)
        df = pd.read_csv(data_path)

        X = df.drop("target", axis=1).values
        y = df["target"].values

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=config.validation_split + config.test_split, random_state=42
        )

        X_val, _, y_val, _ = train_test_split(X_test, y_test, test_size=0.5, random_state=42)

        return X_train, y_train, X_val, y_val

    def _meets_deployment_criteria(self, result, config):
        """Verificar criterios de deployment"""
        if config.model_type == ModelType.CLASSIFICATION:
            return result.val_metrics.get("accuracy", 0) >= config.min_accuracy
        if config.model_type == ModelType.REGRESSION:
            return result.val_metrics.get("r2", 0) >= config.min_accuracy
        return False

    def _generate_model_id(self, config):
        """Generar ID Ãºnico"""
        data = f"{config.model_name}_{config.algorithm}_{datetime.now().isoformat()}"
        return hashlib.md5(data.encode()).hexdigest()[:12]

    def deploy_model(self, model_id: str) -> bool:
        """Deployar modelo"""
        try:
            model_path = self.models_dir / f"{model_id}.pkl"
            with open(model_path, "rb") as f:
                model = pickle.load(f)

            self.active_models[model_id] = {
                "model": model,
                "deployed_at": datetime.now(),
                "predictions_count": 0,
            }

            for result in self.training_history:
                if result.model_id == model_id:
                    result.status = TrainingStatus.DEPLOYED
                    break

            self._save_training_history()
            logger.info(f"âœ… Modelo deployed: {model_id}")
            return True
        except Exception as e:
            logger.error(f"âŒ Error deploying: {e}")
            return False

    def predict(self, model_id: str, X: np.ndarray) -> np.ndarray:
        """Hacer predicciÃ³n"""
        if model_id not in self.active_models:
            raise ValueError(f"Modelo {model_id} no deployado")

        model = self.active_models[model_id]["model"]
        predictions = model.predict(X)
        self.active_models[model_id]["predictions_count"] += len(X)

        return predictions

    def predict_with_cognitive_notification(
        self, model_id: str, X: np.ndarray, prediction_type: str
    ) -> dict[str, Any]:
        """
        Hace predicciÃ³n y notifica al Cognitive Agent

        Args:
            model_id: ID del modelo
            X: Datos de entrada
            prediction_type: 'intention' | 'load' | 'cache' | 'performance'

        Returns:
            Dict con predicciÃ³n, confidence y metadata
        """
        if model_id not in self.active_models:
            raise ValueError(f"Modelo {model_id} no deployado")

        model_info = self.active_models[model_id]
        model = model_info["model"]

        # Hacer predicciÃ³n
        predictions = model.predict(X)
        model_info["predictions_count"] += len(X)

        # Calcular confidence (si el modelo tiene predict_proba)
        confidence = 0.0
        if hasattr(model, "predict_proba"):
            try:
                proba = model.predict_proba(X)
                confidence = float(np.max(proba[0]))
            except Exception:
                confidence = 0.5
        else:
            confidence = 0.7  # Default para modelos de regresiÃ³n

        # Preparar resultado
        result = {
            "model_id": model_id,
            "prediction": predictions[0] if len(predictions) == 1 else predictions.tolist(),
            "confidence": confidence,
            "model_accuracy": model_info.get("accuracy", 0.0),
            "predictions_count": model_info["predictions_count"],
            "timestamp": datetime.now().isoformat(),
        }

        # Notificar al Cognitive Agent
        try:
            from cognitive_integration import get_cognitive_bridge

            bridge = get_cognitive_bridge()
            bridge.notify_ml_prediction(prediction_type, result)
            logger.info(f"âœ… Cognitive notificado: {prediction_type} â†’ {result['prediction']}")
        except Exception as e:
            logger.warning(f"âš ï¸ No se pudo notificar al Cognitive: {e}")

        return result

    def _load_training_history(self):
        """Cargar historial"""
        history_path = self.models_dir / "training_history.json"
        if history_path.exists():
            try:
                with open(history_path) as f:
                    data = json.load(f)
                for item in data:
                    result = TrainingResult(
                        model_id=item["model_id"],
                        model_type=ModelType(item["model_type"]),
                        algorithm=item["algorithm"],
                        status=TrainingStatus(item["status"]),
                    )
                    result.train_metrics = item.get("train_metrics", {})
                    result.val_metrics = item.get("val_metrics", {})
                    result.model_path = item.get("model_path")
                    self.training_history.append(result)
                logger.info(f"ğŸ“‚ Historial cargado: {len(self.training_history)} modelos")
            except Exception as e:
                logger.warning(f"âš ï¸ Error cargando historial: {e}")

    def _auto_load_deployed_models(self):
        """ğŸ†• Auto-carga modelos que estÃ¡n en estado DEPLOYED"""
        deployed_count = 0
        for result in self.training_history:
            if result.status == TrainingStatus.DEPLOYED and result.model_path:
                try:
                    self.deploy_model(result.model_id)
                    deployed_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ Error auto-loading {result.model_id}: {e}")

        if deployed_count > 0:
            logger.info(f"ğŸš€ Auto-loaded {deployed_count} modelos deployados")

    def _save_training_history(self):
        """Guardar historial"""
        history_path = self.models_dir / "training_history.json"
        try:
            data = [r.to_dict() for r in self.training_history]
            with open(history_path, "w") as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            logger.warning(f"âš ï¸ Error guardando historial: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• PROPIEDADES (Retrocompatibilidad)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    @property
    def models_trained(self) -> int:
        """
        ğŸ†• PROPIEDAD: NÃºmero total de modelos entrenados
        Retorna el tamaÃ±o del historial de entrenamiento
        """
        return len(self.training_history)

    def get_stats(self) -> dict[str, Any]:
        """Obtener estadÃ­sticas del pipeline"""
        return {
            "total_models_trained": self.models_trained,
            "active_models": len(self.deployed_models),
            "queue_size": self.training_queue.qsize(),
            "perpetual_mode": self.enable_perpetual_mode,
            "neural_network_connected": self.neural_network is not None,
            "memory_connected": self.memory is not None,
            "cache_connected": self.cache is not None,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ–ï¸ SINGLETON & COMPATIBILITY (v3.0)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_global_ml_pipeline: MilitaryGradeMLPipeline | None = None


def get_ml_pipeline(**kwargs) -> MilitaryGradeMLPipeline:
    """
    ğŸ–ï¸ Obtener instancia global MILITARY GRADE

    Returns:
        MilitaryGradeMLPipeline: Instancia singleton v3.0
    """
    global _global_ml_pipeline
    if _global_ml_pipeline is None:
        _global_ml_pipeline = MilitaryGradeMLPipeline(**kwargs)
    return _global_ml_pipeline


# ğŸ”„ BACKWARD COMPATIBILITY: MLPipeline = MilitaryGradeMLPipeline
MLPipeline = MilitaryGradeMLPipeline


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    pipeline = get_ml_pipeline()

    print("\n" + "=" * 80)
    print("ğŸ–ï¸ ML PIPELINE MILITARY GRADE v3.0")
    print("=" * 80)
    print(f"   Modelos dir: {pipeline.models_dir}")
    print(f"   Modo perpetuo: {pipeline.perpetual_running}")
    print(f"   Queue: {pipeline.training_queue.qsize()}")
    print(f"   Conexiones simbiÃ³ticas: {pipeline.metrics['neural_connections_active']}")
    print(f"   Military Features: âœ“")
    print(f"   Circuit Breaker: {'âœ“' if pipeline.circuit_breaker.get('enabled') else 'âœ—'}")
    print(f"   Rate Limiter: {'âœ“' if pipeline.rate_limiter.get('enabled') else 'âœ—'}")
    print(f"   Event Sourcing: {'âœ“' if pipeline.event_log else 'âœ—'}")
    print("=" * 80)

    print("\nâœ… Sistema ML Pipeline MILITARY GRADE v3.0 inicializado correctamente")